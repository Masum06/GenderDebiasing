{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zalandoresearch/flair\n",
    "\n",
    "https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flair\n",
    "#!pip uninstall spacy\n",
    "#!pip install -U spacy==2.1.0\n",
    "##!python -m spacy download en\n",
    "#!python -m spacy download en_core_web_lg\n",
    "##!python -m spacy download en_core_web_md\n",
    "#!pip install neuralcoref --no-binary neuralcoref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_pronouns   = [\"he\",  \"him\", \"his$\", \"his\", \"himself\"]\n",
    "female_pronouns = [\"she\", \"her\", \"her$\", \"hers\", \"herself\"]\n",
    "neutral_pronouns= [\"zie\", \"zim\", \"zir\", \"zis\", \"zieself\"]\n",
    "merged_pronouns = [\"he/she\", \"him/her\", \"his/her\", \"his/hers\", \"himself/herself\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_pronouns_dict = {}\n",
    "gender_honorific_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (g1,g2,g3,g4) in zip(male_pronouns, female_pronouns, neutral_pronouns, merged_pronouns):\n",
    "    element = {\"male\": g1, \"female\":g2, \"neutral\":g3, \"merged\":g4}\n",
    "    gender_pronouns_dict[g1] = gender_pronouns_dict[g2] = gender_pronouns_dict[g3] = gender_pronouns_dict[g4] =element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_hons   =  [\"Mr.\", \"Mr\", \"Md.\", \"Md\", \"Sir\", \"Lord\", \"Mister\"]\n",
    "female_hons =  [\"Ms.\", \"Ms\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Miss\"]\n",
    "neutral_hons = [\"Mx.\", \"Mx\", \"Mx.\", \"Mx\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]\n",
    "married_hons = [\"Mrs.\", \"Mrs\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Mis'ess\"]\n",
    "merged_hons =  [\"Mr./Ms.\", \"Mr/Ms\", \"Md./Mst.\", \"Md/Mst\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (h1,h2,h3,h4,h5) in zip(male_hons, female_hons, neutral_hons, married_hons, merged_hons):\n",
    "    element = {\"male\": h1, \"female\":h2, \"neutral\":h3, \"married_fem\":h4, \"merged\":h5}\n",
    "    gender_honorific_dict[h1] = gender_honorific_dict[h2] = gender_honorific_dict[h3] = \\\n",
    "    gender_honorific_dict[h4] = gender_honorific_dict[h5] = element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from segtok.segmenter import split_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import neuralcoref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('char2idx.json', 'r') as fp:\n",
    "    char2idx = json.load(fp)\n",
    "    \n",
    "with open('idx2char.json', 'r') as fp:\n",
    "    idx2char = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-02 23:14:32,201 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2019-11-02 23:14:32,258 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2019-11-02 23:14:32,278 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2019-11-02 23:14:32,407 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2019-11-02 23:14:32,415 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2019-11-02 23:14:32,636 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2019-11-02 23:14:32,810 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2019-11-02 23:14:32,819 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model('char_rnn_hsc_model_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1ec7111dbe0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg') # en_core_web_sm #en_core_web_md\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-02 23:14:51,085 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n",
      "2019-11-02 23:15:12,914 loading file C:\\Users\\Hp\\.flair\\models\\en-pos-ontonotes-v0.2.pt\n"
     ]
    }
   ],
   "source": [
    "tagger_ner = SequenceTagger.load('ner')\n",
    "tagger_pos = SequenceTagger.load('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name2Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Converts a name into vector\n",
    "def name2vectorTest(name):\n",
    "    name = name.lower()\n",
    "    new_name = \"\"\n",
    "    for char in name:\n",
    "      if char in char2idx:\n",
    "        new_name += char\n",
    "    chars = list(new_name)\n",
    "    vector = [ char2idx[c] for c in chars ]\n",
    "    return np.array(vector)\n",
    "\n",
    "# Converts names to fixed size tensor\n",
    "def names2tensorTest(names, maxlen=25):\n",
    "    namelist = [name2vectorTest(name) for name in names]\n",
    "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
    "\n",
    "def name2gender(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  if result:\n",
    "    print(\"Male\")\n",
    "  else:\n",
    "    print(\"Female\")\n",
    "  \n",
    "def isMale(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Input Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"At the same time, in front of a crowd in northeast Mississippi, Trump was mocking the Democratic Party as \"completely insane\" -- and mocking several of its candidates. He called former Vice President Joe Biden \"very slow sleepy Joe.\" He said he doesn't know who Hawaii Rep. Tulsi Gabbard is. And he said former Texas Rep. Beto O'Rourke, who dropped out of the race Friday, 'quit like a dog.'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ' '.join(s.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS-NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_pos = []\n",
    "pos = []\n",
    "oracle = []\n",
    "coref2name = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = Sentence(s, use_tokenizer=True)\n",
    "tagger_ner.predict(sent)\n",
    "tagger_pos.predict(sent)\n",
    "tagged_list = sent.to_tagged_string().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(tagged_list),2):\n",
    "    tokens_pos.append(tagged_list[i])\n",
    "    pos.append(tagged_list[i+1])\n",
    "    \n",
    "    if tagged_list[i].lower() in male_pronouns+female_pronouns:\n",
    "        oracle.append(2)\n",
    "    elif tagged_list[i+1] in ['<B-PER/NNP>', '<I-PER/NNP>', '<E-PER/NNP>', '<S-PER/NNP>']:\n",
    "        oracle.append(4)\n",
    "    else:\n",
    "        oracle.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coreference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-4fd6bc12d675>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert len(doc)==len(tokens_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokens = [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " ',',\n",
       " 'in',\n",
       " 'front',\n",
       " 'of',\n",
       " 'a',\n",
       " 'crowd',\n",
       " 'in',\n",
       " 'northeast',\n",
       " 'Mississippi',\n",
       " ',',\n",
       " 'Trump',\n",
       " 'was',\n",
       " 'mocking',\n",
       " 'the',\n",
       " 'Democratic',\n",
       " 'Party',\n",
       " 'as',\n",
       " '\"',\n",
       " 'completely',\n",
       " 'insane',\n",
       " '\"',\n",
       " '--',\n",
       " 'and',\n",
       " 'mocking',\n",
       " 'several',\n",
       " 'of',\n",
       " 'its',\n",
       " 'candidates',\n",
       " '.',\n",
       " 'He',\n",
       " 'called',\n",
       " 'former',\n",
       " 'Vice',\n",
       " 'President',\n",
       " 'Joe',\n",
       " 'Biden',\n",
       " '\"',\n",
       " 'very',\n",
       " 'slow',\n",
       " 'sleepy',\n",
       " 'Joe',\n",
       " '.',\n",
       " '\"',\n",
       " 'He',\n",
       " 'said',\n",
       " 'he',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'who',\n",
       " 'Hawaii',\n",
       " 'Rep.',\n",
       " 'Tulsi',\n",
       " 'Gabbard',\n",
       " 'is',\n",
       " '.',\n",
       " 'And',\n",
       " 'he',\n",
       " 'said',\n",
       " 'former',\n",
       " 'Texas',\n",
       " 'Rep.',\n",
       " 'Beto',\n",
       " \"O'Rourke\",\n",
       " ',',\n",
       " 'who',\n",
       " 'dropped',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'race',\n",
       " 'Friday',\n",
       " ',',\n",
       " \"'\",\n",
       " 'quit',\n",
       " 'like',\n",
       " 'a',\n",
       " 'dog',\n",
       " '.',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " ',',\n",
       " 'in',\n",
       " 'front',\n",
       " 'of',\n",
       " 'a',\n",
       " 'crowd',\n",
       " 'in',\n",
       " 'northeast',\n",
       " 'Mississippi',\n",
       " ',',\n",
       " 'Trump',\n",
       " 'was',\n",
       " 'mocking',\n",
       " 'the',\n",
       " 'Democratic',\n",
       " 'Party',\n",
       " 'as',\n",
       " '\"',\n",
       " 'completely',\n",
       " 'insane',\n",
       " '\"',\n",
       " '--',\n",
       " 'and',\n",
       " 'mocking',\n",
       " 'several',\n",
       " 'of',\n",
       " 'its',\n",
       " 'candidates',\n",
       " '.',\n",
       " 'He',\n",
       " 'called',\n",
       " 'former',\n",
       " 'Vice',\n",
       " 'President',\n",
       " 'Joe',\n",
       " 'Biden',\n",
       " '\"',\n",
       " 'very',\n",
       " 'slow',\n",
       " 'sleepy',\n",
       " 'Joe',\n",
       " '.',\n",
       " '\"',\n",
       " 'He',\n",
       " 'said',\n",
       " 'he',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'who',\n",
       " 'Hawaii',\n",
       " 'Rep',\n",
       " '.',\n",
       " 'Tulsi',\n",
       " 'Gabbard',\n",
       " 'is',\n",
       " '.',\n",
       " 'And',\n",
       " 'he',\n",
       " 'said',\n",
       " 'former',\n",
       " 'Texas',\n",
       " 'Rep',\n",
       " '.',\n",
       " 'Beto',\n",
       " \"O'Rourke\",\n",
       " ',',\n",
       " 'who',\n",
       " 'dropped',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'race',\n",
       " 'Friday',\n",
       " ',',\n",
       " \"'\",\n",
       " 'quit',\n",
       " 'like',\n",
       " 'a',\n",
       " 'dog',\n",
       " '.',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At the same time, in front of a crowd in northeast Mississippi, Trump was mocking the Democratic Party as \"completely insane\" -- and mocking several of its candidates. He called former Vice President Joe Biden \"very slow sleepy Joe.\" He said he doesn\\'t know who Hawaii Rep. Tulsi Gabbard is. And he said former Texas Rep. Beto O\\'Rourke, who dropped out of the race Friday, \\'quit like a dog.\\''"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumption: The sentence will end with period or any other special token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_stack = []\n",
    "name_stack = []\n",
    "for i in range(len(doc)):\n",
    "    token = doc[i]\n",
    "    if token._.in_coref:\n",
    "        coref_stack.append(tokens_pos[i])\n",
    "        if oracle[i] == 4:\n",
    "            name_stack.append(tokens_pos[i])\n",
    "        oracle[i] += 1\n",
    "    else:\n",
    "        if len(name_stack) > 0:\n",
    "            name = ' '.join(name_stack)\n",
    "            coref = ' '.join(coref_stack)\n",
    "            #name2coref[name] = coref\n",
    "            coref2name[coref] = name\n",
    "            name_stack.clear()\n",
    "        coref_stack.clear()\n",
    "\n",
    "# IF THE SENTENCE DOES NOT END WITH A PERIOD OR SPECIAL CHARACTER\n",
    "if len(name_stack) > 0:\n",
    "    name = ' '.join(name_stack)\n",
    "    name2coref[name] = ' '.join(coref_stack)\n",
    "    name_stack.clear()\n",
    "coref_stack.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(name, name_found):\n",
    "    if name_found in Name2Key:\n",
    "        if name not in Name2Key:\n",
    "            element = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
    "    else:\n",
    "        global num_keys\n",
    "        num_keys+=1\n",
    "        key = \"PER_\"+str(num_keys)\n",
    "        gender = name2gender(name)\n",
    "        alias = None\n",
    "        \n",
    "        if name!=name_found:\n",
    "            element_alias = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
    "            Name2Key[name] = element_alias\n",
    "            alias = name\n",
    "        \n",
    "        element = {\"name\": name, \"key\": key, \"gender\":gender, \"alias\":alias, \"is_alias\": False, \"alias_to\": None}\n",
    "        Name2Key[name_found] = element\n",
    "        Key2Name[key] = element\n",
    "        \n",
    "    return Name2Key[name_found][\"key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Name2Key = {}\n",
    "Key2Name = {}\n",
    "encrypted = []\n",
    "num_keys = 0\n",
    "\n",
    "i = 0\n",
    "while i<len(tokens_pos): \n",
    "    #print(\"Oracle \", i, tokens_pos[i])\n",
    "    if oracle[i] == 0:\n",
    "        encrypted.append(tokens_pos[i])\n",
    "    elif oracle[i] == 1:\n",
    "        if tokens_pos[i] in gender_honorific_dict:\n",
    "            encrypted.append(\"<|hons|>\")\n",
    "            encrypted.append(gender_honorific_dict[tokens_pos[i]][\"merged\"])\n",
    "        else:\n",
    "            encrypted.append(tokens_pos[i])\n",
    "    elif oracle[i] == 2:\n",
    "        pronoun = tokens_pos[i].lower()\n",
    "        if pos[i] == '<PRP$>':\n",
    "            pronoun+=\"$\"\n",
    "        encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "    elif oracle[i] == 3:\n",
    "        coref = doc[i]._.coref_clusters[0][0].text\n",
    "        name_found = coref2name[coref]\n",
    "        key = Name2Key[name_found][\"key\"]\n",
    "        encrypted.append(\"<|coref|>\")\n",
    "        pronoun = tokens_pos[i].lower()\n",
    "        if pos[i] == '<PRP$>':\n",
    "            pronoun+=\"$\"\n",
    "        encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "        encrypted.append(key)\n",
    "        \n",
    "    elif oracle[i] in [4,5]:\n",
    "        if pos[i] == '<S-PER/NNP>':\n",
    "            name = tokens_pos[i]\n",
    "        else:\n",
    "            name = \"\"\n",
    "            while True:\n",
    "                name += tokens_pos[i]\n",
    "                if pos[i] == '<E-PER/NNP>':\n",
    "                    break\n",
    "                name += \" \"\n",
    "                i+=1\n",
    "        \n",
    "        if oracle[i] == 4:\n",
    "            key = store(name, name)\n",
    "            encrypted.append(key)\n",
    "        else:\n",
    "            coref = doc[i]._.coref_clusters[0][0].text\n",
    "            name_found = coref2name[coref]\n",
    "            if name == name_found:\n",
    "                key = store(name, name_found)\n",
    "                encrypted.append(key)\n",
    "            else:\n",
    "                key = store(name, name_found)\n",
    "                encrypted.append(\"<|alias|>\")\n",
    "                encrypted.append(key)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name2Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PER_1': {'name': 'Donald Trump',\n",
       "  'key': 'PER_1',\n",
       "  'gender': None,\n",
       "  'alias': None,\n",
       "  'is_alias': False,\n",
       "  'alias_to': None}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Key2Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
