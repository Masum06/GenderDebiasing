{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zalandoresearch/flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 18:57:16,897 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from segtok.segmenter import split_single\n",
    "\n",
    "# load the NER tagger\n",
    "tagger = SequenceTagger.load('ner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namesAndSentences(text):\n",
    "    sentences_obj = [Sentence(sent, use_tokenizer=True) for sent in split_single(text)]\n",
    "    tagger: SequenceTagger = SequenceTagger.load('ner')\n",
    "    #tagger.predict(sentences_obj)\n",
    "    tegged_sentences = tagger.predict(sentences_obj)\n",
    "    #name_gender = {}\n",
    "    sentences = []\n",
    "    male_names = []\n",
    "    female_names = []\n",
    "    for tagged_sent in tegged_sentences:\n",
    "        sent_dict = tagged_sent.to_dict(tag_type='ner')\n",
    "        sentences += [sent_dict['text']]\n",
    "        if sent_dict['entities']:\n",
    "            for entity in sent_dict['entities']:\n",
    "                if entity['type'] == 'PER':\n",
    "                    name = entity['text']\n",
    "                    gender = isMale(name)\n",
    "                    #name_gender[name] = gender\n",
    "                    if gender:\n",
    "                        male_names.append(name)\n",
    "                    else:\n",
    "                        female_names.append(name)\n",
    "                    print(name, gender)\n",
    "    return male_names, female_names, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanName(name, names):\n",
    "    for x in names:\n",
    "        if x in name:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Tom Cruise is the highest paid star in Hollywood . He can demand any payment . But Robert Downey Jr. is now trumping him . He is even asking more money than Tom .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 19:12:13,402 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "sentences_obj = [Sentence(sent, use_tokenizer=True) for sent in split_single(s)]\n",
    "tagger: SequenceTagger = SequenceTagger.load('ner')\n",
    "#tagger.predict(sentences_obj)\n",
    "tegged_sentences = tagger.predict(sentences_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"Tom Cruise is the highest paid star in Hollywood . He can demand any payment . But Robert Downey Jr. is now trumping him . He is even asking more money than Tom .\" - 34 Tokens]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tegged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"Tom Cruise is the highest paid star in Hollywood . He can demand any payment . But Robert Downey Jr. is now trumping him . He is even asking more money than Tom .\" - 34 Tokens"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = Sentence(s, use_tokenizer=True)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"Tom Cruise is the highest paid star in Hollywood . He can demand any payment . But Robert Downey Jr. is now trumping him . He is even asking more money than Tom .\" - 34 Tokens]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tegged_sentences = tagger.predict(sent)\n",
    "tegged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Tom Cruise is the highest paid star in Hollywood . He can demand any payment . But Robert Downey Jr. is now trumping him . He is even asking more money than Tom .',\n",
       " 'labels': [],\n",
       " 'entities': [{'text': 'Tom Cruise',\n",
       "   'start_pos': 0,\n",
       "   'end_pos': 10,\n",
       "   'type': 'PER',\n",
       "   'confidence': 0.9977856576442719},\n",
       "  {'text': 'Hollywood',\n",
       "   'start_pos': 39,\n",
       "   'end_pos': 48,\n",
       "   'type': 'LOC',\n",
       "   'confidence': 0.9991932511329651},\n",
       "  {'text': 'Robert Downey Jr.',\n",
       "   'start_pos': 83,\n",
       "   'end_pos': 100,\n",
       "   'type': 'PER',\n",
       "   'confidence': 0.8331512212753296},\n",
       "  {'text': 'Tom',\n",
       "   'start_pos': 157,\n",
       "   'end_pos': 160,\n",
       "   'type': 'PER',\n",
       "   'confidence': 0.9978317618370056}]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tegged_sentences[0].to_dict(tag_type='ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 20:09:32,582 loading file C:\\Users\\Hp\\.flair\\models\\en-pos-ontonotes-v0.2.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Sentence: \"Tom Cruise is the highest paid star in Hollywood . He can demand any payment . But Robert Downey Jr. is now trumping him . He is even asking more money than Tom .\" - 34 Tokens]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('pos')\n",
    "\n",
    "# text with English and German sentences\n",
    "#sentence = Sentence('George Washington went to Washington . Dort kaufte er einen Hut .')\n",
    "\n",
    "# predict PoS tags\n",
    "tagger.predict(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom <B-PER/NNP> Cruise <E-PER/NNP> is <VBZ> the <DT> highest <JJS> paid <JJ> star <NN> in <IN> Hollywood <S-LOC/NNP> . <.> He <PRP> can <MD> demand <VB> any <DT> payment <NN> . <,> But <CC> Robert <B-PER/NNP> Downey <I-PER/NNP> Jr. <E-PER/NNP> is <VBZ> now <RB> trumping <VBG> him <PRP> . <.> He <PRP> is <VBZ> even <RB> asking <VBG> more <JJR> money <NN> than <IN> Tom <S-PER/NNP> . <.>\n"
     ]
    }
   ],
   "source": [
    "print(sent.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.to_tagged_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Tom Cruise is the highest paid star in Hollywood . He can demand any payment . But Robert Downey Jr. is now trumping him . He is even asking more money than Tom .',\n",
       " 'labels': [],\n",
       " 'entities': [{'text': 'Tom',\n",
       "   'start_pos': 0,\n",
       "   'end_pos': 3,\n",
       "   'type': 'NNP',\n",
       "   'confidence': 0.9994673132896423},\n",
       "  {'text': 'Cruise',\n",
       "   'start_pos': 4,\n",
       "   'end_pos': 10,\n",
       "   'type': 'NNP',\n",
       "   'confidence': 0.9999730587005615},\n",
       "  {'text': 'is',\n",
       "   'start_pos': 11,\n",
       "   'end_pos': 13,\n",
       "   'type': 'VBZ',\n",
       "   'confidence': 0.9999996423721313},\n",
       "  {'text': 'the',\n",
       "   'start_pos': 14,\n",
       "   'end_pos': 17,\n",
       "   'type': 'DT',\n",
       "   'confidence': 0.9999998807907104},\n",
       "  {'text': 'highest',\n",
       "   'start_pos': 18,\n",
       "   'end_pos': 25,\n",
       "   'type': 'RBS',\n",
       "   'confidence': 0.6876330971717834},\n",
       "  {'text': 'paid',\n",
       "   'start_pos': 26,\n",
       "   'end_pos': 30,\n",
       "   'type': 'VBN',\n",
       "   'confidence': 0.8565100431442261},\n",
       "  {'text': 'star',\n",
       "   'start_pos': 31,\n",
       "   'end_pos': 35,\n",
       "   'type': 'NN',\n",
       "   'confidence': 0.9999558925628662},\n",
       "  {'text': 'in',\n",
       "   'start_pos': 36,\n",
       "   'end_pos': 38,\n",
       "   'type': 'IN',\n",
       "   'confidence': 0.9999997615814209},\n",
       "  {'text': 'Hollywood',\n",
       "   'start_pos': 39,\n",
       "   'end_pos': 48,\n",
       "   'type': 'NNP',\n",
       "   'confidence': 0.9999830722808838},\n",
       "  {'text': '.',\n",
       "   'start_pos': 49,\n",
       "   'end_pos': 50,\n",
       "   'type': '.',\n",
       "   'confidence': 0.9835250377655029},\n",
       "  {'text': 'He',\n",
       "   'start_pos': 51,\n",
       "   'end_pos': 53,\n",
       "   'type': 'PRP',\n",
       "   'confidence': 0.999994158744812},\n",
       "  {'text': 'can',\n",
       "   'start_pos': 54,\n",
       "   'end_pos': 57,\n",
       "   'type': 'MD',\n",
       "   'confidence': 1.0},\n",
       "  {'text': 'demand',\n",
       "   'start_pos': 58,\n",
       "   'end_pos': 64,\n",
       "   'type': 'VB',\n",
       "   'confidence': 0.9999964237213135},\n",
       "  {'text': 'any',\n",
       "   'start_pos': 65,\n",
       "   'end_pos': 68,\n",
       "   'type': 'DT',\n",
       "   'confidence': 1.0},\n",
       "  {'text': 'payment',\n",
       "   'start_pos': 69,\n",
       "   'end_pos': 76,\n",
       "   'type': 'NN',\n",
       "   'confidence': 0.9999921321868896},\n",
       "  {'text': '.',\n",
       "   'start_pos': 77,\n",
       "   'end_pos': 78,\n",
       "   'type': ',',\n",
       "   'confidence': 0.8404860496520996},\n",
       "  {'text': 'But',\n",
       "   'start_pos': 79,\n",
       "   'end_pos': 82,\n",
       "   'type': 'CC',\n",
       "   'confidence': 0.9999988079071045},\n",
       "  {'text': 'Robert',\n",
       "   'start_pos': 83,\n",
       "   'end_pos': 89,\n",
       "   'type': 'NNP',\n",
       "   'confidence': 0.9997842907905579},\n",
       "  {'text': 'Downey',\n",
       "   'start_pos': 90,\n",
       "   'end_pos': 96,\n",
       "   'type': 'NNP',\n",
       "   'confidence': 0.9998078942298889},\n",
       "  {'text': 'Jr.',\n",
       "   'start_pos': 97,\n",
       "   'end_pos': 100,\n",
       "   'type': 'NNP',\n",
       "   'confidence': 0.9998773336410522},\n",
       "  {'text': 'is',\n",
       "   'start_pos': 101,\n",
       "   'end_pos': 103,\n",
       "   'type': 'VBZ',\n",
       "   'confidence': 1.0},\n",
       "  {'text': 'now',\n",
       "   'start_pos': 104,\n",
       "   'end_pos': 107,\n",
       "   'type': 'RB',\n",
       "   'confidence': 1.0},\n",
       "  {'text': 'trumping',\n",
       "   'start_pos': 108,\n",
       "   'end_pos': 116,\n",
       "   'type': 'VBG',\n",
       "   'confidence': 0.9999995231628418},\n",
       "  {'text': 'him',\n",
       "   'start_pos': 117,\n",
       "   'end_pos': 120,\n",
       "   'type': 'PRP',\n",
       "   'confidence': 0.9999997615814209},\n",
       "  {'text': '.',\n",
       "   'start_pos': 121,\n",
       "   'end_pos': 122,\n",
       "   'type': '.',\n",
       "   'confidence': 0.8857439160346985},\n",
       "  {'text': 'He',\n",
       "   'start_pos': 123,\n",
       "   'end_pos': 125,\n",
       "   'type': 'PRP',\n",
       "   'confidence': 1.0},\n",
       "  {'text': 'is',\n",
       "   'start_pos': 126,\n",
       "   'end_pos': 128,\n",
       "   'type': 'VBZ',\n",
       "   'confidence': 1.0},\n",
       "  {'text': 'even',\n",
       "   'start_pos': 129,\n",
       "   'end_pos': 133,\n",
       "   'type': 'RB',\n",
       "   'confidence': 0.9999998807907104},\n",
       "  {'text': 'asking',\n",
       "   'start_pos': 134,\n",
       "   'end_pos': 140,\n",
       "   'type': 'VBG',\n",
       "   'confidence': 0.9999998807907104},\n",
       "  {'text': 'more',\n",
       "   'start_pos': 141,\n",
       "   'end_pos': 145,\n",
       "   'type': 'JJR',\n",
       "   'confidence': 0.9997190833091736},\n",
       "  {'text': 'money',\n",
       "   'start_pos': 146,\n",
       "   'end_pos': 151,\n",
       "   'type': 'NN',\n",
       "   'confidence': 0.9999980926513672},\n",
       "  {'text': 'than',\n",
       "   'start_pos': 152,\n",
       "   'end_pos': 156,\n",
       "   'type': 'IN',\n",
       "   'confidence': 0.9999998807907104},\n",
       "  {'text': 'Tom',\n",
       "   'start_pos': 157,\n",
       "   'end_pos': 160,\n",
       "   'type': 'NNP',\n",
       "   'confidence': 0.9999991655349731},\n",
       "  {'text': '.',\n",
       "   'start_pos': 161,\n",
       "   'end_pos': 162,\n",
       "   'type': '.',\n",
       "   'confidence': 0.9999839067459106}]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.to_dict(tag_type='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"Tom Cruise is the highest paid star in Hollywood . He can demand any payment . But Robert Downey Jr. is now trumping him . He is even asking more money than Tom .\" - 34 Tokens]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.predict(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"George Washington went to Washington . He 's too cool .\" - 11 Tokens]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = Sentence(\"George Washington went to Washington. He's too cool.\", use_tokenizer=True)\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name To Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-24 11:26:11,440 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2019-10-24 11:26:11,549 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2019-10-24 11:26:11,592 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2019-10-24 11:26:11,727 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2019-10-24 11:26:11,737 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2019-10-24 11:26:11,987 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2019-10-24 11:26:12,187 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2019-10-24 11:26:12,198 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# LOAD SAVED MODEL\n",
    "from keras.models import load_model\n",
    "\n",
    "#del model  # deletes the existing model\n",
    "model = load_model('char_rnn_hsc_model_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('char2idx.json', 'r') as fp:\n",
    "    char2idx = json.load(fp)\n",
    "    \n",
    "with open('idx2char.json', 'r') as fp:\n",
    "    idx2char = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Converts a name into vector\n",
    "def name2vectorTest(name):\n",
    "    name = name.lower()\n",
    "    new_name = \"\"\n",
    "    for char in name:\n",
    "      if char in char2idx:\n",
    "        new_name += char\n",
    "    chars = list(new_name)\n",
    "    vector = [ char2idx[c] for c in chars ]\n",
    "    return np.array(vector)\n",
    "\n",
    "# Converts names to fixed size tensor\n",
    "def names2tensorTest(names, maxlen=25):\n",
    "    namelist = [name2vectorTest(name) for name in names]\n",
    "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
    "\n",
    "def name2gender(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  if result:\n",
    "    print(\"Male\")\n",
    "  else:\n",
    "    print(\"Female\")\n",
    "  \n",
    "def isMale(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isMale(\"khaleesi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-24 11:41:22,651 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n",
      "John 1\n",
      "Danny 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['John'], ['Danny'], ['John loves his aunt Danny.'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namesAndSentences(\"John loves his aunt Danny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constituency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall spacy\n",
    "#!pip install -U spacy==2.1.0\n",
    "#!python -m spacy download en\n",
    "#!python -m spacy download en_core_web_lg\n",
    "#!python -m spacy download en_core_web_md\n",
    "#!pip install neuralcoref --no-binary neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load your usual SpaCy model (one of SpaCy English models)\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg') # en_core_web_sm #en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x2c94c85c5f8>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add neural coref to SpaCy's pipe\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[My sister: [My sister, She, My sister Jennifer Anderston, her],\n",
       " a dog: [a dog, him]]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'My sister has a dog. She loves him. My sister Jennifer Anderston also loves her cousin Tom.'\n",
    "#s = \"Iron Man is the hero, the legend, he is the bright star in the dark night. He is Iron Man\"\n",
    "#s = \"Tony Stark and Steve Rogers are fighting over a futile argument. Although he is right, he is also right.\"\n",
    "doc = nlp(s)\n",
    "\n",
    "doc._.has_coref\n",
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My sister: [My sister, She, My sister Jennifer Anderston, her]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.coref_clusters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My sister has a dog. My sister loves a dog. My sister also loves My sister cousin Tom.'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{My sister: {My sister: 1.3110305070877075},\n",
       " a dog: {a dog: 1.8048807382583618, My sister: -1.6723215579986572},\n",
       " She: {She: -0.14088207483291626,\n",
       "  My sister: 8.060324668884277,\n",
       "  a dog: -1.063360571861267},\n",
       " him: {him: -1.844308853149414,\n",
       "  My sister: 3.1037380695343018,\n",
       "  a dog: 4.34161376953125,\n",
       "  She: -3.1448943614959717},\n",
       " My sister Jennifer Anderston: {My sister Jennifer Anderston: 0.6244196891784668,\n",
       "  My sister: 6.007168769836426,\n",
       "  a dog: -1.5619761943817139,\n",
       "  She: -1.6959316730499268,\n",
       "  him: -2.714344024658203},\n",
       " Jennifer Anderston: {Jennifer Anderston: 2.7167253494262695,\n",
       "  My sister: -1.988074779510498,\n",
       "  a dog: -1.5813993215560913,\n",
       "  She: -2.404654026031494,\n",
       "  him: -3.1099295616149902,\n",
       "  My sister Jennifer Anderston: -1.530830979347229},\n",
       " her: {her: 0.9861313104629517,\n",
       "  My sister: 1.644162893295288,\n",
       "  a dog: -1.7363190650939941,\n",
       "  She: 2.570068597793579,\n",
       "  him: -4.139921188354492,\n",
       "  My sister Jennifer Anderston: 6.505741119384766,\n",
       "  Jennifer Anderston: 0.5826096534729004},\n",
       " her cousin Tom: {her cousin Tom: 1.609989047050476,\n",
       "  My sister: -1.7570302486419678,\n",
       "  a dog: -1.5227633714675903,\n",
       "  She: -2.2540581226348877,\n",
       "  him: -2.4758641719818115,\n",
       "  My sister Jennifer Anderston: -1.5088984966278076,\n",
       "  Jennifer Anderston: -1.5102113485336304,\n",
       "  her: -1.6567988395690918},\n",
       " Tom: {Tom: 2.1409521102905273,\n",
       "  My sister: -1.810180902481079,\n",
       "  a dog: -1.5597686767578125,\n",
       "  She: -2.3425159454345703,\n",
       "  him: -2.2630350589752197,\n",
       "  My sister Jennifer Anderston: -1.5532585382461548,\n",
       "  Jennifer Anderston: -1.5512094497680664,\n",
       "  her: -1.814178466796875,\n",
       "  her cousin Tom: -1.4981369972229004}}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.coref_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My :  [My sister: [My sister, She, My sister Jennifer Anderston, her]]\n",
      "sister :  [My sister: [My sister, She, My sister Jennifer Anderston, her]]\n",
      "has :  []\n",
      "a :  [a dog: [a dog, him]]\n",
      "dog :  [a dog: [a dog, him]]\n",
      ". :  []\n",
      "She :  [My sister: [My sister, She, My sister Jennifer Anderston, her]]\n",
      "loves :  []\n",
      "him :  [a dog: [a dog, him]]\n",
      ". :  []\n",
      "My :  [My sister: [My sister, She, My sister Jennifer Anderston, her]]\n",
      "sister :  [My sister: [My sister, She, My sister Jennifer Anderston, her]]\n",
      "Jennifer :  [My sister: [My sister, She, My sister Jennifer Anderston, her]]\n",
      "Anderston :  [My sister: [My sister, She, My sister Jennifer Anderston, her]]\n",
      "also :  []\n",
      "loves :  []\n",
      "her :  [My sister: [My sister, She, My sister Jennifer Anderston, her]]\n",
      "cousin :  []\n",
      "Tom :  []\n",
      ". :  []\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, \": \", token._.coref_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jennifer Anderston PERSON\n",
      "Tom PERSON\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting allennlp\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/bb/041115d8bad1447080e5d1e30097c95e4b66e36074277afce8620a61cee3/allennlp-0.9.0-py3-none-any.whl (7.6MB)\n",
      "Collecting parsimonious>=0.8.0 (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from allennlp) (1.16.3)\n",
      "Collecting gevent>=1.3.6 (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/51/97/2e1e8aa7ea27171c3e249480d382e78b49ab4cead5dafb2124d2a1b58a83/gevent-1.4.0-cp36-cp36m-win_amd64.whl (3.0MB)\n",
      "Requirement already satisfied: pytest in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from allennlp) (5.0.0)\n",
      "Collecting flask-cors>=3.0.7 (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
      "Collecting responses>=0.7 (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/5a/b887e89925f1de7890ef298a74438371ed4ed29b33def9e6d02dc6036fd8/responses-0.10.6-py2.py3-none-any.whl\n",
      "Collecting ftfy (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n",
      "Collecting numpydoc>=0.8.0 (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/6a/f3/7cfe4c616e4b9fe05540256cc9c6661c052c8a4cec2915732793b36e1843/numpydoc-0.9.1.tar.gz\n",
      "Requirement already satisfied: h5py in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from allennlp) (2.9.0)\n",
      "Requirement already satisfied: tqdm>=4.19 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from allennlp) (4.30.0)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from allennlp) (3.1.0)\n",
      "Requirement already satisfied: requests>=2.18 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from allennlp) (2.22.0)\n",
      "Collecting overrides (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/b2/2cb6a3fc8ee1dc8617e07e476be19723748ddfcce0c6b9db7a5f2d5b9598/overrides-2.0.tar.gz\n",
      "Collecting editdistance (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/09/c0/e3ee9a2344d333c1b6e66022297dad3ac20199e092f168bd53e8af966d29/editdistance-0.5.3-cp36-cp36m-win_amd64.whl\n",
      "Collecting torch>=1.2.0 (from allennlp)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement torch>=1.2.0 (from allennlp) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)\n",
      "ERROR: No matching distribution found for torch>=1.2.0 (from allennlp)\n",
      "WARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: torch in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from torch) (1.16.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install torch===1.3.0 torchvision===0.4.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_jsonnet not loaded, treating C:\\Users\\Hp\\AppData\\Local\\Temp\\tmpkp1yy6jt\\config.json as json\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\allennlp\\data\\token_indexers\\token_characters_indexer.py:56: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from allennlp import pretrained\n",
    "model = pretrained.neural_coreference_resolution_lee_2017()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ' '.join(\"Natasha Romanof is the assistant of Tony Stark. Natasha doesn't like Tony. She says he's too arrogant.\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model.predict(document=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My dog has a sister . She likes him .\n",
    "0  1   2   3   4    5  6    7   8   9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_spans': [[0, 1],\n",
       "  [3, 7],\n",
       "  [6, 7],\n",
       "  [9, 9],\n",
       "  [13, 13],\n",
       "  [15, 15],\n",
       "  [16, 16],\n",
       "  [17, 17]],\n",
       " 'predicted_antecedents': [-1, -1, 1, 2, 1, 1, -1, 3],\n",
       " 'document': ['Natasha',\n",
       "  'Romanof',\n",
       "  'is',\n",
       "  'the',\n",
       "  'assistant',\n",
       "  'of',\n",
       "  'Tony',\n",
       "  'Stark',\n",
       "  '.',\n",
       "  'Natasha',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'like',\n",
       "  'Tony',\n",
       "  '.',\n",
       "  'She',\n",
       "  'says',\n",
       "  'he',\n",
       "  \"'s\",\n",
       "  'too',\n",
       "  'arrogant',\n",
       "  '.'],\n",
       " 'clusters': [[[0, 1], [6, 7], [9, 9], [13, 13], [15, 15], [17, 17]]]}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  Natasha\n",
      "1 :  Romanof\n",
      "2 :  is\n",
      "3 :  the\n",
      "4 :  assistant\n",
      "5 :  of\n",
      "6 :  Tony\n",
      "7 :  Stark\n",
      "8 :  .\n",
      "9 :  Natasha\n",
      "10 :  does\n",
      "11 :  n't\n",
      "12 :  like\n",
      "13 :  Tony\n",
      "14 :  .\n",
      "15 :  She\n",
      "16 :  says\n",
      "17 :  he\n",
      "18 :  's\n",
      "19 :  too\n",
      "20 :  arrogant\n",
      "21 :  .\n"
     ]
    }
   ],
   "source": [
    "tokens = results['document']\n",
    "for i in range(len(tokens)):\n",
    "    print(i, \": \", tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tom']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tom'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Robert', 'Downey', 'Jr.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[17:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
