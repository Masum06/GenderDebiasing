{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Gender_Encrypter_Decrypter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masum06/GenderDebiasing/blob/development2/Gender_Encrypter_Decrypter_cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILV8heUdFDpF",
        "colab_type": "text"
      },
      "source": [
        "Latest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DLRLPZ9BDqgo"
      },
      "source": [
        "https://www.researchgate.net/publication/337918817_What_You_See_Is_What_You_Learn_Mitigating_Gender_Biases_from_Natural_Language_Processing_Context_through_Gender_Encrypted_Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g17bTEJ7VCJ5"
      },
      "source": [
        "# Gender Encryption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lFctT8bvVCJ9"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RSlIksK3-BSm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fed39675-191f-4a56-9d65-a3a69d1d2d96"
      },
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7F74akq3VCJ-"
      },
      "source": [
        "https://github.com/zalandoresearch/flair\n",
        "\n",
        "https://github.com/huggingface/neuralcoref"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zvn8rO3mVCKA",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "186e4dff-cde9-4a06-dd44-769c5027453a"
      },
      "source": [
        "!pip uninstall torchvision\n",
        "!pip install torchvision==0.4.0\n",
        "!pip install flair==0.4.2\n",
        "!pip uninstall spacy --yes\n",
        "!pip install -U spacy==2.1.0\n",
        "##!python -m spacy download en # SMALL VERSION OF SPACY, FAST DOWNLOAD\n",
        "##!python -m spacy download en_core_web_md # MEDIUM VERSION OF SPACY\n",
        "!python -m spacy download en_core_web_lg # LARGE VERSION OF SPACY, SLOW DOWNLOAD\n",
        "!pip install neuralcoref --no-binary neuralcoref"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torchvision-0.7.0+cu101:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision-0.7.0+cu101.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Collecting torchvision==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/e6/a564eba563f7ff53aa7318ff6aaa5bd8385cbda39ed55ba471e95af27d19/torchvision-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (1.15.0)\n",
            "Collecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 15kB/s \n",
            "\u001b[?25hInstalling collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "Successfully installed torch-1.2.0 torchvision-0.4.0\n",
            "Collecting flair==0.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.8.7)\n",
            "Collecting pytorch-pretrained-bert>=0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.2.2)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.1.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.0)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.2.0)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.4)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (2019.12.20)\n",
            "Collecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.24.3)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.18.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.14.37)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (0.10.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (3.11.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (2.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair==0.4.2) (0.22.2.post1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (49.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (19.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (8.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.9.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.2) (1.12.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 16.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (2.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.37 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.17.37)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.2) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair==0.4.2) (0.16.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (2.49.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.37->boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.15.2)\n",
            "Building wheels for collected packages: sqlitedict, segtok, mpld3\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=b486d27b7caabc2793e2c1e2775401a312978fec34384780d441fe38fca3cdd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25020 sha256=7bf88dbde48eb5563231362b52a93e608dd7cddb8d5546aec6e2a5b19a20f5d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=b22489025c4a076c7df9de5c6a86a934229067c32ef5124d1e8057b0811ede4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "Successfully built sqlitedict segtok mpld3\n",
            "Installing collected packages: pytorch-pretrained-bert, sqlitedict, segtok, mpld3, deprecated, sentencepiece, bpemb, flair\n",
            "Successfully installed bpemb-0.3.2 deprecated-1.2.10 flair-0.4.2 mpld3-0.3 pytorch-pretrained-bert-0.6.2 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.6.0\n",
            "Uninstalling spacy-2.2.4:\n",
            "  Successfully uninstalled spacy-2.2.4\n",
            "Collecting spacy==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/39/4bde5da5f18ab0bdd525760c4fe38808b4bb03907a2aea094000d831afe1/spacy-2.1.0-cp36-cp36m-manylinux1_x86_64.whl (27.7MB)\n",
            "\u001b[K     |████████████████████████████████| 27.7MB 111kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.6.0)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.0.2)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.7MB/s \n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.0.3)\n",
            "Collecting thinc<7.1.0,>=7.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 29.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.0.12 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2020.6.20)\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: blis, preshed, plac, thinc, spacy\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: preshed 3.0.2\n",
            "    Uninstalling preshed-3.0.2:\n",
            "      Successfully uninstalled preshed-3.0.2\n",
            "  Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pZqwsmTJnEOr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1dfc929-1be8-4df3-ddf7-fc9a4d162e45"
      },
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GeForce MX150'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "03dQLWLvnEO1",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "f5456792-e53a-4865-a664-8f6089cf370e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4qlzZsMXVCKH"
      },
      "source": [
        "### Creating Language Resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2h4nHNwnVCKJ",
        "colab": {}
      },
      "source": [
        "male_pronouns   = [\"he\",  \"him\", \"his$\", \"his\", \"himself\"]\n",
        "female_pronouns = [\"she\", \"her\", \"her$\", \"hers\", \"herself\"]\n",
        "neutral_pronouns= [\"zie\", \"zim\", \"zir\", \"zis\", \"zieself\"]\n",
        "merged_pronouns = [\"he/she\", \"him/her\", \"his/her\", \"his/hers\", \"himself/herself\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sim_9aXgVCKO",
        "colab": {}
      },
      "source": [
        "gender_pronouns_dict = {}\n",
        "gender_honorific_dict = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IC4J8YREVCKV",
        "colab": {}
      },
      "source": [
        "for (g1,g2,g3,g4) in zip(male_pronouns, female_pronouns, neutral_pronouns, merged_pronouns):\n",
        "    element = {\"male\": g1.replace(\"$\",\"\"), \"female\":g2.replace(\"$\",\"\"), \"neutral\":g3, \"merged\":g4}\n",
        "    gender_pronouns_dict[g1] = gender_pronouns_dict[g2] = gender_pronouns_dict[g3] = gender_pronouns_dict[g4] =element"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QmE6CL7PVCKd",
        "colab": {}
      },
      "source": [
        "male_hons   =  [\"Mr.\", \"Mr\", \"Md.\", \"Md\", \"Sir\", \"Lord\", \"Mister\"]\n",
        "female_hons =  [\"Ms.\", \"Ms\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Miss\"]\n",
        "neutral_hons = [\"Mx.\", \"Mx\", \"Mx.\", \"Mx\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]\n",
        "married_hons = [\"Mrs.\", \"Mrs\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Mis'ess\"]\n",
        "merged_hons =  [\"Mr./Ms.\", \"Mr/Ms\", \"Md./Mst.\", \"Md/Mst\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbb4Jf6mVCKk",
        "colab": {}
      },
      "source": [
        "for (h1,h2,h3,h4,h5) in zip(male_hons, female_hons, neutral_hons, married_hons, merged_hons):\n",
        "    element = {\"male\": h1, \"female\":h2, \"neutral\":h3, \"married_fem\":h4, \"merged\":h5}\n",
        "    gender_honorific_dict[h1] = gender_honorific_dict[h2] = gender_honorific_dict[h3] = \\\n",
        "    gender_honorific_dict[h4] = gender_honorific_dict[h5] = element"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TzgZxsSUVCKq"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5yTkWcUAYH7n",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZN82xZJgVCKr",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "#from segtok.segmenter import split_single"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MoC0zGDKggFj",
        "colab": {}
      },
      "source": [
        "import flair\n",
        "assert flair.__version__=='0.4.2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kKRKCr8uVCKv",
        "scrolled": true,
        "colab": {},
        "outputId": "44386a2a-5325-460c-97d7-1bbd82321fb7"
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Be8BR8KQVCKz",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import neuralcoref"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G9u1EvUfpr34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "709d0e83-ae6f-42bd-ce66-a46248a9ab08"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8-VH-28OqMGc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6ff2593-0d91-4682-a725-84d144a9ff7d"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nZuAm9_9VCK5"
      },
      "source": [
        "### Loading Essentials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UI8M4VyXVDV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "bf9f0111-c7e3-4bd3-ab29-6052951db4e8"
      },
      "source": [
        "!git clone --single-branch --branch development2 https://github.com/Masum06/GenderDebiasing.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GenderDebiasing'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 147 (delta 10), reused 6 (delta 2), pack-reused 127\u001b[K\n",
            "Receiving objects: 100% (147/147), 43.25 MiB | 9.31 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n",
            "Checking out files: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nA8Mt85PUHJy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef655e46-a779-4d17-993b-30eef86b2bd4"
      },
      "source": [
        "cd GenderDebiasing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F:\\GDrive RA\\Thesis\\GenderDebiasing2\\GenderDebiasing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBbM5JOdEx0C",
        "colab_type": "code",
        "colab": {},
        "outputId": "999a0dea-4fa9-474d-d54a-17be5e643bd6"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F:\\GDrive RA\\Thesis\\GenderDebiasing2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mjlMu-sNVCK6",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "char2idx = 'resources/char2idx.json'\n",
        "idx2char = 'resources/idx2char.json'\n",
        "with open(char2idx, 'r') as fp:\n",
        "    char2idx = json.load(fp)\n",
        "    \n",
        "with open(idx2char, 'r') as fp:\n",
        "    idx2char = json.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h0BOOa4fVCK-",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "0909c5c3-1266-44dc-9fd3-611e986907cd"
      },
      "source": [
        "model_name = 'resources/char_rnn_hsc_model_0.h5'\n",
        "model = load_model(model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-08 19:21:29,071 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "2020-06-08 19:21:29,128 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "2020-06-08 19:21:29,150 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "2020-06-08 19:21:29,324 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "2020-06-08 19:21:29,332 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2020-06-08 19:21:29,655 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "2020-06-08 19:21:29,849 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "2020-06-08 19:21:29,858 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ggCw99GvVCLC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "620c3b79-d0da-4ad0-ed7e-1df739f831f6"
      },
      "source": [
        "#nlp = spacy.load('en_core_web_lg') # en_core_web_sm #en_core_web_md\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()\n",
        "neuralcoref.add_to_pipe(nlp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x25a8d8da438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eP7eFWBaVCLH",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "c6df7a78-7800-4370-ae50-be0b63640cf9"
      },
      "source": [
        "tagger_ner = SequenceTagger.load('ner')\n",
        "tagger_pos = SequenceTagger.load('pos')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-08 19:21:47,202 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n",
            "2020-06-08 19:22:01,368 loading file C:\\Users\\Hp\\.flair\\models\\en-pos-ontonotes-v0.2.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tyHJZ4t-VCLL"
      },
      "source": [
        "### Necessary Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T2FRQ-qzEzDF"
      },
      "source": [
        "Name2Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UExr_6fiVCLM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "# Converts a name into vector\n",
        "def name2vectorTest(name):\n",
        "    name = name.lower()\n",
        "    new_name = \"\"\n",
        "    for char in name:\n",
        "      if char in char2idx:\n",
        "        new_name += char\n",
        "    chars = list(new_name)\n",
        "    vector = [ char2idx[c] for c in chars ]\n",
        "    return np.array(vector)\n",
        "\n",
        "# Converts names to fixed size tensor\n",
        "def names2tensorTest(names, maxlen=25):\n",
        "    namelist = [name2vectorTest(name) for name in names]\n",
        "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
        "\n",
        "def name2gender(name):\n",
        "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
        "  if result:\n",
        "    return \"male\"\n",
        "  else:\n",
        "    return \"female\"\n",
        "  \n",
        "def isMale(name):\n",
        "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nXxZYr_mflVz"
      },
      "source": [
        "Storing Names in Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VJzj_UF_VCMX",
        "colab": {}
      },
      "source": [
        "def store(name, name_found, Name2Key, Key2Name, num_keys): \n",
        "    \n",
        "    if name_found not in Name2Key:\n",
        "        #global num_keys\n",
        "        num_keys+=1\n",
        "        key = \"PER_\"+str(num_keys)\n",
        "        #gender = name2gender(name_found)\n",
        "        alias = None\n",
        "        element = {\"name\": name, \"key\": key, \"gender\":None, \"alias\":alias, \"is_alias\": False, \"alias_to\": None}\n",
        "        Name2Key[name_found] = element\n",
        "        Key2Name[key] = {\"name\": name, \"gender\": None, \"alias\": alias}\n",
        "    \n",
        "    if name not in Name2Key:\n",
        "        element_alias = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
        "        Name2Key[name] = element_alias\n",
        "        Name2Key[name_found][\"alias\"] = name\n",
        "        \n",
        "    return Name2Key[name_found][\"key\"], num_keys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HSYCQfJcOTLU"
      },
      "source": [
        "# Unit Gender Encryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LJLCTIOQOYav",
        "colab": {}
      },
      "source": [
        "def gender_encrypt(s):\n",
        "  s = ' '.join(s.split())\n",
        "  doc = nlp(s)\n",
        "  tokenized_text = ' '.join([token.text for token in doc])\n",
        "  oracle = []\n",
        "  coref2name = {}\n",
        "\n",
        "  # POS TAG\n",
        "  sent = Sentence(tokenized_text)\n",
        "  tagger_ner.predict(sent)\n",
        "  tagger_pos.predict(sent)\n",
        "  tagged_list = sent.to_tagged_string().split()\n",
        "  tokens_pos = []\n",
        "  pos = []\n",
        "  count = 0\n",
        "  for i in range(0,len(tagged_list),2):\n",
        "      tokens_pos.append(tagged_list[i])\n",
        "      count = count+1\n",
        "      pos.append(tagged_list[i+1])\n",
        "      \n",
        "      if tagged_list[i].lower() in male_pronouns+female_pronouns:\n",
        "          oracle.append(2)\n",
        "      elif tagged_list[i+1] in ['<B-PER/NNP>', '<I-PER/NNP>', '<E-PER/NNP>', '<S-PER/NNP>']:\n",
        "          oracle.append(4)\n",
        "      else:\n",
        "          oracle.append(0)\n",
        "\n",
        "  # COREFERENCE RESOLUTION \n",
        "  if len(doc)!=len(tokens_pos):\n",
        "    tokens_doc = [token.text for token in doc]\n",
        "    print(\"doc:\", tokens_doc)\n",
        "    print(\"pos:\", tokens_pos)\n",
        "    return None, None\n",
        "  \n",
        "  coref_stack = []\n",
        "  name_stack = []\n",
        "  for i in range(len(doc)):\n",
        "      token = doc[i]\n",
        "      if token._.in_coref:\n",
        "          coref_stack.append(tokens_pos[i])\n",
        "          if oracle[i] == 4:\n",
        "              name_stack.append(tokens_pos[i])\n",
        "          oracle[i] += 1\n",
        "      else:\n",
        "          if len(name_stack) > 0:\n",
        "              name = ' '.join(name_stack)\n",
        "              coref = ' '.join(coref_stack)\n",
        "              #name2coref[name] = coref\n",
        "              coref2name[coref] = name\n",
        "              name_stack.clear()\n",
        "          coref_stack.clear()\n",
        "\n",
        "  # IF THE SENTENCE DOES NOT END WITH A PERIOD OR SPECIAL CHARACTER\n",
        "  if len(name_stack) > 0:\n",
        "      name = ' '.join(name_stack)\n",
        "      name2coref[name] = ' '.join(coref_stack)\n",
        "      name_stack.clear()\n",
        "  coref_stack.clear()\n",
        "\n",
        "  Name2Key = {}\n",
        "  Key2Name = {}\n",
        "  encrypted = []\n",
        "  num_keys = 0\n",
        "  i = 0\n",
        "  while i<len(tokens_pos): \n",
        "      #print(\"Oracle \", i, tokens_pos[i])\n",
        "      if oracle[i] == 2:\n",
        "          pronoun = tokens_pos[i].lower()\n",
        "          if pos[i] == '<PRP$>':\n",
        "              pronoun+=\"$\"\n",
        "          encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "      elif oracle[i] == 3:\n",
        "          coref = doc[i]._.coref_clusters[0][0].text\n",
        "          pronoun = tokens_pos[i].lower()\n",
        "          if pos[i] == '<PRP$>':\n",
        "              pronoun+=\"$\"\n",
        "          if coref in coref2name:\n",
        "            name_found = coref2name[coref]\n",
        "            key = Name2Key[name_found][\"key\"]\n",
        "            if pronoun in male_pronouns:\n",
        "              Name2Key[name_found][\"gender\"] = \"male\"\n",
        "            elif pronoun in female_pronouns:\n",
        "              Name2Key[name_found][\"gender\"] = \"female\"\n",
        "            else:\n",
        "              Name2Key[name_found][\"gender\"] = \"<|unk|>\"\n",
        "            encrypted.append(\"<|coref|>\")\n",
        "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "            encrypted.append(key)\n",
        "          else:\n",
        "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "          \n",
        "      elif oracle[i] in [4,5]:\n",
        "          if i > 0 and tokens_pos[i-1] in gender_honorific_dict:\n",
        "            hons = encrypted.pop()\n",
        "            if hons in male_hons:\n",
        "              gender = \"male\"\n",
        "            elif hons in female_hons+married_hons:\n",
        "              gender = \"female\"\n",
        "            else:\n",
        "              gender = \"<|unk|>\"\n",
        "            encrypted.append(\"<|hons|>\")\n",
        "            encrypted.append(gender_honorific_dict[hons][\"merged\"])\n",
        "          if pos[i] == '<S-PER/NNP>':\n",
        "              name = tokens_pos[i]\n",
        "          elif pos[i] == '<B-PER/NNP>':\n",
        "              name = \"\"\n",
        "              while True:\n",
        "                  #print(i, oracle[i])\n",
        "                  name += tokens_pos[i]\n",
        "                  if pos[i] == '<E-PER/NNP>':\n",
        "                      break\n",
        "                  name += \" \"\n",
        "                  i+=1\n",
        "          \n",
        "          if oracle[i] == 4:\n",
        "              key, num_keys = store(name, name, Name2Key, Key2Name, num_keys)\n",
        "              encrypted.append(key)\n",
        "          else:\n",
        "              coref = doc[i]._.coref_clusters[0][0].text\n",
        "              name_found = coref2name[coref]\n",
        "              if name == name_found:\n",
        "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                  encrypted.append(key)\n",
        "              else:\n",
        "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                  encrypted.append(\"<|alias|>\")\n",
        "                  encrypted.append(key)\n",
        "          Name2Key[key][\"gender\"] = gender\n",
        "      else:\n",
        "        encrypted.append(tokens_pos[i])\n",
        "      i+=1\n",
        "      \n",
        "  encrypted_text = ' '.join(encrypted)\n",
        "\n",
        "  return tokenized_text, Key2Name, encrypted_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bMItOjUbUQNf"
      },
      "source": [
        "# Gender Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "quTM_EeiVCMu",
        "colab": {}
      },
      "source": [
        "def gender_decrypt(encrypted_text, Key2Name):\n",
        "  encrypted = encrypted_text.split()\n",
        "  decrypted = []\n",
        "  i = 0\n",
        "  while i != len(encrypted):\n",
        "    token = encrypted[i]\n",
        "    if token in Key2Name:\n",
        "      decrypted.append(Key2Name[token][\"name\"])\n",
        "    elif token == '<|alias|>':\n",
        "      i+=1\n",
        "      key = encrypted[i]\n",
        "      if Key2Name[key][\"alias\"]:\n",
        "        decrypted.append(Key2Name[key][\"alias\"])\n",
        "      else:\n",
        "        decrypted.append(Key2Name[key][\"name\"])\n",
        "    elif token == '<|coref|>':\n",
        "      startOfSent = (i==0 or encrypted[i-1] == \".\")\n",
        "      pronoun =  encrypted[i+1]\n",
        "      key = encrypted[i+2]\n",
        "      gender = Key2Name[key][\"gender\"].lower()\n",
        "      decrypted_pronoun = gender_pronouns_dict[pronoun][gender]\n",
        "      decrypted_pronoun = decrypted_pronoun[0].upper()+decrypted_pronoun[1:] if startOfSent else decrypted_pronoun\n",
        "      decrypted.append(decrypted_pronoun)\n",
        "      i+=2\n",
        "    elif token == \"<|hons|>\":\n",
        "      hons = encrypted[i+1]\n",
        "      key = encrypted[i+2] # NEED CHECK FOR HONS IN ALIAS\n",
        "      gender = Key2Name[key][\"gender\"].lower()\n",
        "      decrypted.append(gender_honorific_dict[hons][gender])\n",
        "      i+=1\n",
        "    elif token == \"he/she\":\n",
        "        if i==0 or encrypted[i-1] == \".\":\n",
        "            decrypted.append(\"He/She\")\n",
        "        else:\n",
        "            decrypted.append(\"he/she\")\n",
        "    else:\n",
        "      decrypted.append(token)\n",
        "    i+=1\n",
        "\n",
        "  decrypted_text = ' '.join(decrypted)\n",
        "  #decrypted_text = decrypted_text.replace(\" .\", \".\")\n",
        "  return decrypted_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qv5Y4nngq9AJ",
        "colab": {}
      },
      "source": [
        "key2name_changed = {'PER_1': {'name': 'Abira',\n",
        "    'key': 'PER_1',\n",
        "    'gender': 'Female',\n",
        "    'alias': None,\n",
        "    'is_alias': False,\n",
        "    'alias_to': None},\n",
        "  'PER_2': {'name': 'Shibir',\n",
        "    'key': 'PER_2',\n",
        "    'gender': 'Male',\n",
        "    'alias': None,\n",
        "    'is_alias': False,\n",
        "    'alias_to': None}\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M_Ad5ljDRvvB"
      },
      "source": [
        "### Testing Encryption-Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jDUandyxxJ8m",
        "colab": {}
      },
      "source": [
        "s = \"Mr. John is not a doctor. Ms. Katy is also not a nurse. John can fly, but she cannot swim.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJnQwJd5S_GJ",
        "colab": {}
      },
      "source": [
        "s = \"Morshed Khan told newsmen that 'BNP is a massive party with huge popularity and public acceptance.' This party is now running its operations over Skype. He (Tarique) is operating from London over Skype and that too with only selected leaders. It has turned into the ‘Bangladesh Nationalist Skype Party’. This is painful. I believe the next generation must assume leadership within the party — that would be my recommendation.”\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2WL1lFCFnEQF",
        "colab": {}
      },
      "source": [
        "s = \"Dineshwar then left behind his wife’s stabbed body and hanged himself from a tree in a field nearby.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YsmaikFZFHtl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d647507-2da3-47de-ca79-d97d8e59ab6b"
      },
      "source": [
        "len(s.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5qLWPn4lR1Ss",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "5c9967f9-7821-43b8-dc7f-ec6506c51a45"
      },
      "source": [
        "import time \n",
        "start = time.time()\n",
        "text, key2name, encrypted = gender_encrypt(s)\n",
        "end = time.time()\n",
        "\n",
        "print(encrypted)\n",
        "print(key2name)\n",
        "print(end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'gender' referenced before assignment",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-31-e69b56627845>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey2name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencrypted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgender_encrypt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-24-6119f497c355>\u001b[0m in \u001b[0;36mgender_encrypt\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    126\u001b[0m                   \u001b[0mencrypted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<|alias|>\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                   \u001b[0mencrypted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m           \u001b[0mName2Key\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"gender\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgender\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mencrypted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'gender' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XB-PJPr7lIuJ",
        "colab": {}
      },
      "source": [
        "key2name = {'PER_1': {'name': 'Dineshwar', 'gender': 'merged', 'alias': None}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eeSiLybyVCMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1ea4a950-3955-453a-9554-fa0b59daaaf2"
      },
      "source": [
        "decrypted = gender_decrypt(encrypted, key2name)\n",
        "decrypted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dineshwar then left behind his/her wife ’s stabbed body and hanged himself/herself from a tree in a field nearby .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z2DGAAsDT6HN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "948fe8a6-356f-4deb-c72d-7758be9e6431"
      },
      "source": [
        "decrypted == text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PKBfFmbYvtad",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "33c9a311-0b5e-49f9-86ee-212928bbeff8"
      },
      "source": [
        "en = gender_encrypt(\"Mr Masum Hasan is not a doctor. Masum is an engineer.\")\n",
        "en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gender_encrypt' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-3cf708c253ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0men\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgender_encrypt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mr Masum Hasan is not a doctor. Masum is an engineer.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0men\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'gender_encrypt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7-uNtEcNaJQt",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}