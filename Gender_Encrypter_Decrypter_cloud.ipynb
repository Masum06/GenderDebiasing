{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender_Encrypter_Decrypter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masum06/GenderDebiasing/blob/development/Gender_Encrypter_Decrypter_cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLRLPZ9BDqgo",
        "colab_type": "text"
      },
      "source": [
        "https://www.researchgate.net/publication/337918817_What_You_See_Is_What_You_Learn_Mitigating_Gender_Biases_from_Natural_Language_Processing_Context_through_Gender_Encrypted_Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g17bTEJ7VCJ5"
      },
      "source": [
        "# Gender Encryption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lFctT8bvVCJ9"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RSlIksK3-BSm",
        "outputId": "a637b53d-ee37-4ca6-8d43-64f5b77d08c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3uubDldnEOO",
        "colab_type": "code",
        "outputId": "3bd2f846-7f7c-4765-e390-eea1dc5438cc",
        "colab": {}
      },
      "source": [
        "!conda info --envs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\r\n",
            "#\r\n",
            "base                  *  /home/youngladesh/anaconda3\r\n",
            "gender                   /home/youngladesh/anaconda3/envs/gender\r\n",
            "gender-bias              /home/youngladesh/anaconda3/envs/gender-bias\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "puJwG-ymnEOS",
        "colab_type": "code",
        "outputId": "86f46174-076d-435d-b846-e47976ec854e",
        "colab": {}
      },
      "source": [
        "!source activate gender"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/sh: 1: source: not found\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7F74akq3VCJ-"
      },
      "source": [
        "https://github.com/zalandoresearch/flair\n",
        "\n",
        "https://github.com/huggingface/neuralcoref"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zvn8rO3mVCKA",
        "outputId": "201e58e4-725a-435a-8c99-5ef3a3006b4f",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!pip install flair==0.4.2\n",
        "#!pip uninstall spacy\n",
        "#!pip install -U spacy==2.1.0\n",
        "##!python -m spacy download en # SMALL VERSION OF SPACY, FAST DOWNLOAD\n",
        "##!python -m spacy download en_core_web_md # MEDIUM VERSION OF SPACY\n",
        "#!python -m spacy download en_core_web_lg # LARGE VERSION OF SPACY, SLOW DOWNLOAD\n",
        "!pip install neuralcoref --no-binary neuralcoref\n",
        "#!pip3 install keras==2.2.4\n",
        "#!conda install -c conda-forge tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting neuralcoref\n",
            "  Using cached https://files.pythonhosted.org/packages/0c/40/8db3db763077fe80b71859f57731261aeb03cc624635f97a3bcfe55ab37b/neuralcoref-4.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.15.0 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from neuralcoref) (1.17.4)\n",
            "Requirement already satisfied: boto3 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from neuralcoref) (1.10.16)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from neuralcoref) (2.22.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from neuralcoref) (2.1.0)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from boto3->neuralcoref) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from boto3->neuralcoref) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.16 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from boto3->neuralcoref) (1.13.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2019.9.11)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref) (2.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.0.12 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref) (0.4.0)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from spacy>=2.1.0->neuralcoref) (0.2.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.16->boto3->neuralcoref) (0.15.2)\n",
            "Collecting python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"\n",
            "  Using cached https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.38.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.16->boto3->neuralcoref) (1.13.0)\n",
            "Skipping wheel build for neuralcoref, due to binaries being disabled for it.\n",
            "Installing collected packages: neuralcoref, python-dateutil\n",
            "    Running setup.py install for neuralcoref ... \u001b[?25ldone\n",
            "\u001b[?25h  Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "Successfully installed neuralcoref-4.0 python-dateutil-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AVAkHQ1-nEOY",
        "colab_type": "code",
        "outputId": "a18a9b1a-b44e-412a-a94f-52deb4b7f57f",
        "colab": {}
      },
      "source": [
        "!conda uninstall tensorflow --yes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /home/youngladesh/anaconda3/envs/gender\n",
            "\n",
            "  removed specs:\n",
            "    - tensorflow\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _anaconda_depends-2019.03  |           py36_0           5 KB\n",
            "    libgfortran-ng-7.3.0       |       hdf63c60_0         1.3 MB\n",
            "    libpng-1.6.37              |       hbc83047_0         364 KB\n",
            "    libssh2-1.8.2              |       h1ba5d50_0         250 KB\n",
            "    mkl_fft-1.0.15             |   py36ha843d7b_0         173 KB\n",
            "    mkl_random-1.1.0           |   py36hd6b4f25_0         369 KB\n",
            "    mock-3.0.5                 |           py36_0          47 KB\n",
            "    numexpr-2.7.0              |   py36h9e4a6bb_0         196 KB\n",
            "    numpy-1.17.3               |   py36hd14ec0e_0           4 KB\n",
            "    numpy-base-1.17.3          |   py36hde5b4d6_0         5.3 MB\n",
            "    scikit-learn-0.21.3        |   py36hd81dba3_0         6.8 MB\n",
            "    scipy-1.3.1                |   py36h7c811a0_0        18.1 MB\n",
            "    six-1.13.0                 |           py36_0          27 KB\n",
            "    werkzeug-0.16.0            |             py_0         255 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        33.1 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.0.15-py36ha843d7b_0\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.0-py36hd6b4f25_0\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.17.3-py36hde5b4d6_0\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  _tflow_select-2.1.0-gpu\n",
            "  absl-py-0.8.1-py36_0\n",
            "  astor-0.7.1-py_0\n",
            "  blaze-0.11.3-py36_0\n",
            "  c-ares-1.15.0-h516909a_1001\n",
            "  datashape-0.5.4-py36_1\n",
            "  filelock-3.0.12-py_0\n",
            "  flask-cors-3.0.8-py_0\n",
            "  gast-0.3.2-py_0\n",
            "  glob2-0.7-py_0\n",
            "  grpcio-1.23.0-py36he9ae1f9_0\n",
            "  jupyterlab_launcher-0.13.1-py36_0\n",
            "  keras-2.2.4-0\n",
            "  keras-applications-1.0.8-py_1\n",
            "  keras-base-2.2.4-py36_0\n",
            "  keras-preprocessing-1.1.0-py_0\n",
            "  libblas-3.8.0-14_openblas\n",
            "  libcblas-3.8.0-14_openblas\n",
            "  liblapack-3.8.0-14_openblas\n",
            "  libopenblas-0.3.7-h6e990d7_3\n",
            "  libprotobuf-3.10.1-h8b12597_0\n",
            "  markdown-3.1.1-py_0\n",
            "  odo-0.5.1-py36_0\n",
            "  patchelf-0.9-he6710b0_3\n",
            "  pkginfo-1.5.0.1-py36_0\n",
            "  protobuf-3.10.1-py36he1b5a44_0\n",
            "  tensorboard-1.13.1-py36_0\n",
            "  tensorflow-1.13.1-h76b4ce7_7\n",
            "  tensorflow-base-1.13.1-py36h76b4ce7_7\n",
            "  tensorflow-estimator-1.13.0-py_0\n",
            "  tensorflow-gpu-1.13.1-h0d30ee6_0\n",
            "  termcolor-1.1.0-py_2\n",
            "  typing-3.6.4-py36_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  _anaconda_depends                            5.1.0-py36_2 --> 2019.03-py36_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  libgfortran-ng     conda-forge::libgfortran-ng-7.3.0-hdf~ --> pkgs/main::libgfortran-ng-7.3.0-hdf63c60_0\n",
            "  libpng              conda-forge::libpng-1.6.37-hed695b0_0 --> pkgs/main::libpng-1.6.37-hbc83047_0\n",
            "  libssh2             conda-forge::libssh2-1.8.2-h22169c7_2 --> pkgs/main::libssh2-1.8.2-h1ba5d50_0\n",
            "  mock                                          conda-forge --> pkgs/main\n",
            "  numpy              conda-forge::numpy-1.17.3-py36h95a140~ --> pkgs/main::numpy-1.17.3-py36hd14ec0e_0\n",
            "  scipy              conda-forge::scipy-1.3.2-py36h921218d~ --> pkgs/main::scipy-1.3.1-py36h7c811a0_0\n",
            "  six                                           conda-forge --> pkgs/main\n",
            "  werkzeug                                      conda-forge --> pkgs/main\n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  blas                                         1.0-openblas --> 1.0-mkl\n",
            "  numexpr                              2.7.0-py36h2ffa06c_0 --> 2.7.0-py36h9e4a6bb_0\n",
            "  scikit-learn                        0.21.3-py36h22eb022_0 --> 0.21.3-py36hd81dba3_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "_anaconda_depends-20 | 5 KB      | ##################################### | 100% \n",
            "libpng-1.6.37        | 364 KB    | ##################################### | 100% \n",
            "libgfortran-ng-7.3.0 | 1.3 MB    | ##################################### | 100% \n",
            "werkzeug-0.16.0      | 255 KB    | ##################################### | 100% \n",
            "numpy-base-1.17.3    | 5.3 MB    | ##################################### | 100% \n",
            "scikit-learn-0.21.3  | 6.8 MB    | ##################################### | 100% \n",
            "mkl_fft-1.0.15       | 173 KB    | ##################################### | 100% \n",
            "six-1.13.0           | 27 KB     | ##################################### | 100% \n",
            "libssh2-1.8.2        | 250 KB    | ##################################### | 100% \n",
            "scipy-1.3.1          | 18.1 MB   | ##################################### | 100% \n",
            "mkl_random-1.1.0     | 369 KB    | ##################################### | 100% \n",
            "numexpr-2.7.0        | 196 KB    | ##################################### | 100% \n",
            "numpy-1.17.3         | 4 KB      | ##################################### | 100% \n",
            "mock-3.0.5           | 47 KB     | ##################################### | 100% \n",
            "Preparing transaction: done\n",
            "Verifying transaction: done\n",
            "Executing transaction: done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dBNGIakZnEOb",
        "colab_type": "code",
        "outputId": "2b7614d4-3849-4876-afaa-2a19bdb9410c",
        "colab": {}
      },
      "source": [
        "!conda install tensorflow-gpu anaconda --yes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /home/youngladesh/anaconda3/envs/gender\n",
            "\n",
            "  added / updated specs:\n",
            "    - anaconda\n",
            "    - tensorflow-gpu\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    c-ares-1.15.0              |    h7b6447c_1001         102 KB\n",
            "    cudatoolkit-10.0.130       |                0       380.0 MB\n",
            "    cudnn-7.6.4                |       cuda10.0_0       226.6 MB\n",
            "    cupti-10.0.130             |                0         1.8 MB\n",
            "    gast-0.2.2                 |           py36_0         138 KB\n",
            "    google-pasta-0.1.7         |             py_0          41 KB\n",
            "    grpcio-1.16.1              |   py36hf8bcb03_1         1.1 MB\n",
            "    keras-applications-1.0.8   |             py_0          33 KB\n",
            "    keras-preprocessing-1.1.0  |             py_1          36 KB\n",
            "    libprotobuf-3.9.2          |       hd408876_0         4.7 MB\n",
            "    opt_einsum-3.1.0           |             py_0          54 KB\n",
            "    protobuf-3.9.2             |   py36he6710b0_0         701 KB\n",
            "    tensorboard-2.0.0          |     pyhb230dea_0         3.3 MB\n",
            "    tensorflow-2.0.0           |gpu_py36h6b29c10_0           3 KB\n",
            "    tensorflow-base-2.0.0      |gpu_py36h0ec5d1f_0       329.9 MB\n",
            "    tensorflow-estimator-2.0.0 |     pyh2649769_0         272 KB\n",
            "    tensorflow-gpu-2.0.0       |       h0d30ee6_0           2 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       948.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _tflow_select      pkgs/main/linux-64::_tflow_select-2.1.0-gpu\n",
            "  absl-py            pkgs/main/linux-64::absl-py-0.8.1-py36_0\n",
            "  astor              pkgs/main/linux-64::astor-0.8.0-py36_0\n",
            "  c-ares             pkgs/main/linux-64::c-ares-1.15.0-h7b6447c_1001\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0\n",
            "  cudnn              pkgs/main/linux-64::cudnn-7.6.4-cuda10.0_0\n",
            "  cupti              pkgs/main/linux-64::cupti-10.0.130-0\n",
            "  gast               pkgs/main/linux-64::gast-0.2.2-py36_0\n",
            "  google-pasta       pkgs/main/noarch::google-pasta-0.1.7-py_0\n",
            "  grpcio             pkgs/main/linux-64::grpcio-1.16.1-py36hf8bcb03_1\n",
            "  keras-applications pkgs/main/noarch::keras-applications-1.0.8-py_0\n",
            "  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.1.0-py_1\n",
            "  libprotobuf        pkgs/main/linux-64::libprotobuf-3.9.2-hd408876_0\n",
            "  markdown           pkgs/main/linux-64::markdown-3.1.1-py36_0\n",
            "  opt_einsum         pkgs/main/noarch::opt_einsum-3.1.0-py_0\n",
            "  protobuf           pkgs/main/linux-64::protobuf-3.9.2-py36he6710b0_0\n",
            "  tensorboard        pkgs/main/noarch::tensorboard-2.0.0-pyhb230dea_0\n",
            "  tensorflow         pkgs/main/linux-64::tensorflow-2.0.0-gpu_py36h6b29c10_0\n",
            "  tensorflow-base    pkgs/main/linux-64::tensorflow-base-2.0.0-gpu_py36h0ec5d1f_0\n",
            "  tensorflow-estima~ pkgs/main/noarch::tensorflow-estimator-2.0.0-pyh2649769_0\n",
            "  tensorflow-gpu     pkgs/main/linux-64::tensorflow-gpu-2.0.0-h0d30ee6_0\n",
            "  termcolor          pkgs/main/linux-64::termcolor-1.1.0-py36_1\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "tensorflow-2.0.0     | 3 KB      | ##################################### | 100% \n",
            "protobuf-3.9.2       | 701 KB    | ##################################### | 100% \n",
            "cudnn-7.6.4          | 226.6 MB  | ##################################### | 100% \n",
            "c-ares-1.15.0        | 102 KB    | ##################################### | 100% \n",
            "tensorflow-gpu-2.0.0 | 2 KB      | ##################################### | 100% \n",
            "cudatoolkit-10.0.130 | 380.0 MB  | ##################################### | 100% \n",
            "tensorboard-2.0.0    | 3.3 MB    | ##################################### | 100% \n",
            "libprotobuf-3.9.2    | 4.7 MB    | ##################################### | 100% \n",
            "opt_einsum-3.1.0     | 54 KB     | ##################################### | 100% \n",
            "tensorflow-base-2.0. | 329.9 MB  | ##################################### | 100% \n",
            "google-pasta-0.1.7   | 41 KB     | ##################################### | 100% \n",
            "cupti-10.0.130       | 1.8 MB    | ##################################### | 100% \n",
            "keras-applications-1 | 33 KB     | ##################################### | 100% \n",
            "tensorflow-estimator | 272 KB    | ##################################### | 100% \n",
            "grpcio-1.16.1        | 1.1 MB    | ##################################### | 100% \n",
            "keras-preprocessing- | 36 KB     | ##################################### | 100% \n",
            "gast-0.2.2           | 138 KB    | ##################################### | 100% \n",
            "\n",
            "[Errno 28] No space left on device\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ylKonOmZnEOe",
        "colab_type": "code",
        "outputId": "1134ae71-c162-478e-f255-82cb166cffdc",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 1239171637785232128\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 3251233564002557406\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 11514097771491512103\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZH0jJqBnEOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "assert 'GPU' in str(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNQ9YRlMnEOk",
        "colab_type": "code",
        "outputId": "80908e7b-f2b7-4fbf-eb6e-49df0ae644ba",
        "colab": {}
      },
      "source": [
        "from keras import backend\n",
        "assert len(backend.tensorflow_backend._get_available_gpus()) > 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3692276c0c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "N31wqboEnEOm",
        "colab_type": "code",
        "outputId": "bc928604-ce43-4fab-867a-b19e5e9291d9",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "9nwuXXzgnEOo",
        "colab_type": "code",
        "outputId": "0da6965e-ee2a-479f-ed31-65d7ec9c8089",
        "colab": {}
      },
      "source": [
        "!conda install -c pytorch pytorch --yes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /home/youngladesh/anaconda3/envs/gender-bias\n",
            "\n",
            "  added / updated specs:\n",
            "    - pytorch\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cudatoolkit-10.1.243       |       h6bb024c_0       513.2 MB\n",
            "    pytorch-1.3.1              |py3.6_cuda10.1.243_cudnn7.6.3_0       428.0 MB  pytorch\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       941.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
            "  cffi               pkgs/main/linux-64::cffi-1.13.1-py36h2e261b9_0\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.1.243-h6bb024c_0\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2019.4-243\n",
            "  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-7.3.0-hdf63c60_0\n",
            "  mkl                pkgs/main/linux-64::mkl-2019.4-243\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py36he904b0f_0\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.0.15-py36ha843d7b_0\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.0-py36hd6b4f25_0\n",
            "  ninja              pkgs/main/linux-64::ninja-1.9.0-py36hfd86e86_0\n",
            "  numpy              pkgs/main/linux-64::numpy-1.17.3-py36hd14ec0e_0\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.17.3-py36hde5b4d6_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py36_0\n",
            "  pytorch            pytorch/linux-64::pytorch-1.3.1-py3.6_cuda10.1.243_cudnn7.6.3_0\n",
            "  six                pkgs/main/linux-64::six-1.13.0-py36_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "cudatoolkit-10.1.243 | 513.2 MB  | ##################################### | 100% \n",
            "pytorch-1.3.1        | 428.0 MB  | ##################################### | 100% \n",
            "Preparing transaction: done\n",
            "Verifying transaction: done\n",
            "Executing transaction: done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZqwsmTJnEOr",
        "colab_type": "code",
        "outputId": "c91e69de-1ba3-45b8-d9dc-1805957ed397",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "B4-CTsz_nEOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "mjMUaCCRnEOx",
        "colab_type": "code",
        "outputId": "17ba2d8b-881c-41db-b6d4-b8f87a12978f",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 9139571820873407865\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 8400240869127024231\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 1183154943105151776\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "03dQLWLvnEO1",
        "colab_type": "code",
        "outputId": "d60b6958-4846-4344-9191-4cc640d9ec48",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Nov 13 12:53:53 2019       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   73C    P0    73W / 149W |     85MiB / 11441MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|    0      1797      G   /usr/lib/xorg/Xorg                            15MiB |\r\n",
            "|    0     16228      C   ...h/anaconda3/envs/gender-bias/bin/python    58MiB |\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msY_UWwznEO3",
        "colab_type": "code",
        "outputId": "3021b094-f664-428f-ab62-4c6b9544aa11",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow --yes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.13.1:\n",
            "  Successfully uninstalled tensorflow-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eqJQ0KEknEO5",
        "colab_type": "code",
        "outputId": "bf20aad8-f27f-455b-e48b-4e6280fc41c1",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 22kB/s s eta 0:00:01     |██████████                      | 119.8MB 56.2MB/s eta 0:00:05\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorflow-gpu) (1.17.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorflow-gpu) (1.1.0)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.6MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 39.5MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorflow-gpu) (3.10.1)\n",
            "Collecting google-pasta>=0.1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.8MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 53.8MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorflow-gpu) (1.23.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorflow-gpu) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorflow-gpu) (1.13.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (41.6.0.post20191030)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/81/d1e7d9974ba7c886f6d133a8baae18cb8d92b2d09bcc4f46328306825de0/google_auth-1.7.0-py2.py3-none-any.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.9MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.9.0)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.2MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting cachetools<3.2,>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
            "Collecting rsa<4.1,>=3.1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/71/8f0d444e3a74e5640a3d5d967c1c6b015da9c655f35b2d308a55d907a517/pyasn1-0.4.7-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.0MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 47.7MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.22.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/youngladesh/anaconda3/envs/gender/lib/python3.6/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.9.11)\n",
            "Building wheels for collected packages: opt-einsum, gast\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-cp36-none-any.whl size=61682 sha256=d7844ed56ef106aa3004d67bbce0fc9aaf952c926da9159a7999c42c6bacb36a\n",
            "  Stored in directory: /home/youngladesh/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=e1336921c8aed8e4e5e8f169ab6432d037a8916dfdbd0cc202c07e0b5c4b55fa\n",
            "  Stored in directory: /home/youngladesh/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built opt-einsum gast\n",
            "\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.23.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opt-einsum, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, google-pasta, tensorflow-estimator, gast, tensorflow-gpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Found existing installation: tensorboard 1.13.1\n",
            "    Uninstalling tensorboard-1.13.1:\n",
            "      Successfully uninstalled tensorboard-1.13.1\n",
            "  Found existing installation: tensorflow-estimator 1.13.0\n",
            "    Uninstalling tensorflow-estimator-1.13.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.13.0\n",
            "  Found existing installation: gast 0.3.2\n",
            "    Uninstalling gast-0.3.2:\n",
            "      Successfully uninstalled gast-0.3.2\n",
            "Successfully installed cachetools-3.1.1 gast-0.2.2 google-auth-1.7.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 oauthlib-3.1.0 opt-einsum-3.1.0 pyasn1-0.4.7 pyasn1-modules-0.2.7 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.0.1 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4qlzZsMXVCKH"
      },
      "source": [
        "### Creating Language Resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2h4nHNwnVCKJ",
        "colab": {}
      },
      "source": [
        "male_pronouns   = [\"he\",  \"him\", \"his$\", \"his\", \"himself\"]\n",
        "female_pronouns = [\"she\", \"her\", \"her$\", \"hers\", \"herself\"]\n",
        "neutral_pronouns= [\"zie\", \"zim\", \"zir\", \"zis\", \"zieself\"]\n",
        "merged_pronouns = [\"he/she\", \"him/her\", \"his/her\", \"his/hers\", \"himself/herself\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sim_9aXgVCKO",
        "colab": {}
      },
      "source": [
        "gender_pronouns_dict = {}\n",
        "gender_honorific_dict = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IC4J8YREVCKV",
        "colab": {}
      },
      "source": [
        "for (g1,g2,g3,g4) in zip(male_pronouns, female_pronouns, neutral_pronouns, merged_pronouns):\n",
        "    element = {\"male\": g1.replace(\"$\",\"\"), \"female\":g2.replace(\"$\",\"\"), \"neutral\":g3, \"merged\":g4}\n",
        "    gender_pronouns_dict[g1] = gender_pronouns_dict[g2] = gender_pronouns_dict[g3] = gender_pronouns_dict[g4] =element"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QmE6CL7PVCKd",
        "colab": {}
      },
      "source": [
        "male_hons   =  [\"Mr.\", \"Mr\", \"Md.\", \"Md\", \"Sir\", \"Lord\", \"Mister\"]\n",
        "female_hons =  [\"Ms.\", \"Ms\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Miss\"]\n",
        "neutral_hons = [\"Mx.\", \"Mx\", \"Mx.\", \"Mx\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]\n",
        "married_hons = [\"Mrs.\", \"Mrs\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Mis'ess\"]\n",
        "merged_hons =  [\"Mr./Ms.\", \"Mr/Ms\", \"Md./Mst.\", \"Md/Mst\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbb4Jf6mVCKk",
        "colab": {}
      },
      "source": [
        "for (h1,h2,h3,h4,h5) in zip(male_hons, female_hons, neutral_hons, married_hons, merged_hons):\n",
        "    element = {\"male\": h1, \"female\":h2, \"neutral\":h3, \"married_fem\":h4, \"merged\":h5}\n",
        "    gender_honorific_dict[h1] = gender_honorific_dict[h2] = gender_honorific_dict[h3] = \\\n",
        "    gender_honorific_dict[h4] = gender_honorific_dict[h5] = element"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TzgZxsSUVCKq"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5yTkWcUAYH7n",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZN82xZJgVCKr",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "#from segtok.segmenter import split_single"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MoC0zGDKggFj",
        "colab": {}
      },
      "source": [
        "import flair\n",
        "assert flair.__version__=='0.4.2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kKRKCr8uVCKv",
        "outputId": "32c6b80b-6ee3-4ecc-ef19-4e514dbcbd0b",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Be8BR8KQVCKz",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import neuralcoref"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nZuAm9_9VCK5"
      },
      "source": [
        "### Loading Essentials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UI8M4VyXVDV6",
        "colab": {}
      },
      "source": [
        "#!git clone --single-branch --branch development https://github.com/Masum06/GenderDebiasing.git resources"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mjlMu-sNVCK6",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "char2idx = 'resources/char2idx.json'\n",
        "idx2char = 'resources/idx2char.json'\n",
        "with open(char2idx, 'r') as fp:\n",
        "    char2idx = json.load(fp)\n",
        "    \n",
        "with open(idx2char, 'r') as fp:\n",
        "    idx2char = json.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h0BOOa4fVCK-",
        "outputId": "f912b456-00fa-49e2-8264-39558915bcbe",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "model_name = 'resources/char_rnn_hsc_model_0.h5'\n",
        "model = load_model(model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/youngladesh/anaconda3/envs/gender-bias/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ggCw99GvVCLC",
        "outputId": "4d6ae43e-d3d1-4700-c6ea-6b4bc6666c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#nlp = spacy.load('en_core_web_lg') # en_core_web_sm #en_core_web_md\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()\n",
        "neuralcoref.add_to_pipe(nlp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7fc5fe79c400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eP7eFWBaVCLH",
        "outputId": "032777c6-c994-48d4-d7bd-f07586d78ee0",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "tagger_ner = SequenceTagger.load('ner')\n",
        "tagger_pos = SequenceTagger.load('pos')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-11-13 23:34:38,859 loading file /home/youngladesh/.flair/models/en-ner-conll03-v0.4.pt\n",
            "2019-11-13 23:36:36,016 loading file /home/youngladesh/.flair/models/en-pos-ontonotes-v0.2.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJJlWZkBnEPl",
        "colab_type": "code",
        "outputId": "40740f85-9293-4b3b-9671-47038ec13064",
        "colab": {}
      },
      "source": [
        "\"hi\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tyHJZ4t-VCLL"
      },
      "source": [
        "### Necessary Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T2FRQ-qzEzDF"
      },
      "source": [
        "Name2Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UExr_6fiVCLM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "# Converts a name into vector\n",
        "def name2vectorTest(name):\n",
        "    name = name.lower()\n",
        "    new_name = \"\"\n",
        "    for char in name:\n",
        "      if char in char2idx:\n",
        "        new_name += char\n",
        "    chars = list(new_name)\n",
        "    vector = [ char2idx[c] for c in chars ]\n",
        "    return np.array(vector)\n",
        "\n",
        "# Converts names to fixed size tensor\n",
        "def names2tensorTest(names, maxlen=25):\n",
        "    namelist = [name2vectorTest(name) for name in names]\n",
        "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
        "\n",
        "def name2gender(name):\n",
        "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
        "  if result:\n",
        "    return \"male\"\n",
        "  else:\n",
        "    return \"female\"\n",
        "  \n",
        "def isMale(name):\n",
        "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nXxZYr_mflVz"
      },
      "source": [
        "Storing Names in Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VJzj_UF_VCMX",
        "colab": {}
      },
      "source": [
        "def store(name, name_found, Name2Key, Key2Name, num_keys): \n",
        "    \n",
        "    if name_found not in Name2Key:\n",
        "        #global num_keys\n",
        "        num_keys+=1\n",
        "        key = \"PER_\"+str(num_keys)\n",
        "        #gender = name2gender(name_found)\n",
        "        alias = None\n",
        "        element = {\"name\": name, \"key\": key, \"gender\":None, \"alias\":alias, \"is_alias\": False, \"alias_to\": None}\n",
        "        Name2Key[name_found] = element\n",
        "        Key2Name[key] = {\"name\": name, \"gender\": None, \"alias\": alias}\n",
        "    \n",
        "    if name not in Name2Key:\n",
        "        element_alias = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
        "        Name2Key[name] = element_alias\n",
        "        Name2Key[name_found][\"alias\"] = name\n",
        "        \n",
        "    return Name2Key[name_found][\"key\"], num_keys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HSYCQfJcOTLU"
      },
      "source": [
        "# Unit Gender Encryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LJLCTIOQOYav",
        "colab": {}
      },
      "source": [
        "def gender_encrypt(s):\n",
        "  s = ' '.join(s.split())\n",
        "  doc = nlp(s)\n",
        "  tokenized_text = ' '.join([token.text for token in doc])\n",
        "  oracle = []\n",
        "  coref2name = {}\n",
        "\n",
        "  # POS TAG\n",
        "  sent = Sentence(tokenized_text)\n",
        "  tagger_ner.predict(sent)\n",
        "  tagger_pos.predict(sent)\n",
        "  tagged_list = sent.to_tagged_string().split()\n",
        "  tokens_pos = []\n",
        "  pos = []\n",
        "  count = 0\n",
        "  for i in range(0,len(tagged_list),2):\n",
        "      tokens_pos.append(tagged_list[i])\n",
        "      count = count+1\n",
        "      pos.append(tagged_list[i+1])\n",
        "      \n",
        "      if tagged_list[i].lower() in male_pronouns+female_pronouns:\n",
        "          oracle.append(2)\n",
        "      elif tagged_list[i+1] in ['<B-PER/NNP>', '<I-PER/NNP>', '<E-PER/NNP>', '<S-PER/NNP>']:\n",
        "          oracle.append(4)\n",
        "      else:\n",
        "          oracle.append(0)\n",
        "\n",
        "  # COREFERENCE RESOLUTION \n",
        "  if len(doc)!=len(tokens_pos):\n",
        "    tokens_doc = [token.text for token in doc]\n",
        "    print(\"doc:\", tokens_doc)\n",
        "    print(\"pos:\", tokens_pos)\n",
        "    return None, None\n",
        "  \n",
        "  coref_stack = []\n",
        "  name_stack = []\n",
        "  for i in range(len(doc)):\n",
        "      token = doc[i]\n",
        "      if token._.in_coref:\n",
        "          coref_stack.append(tokens_pos[i])\n",
        "          if oracle[i] == 4:\n",
        "              name_stack.append(tokens_pos[i])\n",
        "          oracle[i] += 1\n",
        "      else:\n",
        "          if len(name_stack) > 0:\n",
        "              name = ' '.join(name_stack)\n",
        "              coref = ' '.join(coref_stack)\n",
        "              #name2coref[name] = coref\n",
        "              coref2name[coref] = name\n",
        "              name_stack.clear()\n",
        "          coref_stack.clear()\n",
        "\n",
        "  # IF THE SENTENCE DOES NOT END WITH A PERIOD OR SPECIAL CHARACTER\n",
        "  if len(name_stack) > 0:\n",
        "      name = ' '.join(name_stack)\n",
        "      name2coref[name] = ' '.join(coref_stack)\n",
        "      name_stack.clear()\n",
        "  coref_stack.clear()\n",
        "\n",
        "  Name2Key = {}\n",
        "  Key2Name = {}\n",
        "  encrypted = []\n",
        "  num_keys = 0\n",
        "  i = 0\n",
        "  while i<len(tokens_pos): \n",
        "      #print(\"Oracle \", i, tokens_pos[i])\n",
        "      if oracle[i] == 2:\n",
        "          pronoun = tokens_pos[i].lower()\n",
        "          if pos[i] == '<PRP$>':\n",
        "              pronoun+=\"$\"\n",
        "          encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "      elif oracle[i] == 3:\n",
        "          coref = doc[i]._.coref_clusters[0][0].text\n",
        "          pronoun = tokens_pos[i].lower()\n",
        "          if pos[i] == '<PRP$>':\n",
        "              pronoun+=\"$\"\n",
        "          if coref in coref2name:\n",
        "            name_found = coref2name[coref]\n",
        "            key = Name2Key[name_found][\"key\"]\n",
        "            if pronoun in male_pronouns:\n",
        "              Name2Key[name_found][\"gender\"] = \"male\"\n",
        "            else if pronoun in female_pronouns:\n",
        "              Name2Key[name_found][\"gender\"] = \"female\"\n",
        "            else:\n",
        "              Name2Key[name_found][\"gender\"] = \"<|unk|>\"\n",
        "            encrypted.append(\"<|coref|>\")\n",
        "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "            encrypted.append(key)\n",
        "          else:\n",
        "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "          \n",
        "      elif oracle[i] in [4,5]:\n",
        "          if i > 0 and tokens_pos[i-1] in gender_honorific_dict:\n",
        "            hons = encrypted.pop()\n",
        "            if hons in male_hons:\n",
        "              gender = \"male\"\n",
        "            else if hons in female_hons+married_hons:\n",
        "              gender = \"female\"\n",
        "            else:\n",
        "              gender = \"<|unk|>\"\n",
        "            encrypted.append(\"<|hons|>\")\n",
        "            encrypted.append(gender_honorific_dict[hons][\"merged\"])\n",
        "          if pos[i] == '<S-PER/NNP>':\n",
        "              name = tokens_pos[i]\n",
        "          elif pos[i] == '<B-PER/NNP>':\n",
        "              name = \"\"\n",
        "              while True:\n",
        "                  #print(i, oracle[i])\n",
        "                  name += tokens_pos[i]\n",
        "                  if pos[i] == '<E-PER/NNP>':\n",
        "                      break\n",
        "                  name += \" \"\n",
        "                  i+=1\n",
        "          \n",
        "          if oracle[i] == 4:\n",
        "              key, num_keys = store(name, name, Name2Key, Key2Name, num_keys)\n",
        "              encrypted.append(key)\n",
        "          else:\n",
        "              coref = doc[i]._.coref_clusters[0][0].text\n",
        "              name_found = coref2name[coref]\n",
        "              if name == name_found:\n",
        "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                  encrypted.append(key)\n",
        "              else:\n",
        "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                  encrypted.append(\"<|alias|>\")\n",
        "                  encrypted.append(key)\n",
        "          Name2Key[key][\"gender\"] = gender\n",
        "      else:\n",
        "        encrypted.append(tokens_pos[i])\n",
        "      i+=1\n",
        "      \n",
        "  encrypted_text = ' '.join(encrypted)\n",
        "\n",
        "  return tokenized_text, Key2Name, encrypted_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bMItOjUbUQNf"
      },
      "source": [
        "# Gender Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "quTM_EeiVCMu",
        "colab": {}
      },
      "source": [
        "def gender_decrypt(encrypted_text, Key2Name):\n",
        "  encrypted = encrypted_text.split()\n",
        "  decrypted = []\n",
        "  i = 0\n",
        "  while i != len(encrypted):\n",
        "    token = encrypted[i]\n",
        "    if token in Key2Name:\n",
        "      decrypted.append(Key2Name[token][\"name\"])\n",
        "    elif token == '<|alias|>':\n",
        "      i+=1\n",
        "      key = encrypted[i]\n",
        "      if Key2Name[key][\"alias\"]:\n",
        "        decrypted.append(Key2Name[key][\"alias\"])\n",
        "      else:\n",
        "        decrypted.append(Key2Name[key][\"name\"])\n",
        "    elif token == '<|coref|>':\n",
        "      startOfSent = (i==0 or encrypted[i-1] == \".\")\n",
        "      pronoun =  encrypted[i+1]\n",
        "      key = encrypted[i+2]\n",
        "      gender = Key2Name[key][\"gender\"].lower()\n",
        "      decrypted_pronoun = gender_pronouns_dict[pronoun][gender]\n",
        "      decrypted_pronoun = decrypted_pronoun[0].upper()+decrypted_pronoun[1:] if startOfSent else decrypted_pronoun\n",
        "      decrypted.append(decrypted_pronoun)\n",
        "      i+=2\n",
        "    elif token == \"<|hons|>\":\n",
        "      hons = encrypted[i+1]\n",
        "      key = encrypted[i+2] # NEED CHECK FOR HONS IN ALIAS\n",
        "      gender = Key2Name[key][\"gender\"].lower()\n",
        "      decrypted.append(gender_honorific_dict[hons][gender])\n",
        "      i+=1\n",
        "    elif token == \"he/she\":\n",
        "        if i==0 or encrypted[i-1] == \".\":\n",
        "            decrypted.append(\"He/She\")\n",
        "        else:\n",
        "            decrypted.append(\"he/she\")\n",
        "    else:\n",
        "      decrypted.append(token)\n",
        "    i+=1\n",
        "\n",
        "  decrypted_text = ' '.join(decrypted)\n",
        "  #decrypted_text = decrypted_text.replace(\" .\", \".\")\n",
        "  return decrypted_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qv5Y4nngq9AJ",
        "colab": {}
      },
      "source": [
        "key2name_changed = {'PER_1': {'name': 'Abira',\n",
        "    'key': 'PER_1',\n",
        "    'gender': 'Female',\n",
        "    'alias': None,\n",
        "    'is_alias': False,\n",
        "    'alias_to': None},\n",
        "  'PER_2': {'name': 'Shibir',\n",
        "    'key': 'PER_2',\n",
        "    'gender': 'Male',\n",
        "    'alias': None,\n",
        "    'is_alias': False,\n",
        "    'alias_to': None}\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M_Ad5ljDRvvB"
      },
      "source": [
        "### Testing Encryption-Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jDUandyxxJ8m",
        "colab": {}
      },
      "source": [
        "s = \"Mr. John is not a doctor. Ms. Katy is also not a nurse. John can fly, but she cannot swim.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJnQwJd5S_GJ",
        "colab": {}
      },
      "source": [
        "s = \"Morshed Khan told newsmen that 'BNP is a massive party with huge popularity and public acceptance.' This party is now running its operations over Skype. He (Tarique) is operating from London over Skype and that too with only selected leaders. It has turned into the ‘Bangladesh Nationalist Skype Party’. This is painful. I believe the next generation must assume leadership within the party — that would be my recommendation.”\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WL1lFCFnEQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = \"Dineshwar then left behind his wife’s stabbed body and hanged himself from a tree in a field nearby.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YsmaikFZFHtl",
        "outputId": "7d647507-2da3-47de-ca79-d97d8e59ab6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(s.split())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5qLWPn4lR1Ss",
        "scrolled": true,
        "outputId": "b90350a4-f0d6-4bec-9fa7-a22bec971b8e",
        "colab": {}
      },
      "source": [
        "import time \n",
        "start = time.time()\n",
        "text, key2name, encrypted = gender_encrypt(s)\n",
        "end = time.time()\n",
        "\n",
        "print(encrypted)\n",
        "print(key2name)\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PER_1 then left behind <|coref|> his/her PER_1 wife ’s stabbed body and hanged <|coref|> himself/herself PER_1 from a tree in a field nearby .\n",
            "{'PER_1': {'name': 'Dineshwar', 'gender': 'male', 'alias': None}}\n",
            "5.390132427215576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XB-PJPr7lIuJ",
        "colab": {}
      },
      "source": [
        "key2name = {'PER_1': {'name': 'Dineshwar', 'gender': 'merged', 'alias': None}}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eeSiLybyVCMx",
        "outputId": "1ea4a950-3955-453a-9554-fa0b59daaaf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "decrypted = gender_decrypt(encrypted, key2name)\n",
        "decrypted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dineshwar then left behind his/her wife ’s stabbed body and hanged himself/herself from a tree in a field nearby .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z2DGAAsDT6HN",
        "outputId": "948fe8a6-356f-4deb-c72d-7758be9e6431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decrypted == text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PKBfFmbYvtad",
        "outputId": "33c9a311-0b5e-49f9-86ee-212928bbeff8",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "en = gender_encrypt(\"Mr Masum Hasan is not a doctor. Masum is an engineer.\")\n",
        "en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gender_encrypt' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-3cf708c253ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0men\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgender_encrypt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mr Masum Hasan is not a doctor. Masum is an engineer.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0men\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'gender_encrypt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7-uNtEcNaJQt",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}