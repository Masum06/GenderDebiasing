{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Gender_Encrypter_Decrypter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masum06/GenderDebiasing/blob/development2/Gender_Encrypter_Decrypter_cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILV8heUdFDpF",
        "colab_type": "text"
      },
      "source": [
        "Latest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DLRLPZ9BDqgo"
      },
      "source": [
        "https://www.researchgate.net/publication/337918817_What_You_See_Is_What_You_Learn_Mitigating_Gender_Biases_from_Natural_Language_Processing_Context_through_Gender_Encrypted_Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g17bTEJ7VCJ5"
      },
      "source": [
        "# Gender Encryption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lFctT8bvVCJ9"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RSlIksK3-BSm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "13030e97-ed26-4b6d-8b40-dbf315a0b7a0"
      },
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7F74akq3VCJ-"
      },
      "source": [
        "https://github.com/zalandoresearch/flair\n",
        "\n",
        "https://github.com/huggingface/neuralcoref"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zvn8rO3mVCKA",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "186e4dff-cde9-4a06-dd44-769c5027453a"
      },
      "source": [
        "### Restart Runtime after spacy\n",
        "\n",
        "!pip uninstall torchvision\n",
        "!pip install torchvision==0.4.0\n",
        "!pip install flair==0.4.2\n",
        "!pip uninstall spacy --yes\n",
        "!pip install -U spacy==2.1.0\n",
        "##!python -m spacy download en # SMALL VERSION OF SPACY, FAST DOWNLOAD\n",
        "##!python -m spacy download en_core_web_md # MEDIUM VERSION OF SPACY\n",
        "!python -m spacy download en_core_web_lg # LARGE VERSION OF SPACY, SLOW DOWNLOAD\n",
        "!pip install neuralcoref --no-binary neuralcoref"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torchvision-0.7.0+cu101:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision-0.7.0+cu101.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Collecting torchvision==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/e6/a564eba563f7ff53aa7318ff6aaa5bd8385cbda39ed55ba471e95af27d19/torchvision-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (1.15.0)\n",
            "Collecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 15kB/s \n",
            "\u001b[?25hInstalling collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "Successfully installed torch-1.2.0 torchvision-0.4.0\n",
            "Collecting flair==0.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.8.7)\n",
            "Collecting pytorch-pretrained-bert>=0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.2.2)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.1.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.0)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.2.0)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.4)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (2019.12.20)\n",
            "Collecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.24.3)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.18.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.14.37)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (0.10.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (3.11.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (2.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair==0.4.2) (0.22.2.post1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (49.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (19.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (8.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.9.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.2) (1.12.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 16.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (2.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.37 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.17.37)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.2) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair==0.4.2) (0.16.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (2.49.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.37->boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.15.2)\n",
            "Building wheels for collected packages: sqlitedict, segtok, mpld3\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=b486d27b7caabc2793e2c1e2775401a312978fec34384780d441fe38fca3cdd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25020 sha256=7bf88dbde48eb5563231362b52a93e608dd7cddb8d5546aec6e2a5b19a20f5d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=b22489025c4a076c7df9de5c6a86a934229067c32ef5124d1e8057b0811ede4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "Successfully built sqlitedict segtok mpld3\n",
            "Installing collected packages: pytorch-pretrained-bert, sqlitedict, segtok, mpld3, deprecated, sentencepiece, bpemb, flair\n",
            "Successfully installed bpemb-0.3.2 deprecated-1.2.10 flair-0.4.2 mpld3-0.3 pytorch-pretrained-bert-0.6.2 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.6.0\n",
            "Uninstalling spacy-2.2.4:\n",
            "  Successfully uninstalled spacy-2.2.4\n",
            "Collecting spacy==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/39/4bde5da5f18ab0bdd525760c4fe38808b4bb03907a2aea094000d831afe1/spacy-2.1.0-cp36-cp36m-manylinux1_x86_64.whl (27.7MB)\n",
            "\u001b[K     |████████████████████████████████| 27.7MB 111kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.6.0)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.0.2)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.7MB/s \n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.0.3)\n",
            "Collecting thinc<7.1.0,>=7.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 29.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.0.12 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2020.6.20)\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: blis, preshed, plac, thinc, spacy\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: preshed 3.0.2\n",
            "    Uninstalling preshed-3.0.2:\n",
            "      Successfully uninstalled preshed-3.0.2\n",
            "  Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "Successfully installed blis-0.2.4 plac-0.9.6 preshed-2.0.1 spacy-2.1.0 thinc-7.0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "blis",
                  "plac",
                  "plac_core",
                  "plac_ext",
                  "preshed",
                  "spacy",
                  "thinc"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
            "\u001b[K     |████████████████████████████████| 826.9MB 1.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255078 sha256=f6564207c669783908456aa36694909b221e6a00fb6d3cf9f43d1ef181efc738\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-79483ea3/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "Collecting neuralcoref\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/40/8db3db763077fe80b71859f57731261aeb03cc624635f97a3bcfe55ab37b/neuralcoref-4.0.tar.gz (368kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.18.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.14.37)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.23.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.1.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.37 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (1.17.37)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.3)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.0.12 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.7.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.37->boto3->neuralcoref) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.37->boto3->neuralcoref) (2.8.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.37->boto3->neuralcoref) (1.15.0)\n",
            "Skipping wheel build for neuralcoref, due to binaries being disabled for it.\n",
            "Installing collected packages: neuralcoref\n",
            "    Running setup.py install for neuralcoref ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed neuralcoref-4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pZqwsmTJnEOr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e51373a1-fe9b-4d24-ddd9-26ca82a2eb9a"
      },
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "03dQLWLvnEO1",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "07ad6c6d-8608-4242-dc52-0e51e9b957b3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 12 05:25:23 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P8    32W / 149W |     11MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4qlzZsMXVCKH"
      },
      "source": [
        "### Creating Language Resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2h4nHNwnVCKJ",
        "colab": {}
      },
      "source": [
        "male_pronouns   = [\"he\",  \"him\", \"his$\", \"his\", \"himself\"]\n",
        "female_pronouns = [\"she\", \"her\", \"her$\", \"hers\", \"herself\"]\n",
        "neutral_pronouns= [\"zie\", \"zim\", \"zir\", \"zis\", \"zieself\"]\n",
        "merged_pronouns = [\"he/she\", \"him/her\", \"his/her\", \"his/hers\", \"himself/herself\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sim_9aXgVCKO",
        "colab": {}
      },
      "source": [
        "gender_pronouns_dict = {}\n",
        "gender_honorific_dict = {}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IC4J8YREVCKV",
        "colab": {}
      },
      "source": [
        "for (g1,g2,g3,g4) in zip(male_pronouns, female_pronouns, neutral_pronouns, merged_pronouns):\n",
        "    element = {\"male\": g1.replace(\"$\",\"\"), \"female\":g2.replace(\"$\",\"\"), \"neutral\":g3, \"merged\":g4}\n",
        "    gender_pronouns_dict[g1] = gender_pronouns_dict[g2] = gender_pronouns_dict[g3] = gender_pronouns_dict[g4] =element"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QmE6CL7PVCKd",
        "colab": {}
      },
      "source": [
        "male_hons   =  [\"Mr.\", \"Mr\", \"Md.\", \"Md\", \"Sir\", \"Lord\", \"Mister\"]\n",
        "female_hons =  [\"Ms.\", \"Ms\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Miss\"]\n",
        "neutral_hons = [\"Mx.\", \"Mx\", \"Mx.\", \"Mx\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]\n",
        "married_hons = [\"Mrs.\", \"Mrs\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Mis'ess\"]\n",
        "merged_hons =  [\"Mr./Ms.\", \"Mr/Ms\", \"Md./Mst.\", \"Md/Mst\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbb4Jf6mVCKk",
        "colab": {}
      },
      "source": [
        "for (h1,h2,h3,h4,h5) in zip(male_hons, female_hons, neutral_hons, married_hons, merged_hons):\n",
        "    element = {\"male\": h1, \"female\":h2, \"neutral\":h3, \"married_fem\":h4, \"merged\":h5}\n",
        "    gender_honorific_dict[h1] = gender_honorific_dict[h2] = gender_honorific_dict[h3] = \\\n",
        "    gender_honorific_dict[h4] = gender_honorific_dict[h5] = element"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TzgZxsSUVCKq"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5yTkWcUAYH7n",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZN82xZJgVCKr",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "#from segtok.segmenter import split_single"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MoC0zGDKggFj",
        "colab": {}
      },
      "source": [
        "import flair\n",
        "assert flair.__version__=='0.4.2'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kKRKCr8uVCKv",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Be8BR8KQVCKz",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import neuralcoref"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G9u1EvUfpr34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d17ec78-7813-4511-a223-8052bb3a722e"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8-VH-28OqMGc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6772481d-6f3f-4ed3-e196-fca9f2e0de39"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nZuAm9_9VCK5"
      },
      "source": [
        "### Loading Essentials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UI8M4VyXVDV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "5c55ef76-29a8-4be1-922f-838272e5ba1a"
      },
      "source": [
        "## Only do this on colab\n",
        "!git clone --single-branch --branch development2 https://github.com/Masum06/GenderDebiasing.git"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GenderDebiasing'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 157 (delta 17), reused 9 (delta 4), pack-reused 127\u001b[K\n",
            "Receiving objects: 100% (157/157), 43.27 MiB | 9.47 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n",
            "Checking out files: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nA8Mt85PUHJy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f362b778-fb5e-4d3b-97ca-bfc26a283531"
      },
      "source": [
        "#cd GenderDebiasing"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GenderDebiasing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBbM5JOdEx0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61c36dea-08cc-4455-b66f-8503d20ac2ac"
      },
      "source": [
        "#cd .."
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdpZ5YZgHnOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f970ec31-766a-4b9b-e411-18437bb67191"
      },
      "source": [
        "ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mGenderDebiasing\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mjlMu-sNVCK6",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "char2idx = 'GenderDebiasing/resources/char2idx.json'\n",
        "idx2char = 'GenderDebiasing/resources/idx2char.json'\n",
        "with open(char2idx, 'r') as fp:\n",
        "    char2idx = json.load(fp)\n",
        "    \n",
        "with open(idx2char, 'r') as fp:\n",
        "    idx2char = json.load(fp)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h0BOOa4fVCK-",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "265fed8d-3a4d-446b-868c-9f7b44677e04"
      },
      "source": [
        "model_name = 'GenderDebiasing/resources/char_rnn_hsc_model_0.h5'\n",
        "model = load_model(model_name)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-12 05:26:02,312 Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ggCw99GvVCLC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bbff013-75db-4360-8656-d0c6025ac44d"
      },
      "source": [
        "#nlp = spacy.load('en_core_web_lg') # en_core_web_sm #en_core_web_md\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()\n",
        "neuralcoref.add_to_pipe(nlp)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7f74380987f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eP7eFWBaVCLH",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "0fb7d182-602e-4927-a827-6d60053413e3"
      },
      "source": [
        "tagger_ner = SequenceTagger.load('ner')\n",
        "tagger_pos = SequenceTagger.load('pos')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-12 05:26:48,360 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/NER-conll03-english/en-ner-conll03-v0.4.pt not found in cache, downloading to /tmp/tmp66mna518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 432197603/432197603 [00:45<00:00, 9411558.47B/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-08-12 05:27:35,558 copying /tmp/tmp66mna518 to cache at /root/.flair/models/en-ner-conll03-v0.4.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-08-12 05:27:36,822 removing temp file /tmp/tmp66mna518\n",
            "2020-08-12 05:27:36,889 loading file /root/.flair/models/en-ner-conll03-v0.4.pt\n",
            "2020-08-12 05:27:40,229 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.2/POS-ontonotes--h256-l1-b32-%2Bmix-forward%2Bmix-backward--v0.2/en-pos-ontonotes-v0.2.pt not found in cache, downloading to /tmp/tmp0jb2ctqo\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 248585588/248585588 [00:31<00:00, 7931316.04B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-08-12 05:28:12,772 copying /tmp/tmp0jb2ctqo to cache at /root/.flair/models/en-pos-ontonotes-v0.2.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-08-12 05:28:13,525 removing temp file /tmp/tmp0jb2ctqo\n",
            "2020-08-12 05:28:14,002 loading file /root/.flair/models/en-pos-ontonotes-v0.2.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tyHJZ4t-VCLL"
      },
      "source": [
        "### Necessary Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T2FRQ-qzEzDF"
      },
      "source": [
        "Name2Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UExr_6fiVCLM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "# Converts a name into vector\n",
        "def name2vectorTest(name):\n",
        "    name = name.lower()\n",
        "    new_name = \"\"\n",
        "    for char in name:\n",
        "      if char in char2idx:\n",
        "        new_name += char\n",
        "    chars = list(new_name)\n",
        "    vector = [ char2idx[c] for c in chars ]\n",
        "    return np.array(vector)\n",
        "\n",
        "# Converts names to fixed size tensor\n",
        "def names2tensorTest(names, maxlen=25):\n",
        "    namelist = [name2vectorTest(name) for name in names]\n",
        "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
        "\n",
        "def name2gender(name):\n",
        "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
        "  if result:\n",
        "    return \"male\"\n",
        "  else:\n",
        "    return \"female\"\n",
        "  \n",
        "def isMale(name):\n",
        "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
        "  return result"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nXxZYr_mflVz"
      },
      "source": [
        "Storing Names in Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VJzj_UF_VCMX",
        "colab": {}
      },
      "source": [
        "def store(name, name_found, Name2Key, Key2Name, num_keys): \n",
        "    \n",
        "    if name_found not in Name2Key:\n",
        "        #global num_keys\n",
        "        num_keys+=1\n",
        "        key = \"PER_\"+str(num_keys)\n",
        "        #gender = name2gender(name_found)\n",
        "        alias = None\n",
        "        element = {\"name\": name, \"key\": key, \"gender\":None, \"alias\":alias, \"is_alias\": False, \"alias_to\": None}\n",
        "        Name2Key[name_found] = element\n",
        "        Key2Name[key] = {\"name\": name, \"gender\": None, \"alias\": alias}\n",
        "    \n",
        "    if name not in Name2Key:\n",
        "        element_alias = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
        "        Name2Key[name] = element_alias\n",
        "        Name2Key[name_found][\"alias\"] = name\n",
        "        \n",
        "    return Name2Key[name_found][\"key\"], num_keys"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HSYCQfJcOTLU"
      },
      "source": [
        "# Unit Gender Encryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LJLCTIOQOYav",
        "colab": {}
      },
      "source": [
        "def gender_encrypt(s):\n",
        "  s = ' '.join(s.split())\n",
        "  doc = nlp(s)\n",
        "  tokenized_text = ' '.join([token.text for token in doc])\n",
        "  oracle = []\n",
        "  coref2name = {}\n",
        "\n",
        "  # POS TAG\n",
        "  sent = Sentence(tokenized_text)\n",
        "  tagger_ner.predict(sent)\n",
        "  tagger_pos.predict(sent)\n",
        "  tagged_list = sent.to_tagged_string().split()\n",
        "  tokens_pos = []\n",
        "  pos = []\n",
        "  count = 0\n",
        "  for i in range(0,len(tagged_list),2):\n",
        "      tokens_pos.append(tagged_list[i])\n",
        "      count = count+1\n",
        "      pos.append(tagged_list[i+1])\n",
        "      \n",
        "      if tagged_list[i].lower() in male_pronouns+female_pronouns:\n",
        "          oracle.append(2)\n",
        "      elif tagged_list[i+1] in ['<B-PER/NNP>', '<I-PER/NNP>', '<E-PER/NNP>', '<S-PER/NNP>']:\n",
        "          oracle.append(4)\n",
        "      else:\n",
        "          oracle.append(0)\n",
        "\n",
        "  # COREFERENCE RESOLUTION \n",
        "  if len(doc)!=len(tokens_pos):\n",
        "    tokens_doc = [token.text for token in doc]\n",
        "    print(\"doc:\", tokens_doc)\n",
        "    print(\"pos:\", tokens_pos)\n",
        "    return None, None\n",
        "  \n",
        "  coref_stack = []\n",
        "  name_stack = []\n",
        "  for i in range(len(doc)):\n",
        "      token = doc[i]\n",
        "      if token._.in_coref:\n",
        "          coref_stack.append(tokens_pos[i])\n",
        "          if oracle[i] == 4:\n",
        "              name_stack.append(tokens_pos[i])\n",
        "          oracle[i] += 1\n",
        "      else:\n",
        "          if len(name_stack) > 0:\n",
        "              name = ' '.join(name_stack)\n",
        "              coref = ' '.join(coref_stack)\n",
        "              #name2coref[name] = coref\n",
        "              coref2name[coref] = name\n",
        "              name_stack.clear()\n",
        "          coref_stack.clear()\n",
        "\n",
        "  # IF THE SENTENCE DOES NOT END WITH A PERIOD OR SPECIAL CHARACTER\n",
        "  if len(name_stack) > 0:\n",
        "      name = ' '.join(name_stack)\n",
        "      name2coref[name] = ' '.join(coref_stack)\n",
        "      name_stack.clear()\n",
        "  coref_stack.clear()\n",
        "\n",
        "  Name2Key = {}\n",
        "  Key2Name = {}\n",
        "  encrypted = []\n",
        "  num_keys = 0\n",
        "  i = 0\n",
        "  while i<len(tokens_pos): \n",
        "      #print(\"Oracle \", i, tokens_pos[i])\n",
        "      if oracle[i] == 2:\n",
        "          pronoun = tokens_pos[i].lower()\n",
        "          if pos[i] == '<PRP$>':\n",
        "              pronoun+=\"$\"\n",
        "          encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "      elif oracle[i] == 3:\n",
        "          coref = doc[i]._.coref_clusters[0][0].text\n",
        "          pronoun = tokens_pos[i].lower()\n",
        "          if pos[i] == '<PRP$>':\n",
        "              pronoun+=\"$\"\n",
        "          if coref in coref2name:\n",
        "            name_found = coref2name[coref]\n",
        "            key = Name2Key[name_found][\"key\"]\n",
        "            if pronoun in male_pronouns:\n",
        "              Name2Key[name_found][\"gender\"] = \"male\"\n",
        "            elif pronoun in female_pronouns:\n",
        "              Name2Key[name_found][\"gender\"] = \"female\"\n",
        "            else:\n",
        "              Name2Key[name_found][\"gender\"] = \"<|unk|>\"\n",
        "            encrypted.append(\"<|coref|>\")\n",
        "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "            encrypted.append(key)\n",
        "          else:\n",
        "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "          \n",
        "      elif oracle[i] in [4,5]:\n",
        "          if i > 0 and tokens_pos[i-1] in gender_honorific_dict:\n",
        "            hons = encrypted.pop()\n",
        "            if hons in male_hons:\n",
        "              gender = \"male\"\n",
        "            elif hons in female_hons+married_hons:\n",
        "              gender = \"female\"\n",
        "            else:\n",
        "              gender = \"<|unk|>\"\n",
        "            encrypted.append(\"<|hons|>\")\n",
        "            encrypted.append(gender_honorific_dict[hons][\"merged\"])\n",
        "          if pos[i] == '<S-PER/NNP>':\n",
        "              name = tokens_pos[i]\n",
        "          elif pos[i] == '<B-PER/NNP>':\n",
        "              name = \"\"\n",
        "              while True:\n",
        "                  #print(i, oracle[i])\n",
        "                  name += tokens_pos[i]\n",
        "                  if pos[i] == '<E-PER/NNP>':\n",
        "                      break\n",
        "                  name += \" \"\n",
        "                  i+=1\n",
        "          \n",
        "          if oracle[i] == 4:\n",
        "              key, num_keys = store(name, name, Name2Key, Key2Name, num_keys)\n",
        "              encrypted.append(key)\n",
        "          else:\n",
        "              coref = doc[i]._.coref_clusters[0][0].text\n",
        "              name_found = coref2name[coref]\n",
        "              if name == name_found:\n",
        "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                  encrypted.append(key)\n",
        "              else:\n",
        "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                  encrypted.append(\"<|alias|>\")\n",
        "                  encrypted.append(key)\n",
        "          #Name2Key[key][\"gender\"] = gender\n",
        "      else:\n",
        "        encrypted.append(tokens_pos[i])\n",
        "      i+=1\n",
        "      \n",
        "  encrypted_text = ' '.join(encrypted)\n",
        "\n",
        "  return tokenized_text, Key2Name, encrypted_text"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bMItOjUbUQNf"
      },
      "source": [
        "# Gender Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "quTM_EeiVCMu",
        "colab": {}
      },
      "source": [
        "def gender_decrypt(encrypted_text, Key2Name):\n",
        "  encrypted = encrypted_text.split()\n",
        "  decrypted = []\n",
        "  i = 0\n",
        "  while i != len(encrypted):\n",
        "    token = encrypted[i]\n",
        "    if token in Key2Name:\n",
        "      decrypted.append(Key2Name[token][\"name\"])\n",
        "    elif token == '<|alias|>':\n",
        "      i+=1\n",
        "      key = encrypted[i]\n",
        "      if Key2Name[key][\"alias\"]:\n",
        "        decrypted.append(Key2Name[key][\"alias\"])\n",
        "      else:\n",
        "        decrypted.append(Key2Name[key][\"name\"])\n",
        "    elif token == '<|coref|>':\n",
        "      startOfSent = (i==0 or encrypted[i-1] == \".\")\n",
        "      pronoun =  encrypted[i+1]\n",
        "      key = encrypted[i+2]\n",
        "      gender = Key2Name[key][\"gender\"].lower()\n",
        "      decrypted_pronoun = gender_pronouns_dict[pronoun][gender]\n",
        "      decrypted_pronoun = decrypted_pronoun[0].upper()+decrypted_pronoun[1:] if startOfSent else decrypted_pronoun\n",
        "      decrypted.append(decrypted_pronoun)\n",
        "      i+=2\n",
        "    elif token == \"<|hons|>\":\n",
        "      hons = encrypted[i+1]\n",
        "      key = encrypted[i+2] # NEED CHECK FOR HONS IN ALIAS\n",
        "      gender = Key2Name[key][\"gender\"].lower()\n",
        "      decrypted.append(gender_honorific_dict[hons][gender])\n",
        "      i+=1\n",
        "    elif token == \"he/she\":\n",
        "        if i==0 or encrypted[i-1] == \".\":\n",
        "            decrypted.append(\"He/She\")\n",
        "        else:\n",
        "            decrypted.append(\"he/she\")\n",
        "    else:\n",
        "      decrypted.append(token)\n",
        "    i+=1\n",
        "\n",
        "  decrypted_text = ' '.join(decrypted)\n",
        "  #decrypted_text = decrypted_text.replace(\" .\", \".\")\n",
        "  return decrypted_text"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qv5Y4nngq9AJ",
        "colab": {}
      },
      "source": [
        "key2name_changed = {'PER_1': {'name': 'Abira',\n",
        "    'key': 'PER_1',\n",
        "    'gender': 'Female',\n",
        "    'alias': None,\n",
        "    'is_alias': False,\n",
        "    'alias_to': None},\n",
        "  'PER_2': {'name': 'Shibir',\n",
        "    'key': 'PER_2',\n",
        "    'gender': 'Male',\n",
        "    'alias': None,\n",
        "    'is_alias': False,\n",
        "    'alias_to': None}\n",
        "  }"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M_Ad5ljDRvvB"
      },
      "source": [
        "### Testing Encryption-Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jDUandyxxJ8m",
        "colab": {}
      },
      "source": [
        "s = \"Mr. John is not a doctor. Ms. Katy is also not a nurse. John can fly, but she cannot swim.\""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJnQwJd5S_GJ",
        "colab": {}
      },
      "source": [
        "s = \"Morshed Khan told newsmen that 'BNP is a massive party with huge popularity and public acceptance.' This party is now running its operations over Skype. He (Tarique) is operating from London over Skype and that too with only selected leaders. It has turned into the ‘Bangladesh Nationalist Skype Party’. This is painful. I believe the next generation must assume leadership within the party — that would be my recommendation.”\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2WL1lFCFnEQF",
        "colab": {}
      },
      "source": [
        "s = \"Dineshwar then left behind his wife’s stabbed body and hanged himself from a tree in a field nearby.\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YsmaikFZFHtl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cf9de03-0904-4da2-9a4e-78b1bc56afb5"
      },
      "source": [
        "len(s.split())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5qLWPn4lR1Ss",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2c7b12b1-262b-4ba6-a337-b81189250b15"
      },
      "source": [
        "import datetime \n",
        "start = datetime.datetime.now()\n",
        "text, key2name, encrypted = gender_encrypt(s)\n",
        "end = datetime.datetime.now()\n",
        "\n",
        "print(encrypted)\n",
        "print(key2name)\n",
        "print(end-start)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PER_1 then left behind <|coref|> his/her PER_1 wife ’s stabbed body and hanged <|coref|> himself/herself PER_1 from a tree in a field nearby .\n",
            "{'PER_1': {'name': 'Dineshwar', 'gender': None, 'alias': None}}\n",
            "0:00:00.307706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XB-PJPr7lIuJ",
        "colab": {}
      },
      "source": [
        "key2name = {'PER_1': {'name': 'Dineshwar', 'gender': 'merged', 'alias': None}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eeSiLybyVCMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1ea4a950-3955-453a-9554-fa0b59daaaf2"
      },
      "source": [
        "decrypted = gender_decrypt(encrypted, key2name)\n",
        "decrypted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dineshwar then left behind his/her wife ’s stabbed body and hanged himself/herself from a tree in a field nearby .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z2DGAAsDT6HN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "948fe8a6-356f-4deb-c72d-7758be9e6431"
      },
      "source": [
        "decrypted == text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PKBfFmbYvtad",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "33c9a311-0b5e-49f9-86ee-212928bbeff8"
      },
      "source": [
        "en = gender_encrypt(\"Mr Masum Hasan is not a doctor. Masum is an engineer.\")\n",
        "en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gender_encrypt' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-3cf708c253ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0men\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgender_encrypt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mr Masum Hasan is not a doctor. Masum is an engineer.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0men\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'gender_encrypt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7-uNtEcNaJQt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca2203a2-0951-4878-e318-699ba2ae5e34"
      },
      "source": [
        "isMale(\"Masum\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCgfZwjMJxAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}