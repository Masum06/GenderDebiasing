{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Masum06/GenderDebiasing/blob/development/Gender_Encrypter_Decrypter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g17bTEJ7VCJ5"
   },
   "source": [
    "# Gender Encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFctT8bvVCJ9"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RSlIksK3-BSm",
    "outputId": "a637b53d-ee37-4ca6-8d43-64f5b77d08c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7F74akq3VCJ-"
   },
   "source": [
    "https://github.com/zalandoresearch/flair\n",
    "\n",
    "https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Zvn8rO3mVCKA",
    "outputId": "201e58e4-725a-435a-8c99-5ef3a3006b4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair==0.4.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 10.1MB/s \n",
      "\u001b[?25hCollecting mpld3==0.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
      "\u001b[K     |████████████████████████████████| 798kB 50.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (4.28.1)\n",
      "Collecting regex\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 48.2MB/s \n",
      "\u001b[?25hCollecting deprecated>=1.2.4\n",
      "  Downloading https://files.pythonhosted.org/packages/88/0e/9d5a1a8cd7130c49334cce7b8167ceda63d6a329c8ea65b626116bc9e9e6/Deprecated-1.2.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.8.5)\n",
      "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.4)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.3.0+cu100)\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.24.3)\n",
      "Collecting pytorch-pretrained-bert>=0.6.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 47.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.1.1)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.0)\n",
      "Collecting bpemb>=0.2.9\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.1.2)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.0)\n",
      "Collecting segtok>=1.5.7\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.2) (1.11.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (19.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (41.4.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (7.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.3.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.8.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (0.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->flair==0.4.2) (1.17.3)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.10.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.6.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.3.1)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.8.4)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 50.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (2.4)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (0.16.0)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (3.9.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair==0.4.2) (0.21.3)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.7 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.13.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.9.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2019.9.11)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (2.49.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.2) (4.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair==0.4.2) (0.14.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.15.2)\n",
      "Building wheels for collected packages: mpld3, sqlitedict, segtok\n",
      "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=fa3d0b2ee053a69f591c6c085a65c38ea0bc802c5fae4a456d97a93dba59d311\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=84f5322466ef66863eba6de99b41527810b49fb79108ef998537cc0386d58cb0\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
      "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=0f17632a935deeefc90dd3eeeff0682e43d74d65d97fea6af5b0b9df3a1ac042\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
      "Successfully built mpld3 sqlitedict segtok\n",
      "Installing collected packages: mpld3, regex, deprecated, sqlitedict, pytorch-pretrained-bert, sentencepiece, bpemb, segtok, flair\n",
      "Successfully installed bpemb-0.3.0 deprecated-1.2.6 flair-0.4.2 mpld3-0.3 pytorch-pretrained-bert-0.6.2 regex-2019.11.1 segtok-1.5.7 sentencepiece-0.1.83 sqlitedict-1.6.0\n",
      "Collecting en_core_web_lg==2.1.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
      "\u001b[K     |████████████████████████████████| 826.9MB 1.1MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
      "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255076 sha256=c415c89471fa26c98fc5ef5f46aaebde6b783d640ce70ff2c136c20f0d5fb077\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hwo36rl0/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
      "Successfully built en-core-web-lg\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-2.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n",
      "Collecting neuralcoref\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/40/8db3db763077fe80b71859f57731261aeb03cc624635f97a3bcfe55ab37b/neuralcoref-4.0.tar.gz (368kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 9.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.17.3)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.10.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.21.0)\n",
      "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.1.9)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.7 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (1.13.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.9.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.3.0)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.2)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->neuralcoref) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->neuralcoref) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy>=2.1.0->neuralcoref) (4.28.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.7->boto3->neuralcoref) (1.12.0)\n",
      "Skipping wheel build for neuralcoref, due to binaries being disabled for it.\n",
      "Installing collected packages: neuralcoref\n",
      "    Running setup.py install for neuralcoref ... \u001b[?25l\u001b[?25hdone\n",
      "Successfully installed neuralcoref-4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flair==0.4.2\n",
    "#!pip uninstall spacy\n",
    "#!pip install -U spacy==2.1.0\n",
    "##!python -m spacy download en # SMALL VERSION OF SPACY, FAST DOWNLOAD\n",
    "##!python -m spacy download en_core_web_md # MEDIUM VERSION OF SPACY\n",
    "!python -m spacy download en_core_web_lg # LARGE VERSION OF SPACY, SLOW DOWNLOAD\n",
    "!pip install neuralcoref --no-binary neuralcoref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qlzZsMXVCKH"
   },
   "source": [
    "### Creating Language Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2h4nHNwnVCKJ"
   },
   "outputs": [],
   "source": [
    "male_pronouns   = [\"he\",  \"him\", \"his$\", \"his\", \"himself\"]\n",
    "female_pronouns = [\"she\", \"her\", \"her$\", \"hers\", \"herself\"]\n",
    "neutral_pronouns= [\"zie\", \"zim\", \"zir\", \"zis\", \"zieself\"]\n",
    "merged_pronouns = [\"he/she\", \"him/her\", \"his/her\", \"his/hers\", \"himself/herself\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sim_9aXgVCKO"
   },
   "outputs": [],
   "source": [
    "gender_pronouns_dict = {}\n",
    "gender_honorific_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IC4J8YREVCKV"
   },
   "outputs": [],
   "source": [
    "for (g1,g2,g3,g4) in zip(male_pronouns, female_pronouns, neutral_pronouns, merged_pronouns):\n",
    "    element = {\"male\": g1.replace(\"$\",\"\"), \"female\":g2.replace(\"$\",\"\"), \"neutral\":g3, \"merged\":g4}\n",
    "    gender_pronouns_dict[g1] = gender_pronouns_dict[g2] = gender_pronouns_dict[g3] = gender_pronouns_dict[g4] =element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmE6CL7PVCKd"
   },
   "outputs": [],
   "source": [
    "male_hons   =  [\"Mr.\", \"Mr\", \"Md.\", \"Md\", \"Sir\", \"Lord\", \"Mister\"]\n",
    "female_hons =  [\"Ms.\", \"Ms\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Miss\"]\n",
    "neutral_hons = [\"Mx.\", \"Mx\", \"Mx.\", \"Mx\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]\n",
    "married_hons = [\"Mrs.\", \"Mrs\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Mis'ess\"]\n",
    "merged_hons =  [\"Mr./Ms.\", \"Mr/Ms\", \"Md./Mst.\", \"Md/Mst\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbb4Jf6mVCKk"
   },
   "outputs": [],
   "source": [
    "for (h1,h2,h3,h4,h5) in zip(male_hons, female_hons, neutral_hons, married_hons, merged_hons):\n",
    "    element = {\"male\": h1, \"female\":h2, \"neutral\":h3, \"married_fem\":h4, \"merged\":h5}\n",
    "    gender_honorific_dict[h1] = gender_honorific_dict[h2] = gender_honorific_dict[h3] = \\\n",
    "    gender_honorific_dict[h4] = gender_honorific_dict[h5] = element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TzgZxsSUVCKq"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yTkWcUAYH7n"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZN82xZJgVCKr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from segtok.segmenter import split_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MoC0zGDKggFj"
   },
   "outputs": [],
   "source": [
    "import flair\n",
    "assert flair.__version__=='0.4.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "kKRKCr8uVCKv",
    "outputId": "32c6b80b-6ee3-4ecc-ef19-4e514dbcbd0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "Be8BR8KQVCKz",
    "outputId": "4fd8730e-1513-4472-f7e3-2de7b87b3af9"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import neuralcoref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZuAm9_9VCK5"
   },
   "source": [
    "### Loading Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UI8M4VyXVDV6",
    "outputId": "7055c7c2-3ab2-4ce4-b23a-1e2a3808db54"
   },
   "outputs": [],
   "source": [
    "!git clone --single-branch --branch development https://github.com/Masum06/GenderDebiasing.git resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjlMu-sNVCK6"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "char2idx = 'resources/char2idx.json'\n",
    "idx2char = 'resources/idx2char.json'\n",
    "with open(char2idx, 'r') as fp:\n",
    "    char2idx = json.load(fp)\n",
    "    \n",
    "with open(idx2char, 'r') as fp:\n",
    "    idx2char = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "colab_type": "code",
    "id": "h0BOOa4fVCK-",
    "outputId": "f912b456-00fa-49e2-8264-39558915bcbe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-08 08:34:45,722 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2019-11-08 08:34:45,811 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2019-11-08 08:34:45,846 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2019-11-08 08:34:46,006 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2019-11-08 08:34:46,021 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2019-11-08 08:34:46,388 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2019-11-08 08:34:46,601 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2019-11-08 08:34:46,610 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_name = 'resources/char_rnn_hsc_model_0.h5'\n",
    "model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ggCw99GvVCLC",
    "outputId": "4d6ae43e-d3d1-4700-c6ea-6b4bc6666c0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x246e4f24b00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nlp = spacy.load('en_core_web_lg') # en_core_web_sm #en_core_web_md\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "eP7eFWBaVCLH",
    "outputId": "032777c6-c994-48d4-d7bd-f07586d78ee0",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-08 08:35:04,083 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n",
      "2019-11-08 08:35:28,511 loading file C:\\Users\\Hp\\.flair\\models\\en-pos-ontonotes-v0.2.pt\n"
     ]
    }
   ],
   "source": [
    "tagger_ner = SequenceTagger.load('ner')\n",
    "tagger_pos = SequenceTagger.load('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyHJZ4t-VCLL"
   },
   "source": [
    "### Necessary Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2FRQ-qzEzDF"
   },
   "source": [
    "Name2Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UExr_6fiVCLM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Converts a name into vector\n",
    "def name2vectorTest(name):\n",
    "    name = name.lower()\n",
    "    new_name = \"\"\n",
    "    for char in name:\n",
    "      if char in char2idx:\n",
    "        new_name += char\n",
    "    chars = list(new_name)\n",
    "    vector = [ char2idx[c] for c in chars ]\n",
    "    return np.array(vector)\n",
    "\n",
    "# Converts names to fixed size tensor\n",
    "def names2tensorTest(names, maxlen=25):\n",
    "    namelist = [name2vectorTest(name) for name in names]\n",
    "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
    "\n",
    "def name2gender(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  if result:\n",
    "    return \"male\"\n",
    "  else:\n",
    "    return \"female\"\n",
    "  \n",
    "def isMale(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXxZYr_mflVz"
   },
   "source": [
    "Storing Names in Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJzj_UF_VCMX"
   },
   "outputs": [],
   "source": [
    "def store(name, name_found, Name2Key, Key2Name, num_keys): \n",
    "    \n",
    "    if name_found not in Name2Key:\n",
    "        #global num_keys\n",
    "        num_keys+=1\n",
    "        key = \"PER_\"+str(num_keys)\n",
    "        gender = name2gender(name_found)\n",
    "        alias = None\n",
    "        element = {\"name\": name, \"key\": key, \"gender\":gender, \"alias\":alias, \"is_alias\": False, \"alias_to\": None}\n",
    "        Name2Key[name_found] = element\n",
    "        Key2Name[key] = element\n",
    "    \n",
    "    if name not in Name2Key:\n",
    "        element_alias = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
    "        Name2Key[name] = element_alias\n",
    "        Name2Key[name_found][\"alias\"] = name\n",
    "        \n",
    "    return Name2Key[name_found][\"key\"], num_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSYCQfJcOTLU"
   },
   "source": [
    "# Unit Gender Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJLCTIOQOYav"
   },
   "outputs": [],
   "source": [
    "def gender_encrypt(s):\n",
    "  s = ' '.join(s.split())\n",
    "  doc = nlp(s)\n",
    "  tokenized_text = ' '.join([token.text for token in doc])\n",
    "  oracle = []\n",
    "  coref2name = {}\n",
    "\n",
    "  # POS TAG\n",
    "  sent = Sentence(tokenized_text)\n",
    "  tagger_ner.predict(sent)\n",
    "  tagger_pos.predict(sent)\n",
    "  tagged_list = sent.to_tagged_string().split()\n",
    "  tokens_pos = []\n",
    "  pos = []\n",
    "  count = 0\n",
    "  for i in range(0,len(tagged_list),2):\n",
    "      tokens_pos.append(tagged_list[i])\n",
    "      count = count+1\n",
    "      pos.append(tagged_list[i+1])\n",
    "      \n",
    "      if tagged_list[i].lower() in male_pronouns+female_pronouns:\n",
    "          oracle.append(2)\n",
    "      elif tagged_list[i+1] in ['<B-PER/NNP>', '<I-PER/NNP>', '<E-PER/NNP>', '<S-PER/NNP>']:\n",
    "          oracle.append(4)\n",
    "      else:\n",
    "          oracle.append(0)\n",
    "\n",
    "  # COREFERENCE RESOLUTION \n",
    "  if len(doc)!=len(tokens_pos):\n",
    "    tokens_doc = [token.text for token in doc]\n",
    "    print(\"doc:\", tokens_doc)\n",
    "    print(\"pos:\", tokens_pos)\n",
    "    return None, None\n",
    "  \n",
    "  coref_stack = []\n",
    "  name_stack = []\n",
    "  for i in range(len(doc)):\n",
    "      token = doc[i]\n",
    "      if token._.in_coref:\n",
    "          coref_stack.append(tokens_pos[i])\n",
    "          if oracle[i] == 4:\n",
    "              name_stack.append(tokens_pos[i])\n",
    "          oracle[i] += 1\n",
    "      else:\n",
    "          if len(name_stack) > 0:\n",
    "              name = ' '.join(name_stack)\n",
    "              coref = ' '.join(coref_stack)\n",
    "              #name2coref[name] = coref\n",
    "              coref2name[coref] = name\n",
    "              name_stack.clear()\n",
    "          coref_stack.clear()\n",
    "\n",
    "  # IF THE SENTENCE DOES NOT END WITH A PERIOD OR SPECIAL CHARACTER\n",
    "  if len(name_stack) > 0:\n",
    "      name = ' '.join(name_stack)\n",
    "      name2coref[name] = ' '.join(coref_stack)\n",
    "      name_stack.clear()\n",
    "  coref_stack.clear()\n",
    "\n",
    "  Name2Key = {}\n",
    "  Key2Name = {}\n",
    "  encrypted = []\n",
    "  num_keys = 0\n",
    "  i = 0\n",
    "  while i<len(tokens_pos): \n",
    "      #print(\"Oracle \", i, tokens_pos[i])\n",
    "      if oracle[i] == 2:\n",
    "          pronoun = tokens_pos[i].lower()\n",
    "          if pos[i] == '<PRP$>':\n",
    "              pronoun+=\"$\"\n",
    "          encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "      elif oracle[i] == 3:\n",
    "          coref = doc[i]._.coref_clusters[0][0].text\n",
    "          pronoun = tokens_pos[i].lower()\n",
    "          if pos[i] == '<PRP$>':\n",
    "              pronoun+=\"$\"\n",
    "          if coref in coref2name:\n",
    "            name_found = coref2name[coref]\n",
    "            key = Name2Key[name_found][\"key\"]\n",
    "            encrypted.append(\"<|coref|>\")\n",
    "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "            encrypted.append(key)\n",
    "          else:\n",
    "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "          \n",
    "      elif oracle[i] in [4,5]:\n",
    "          if i > 0 and tokens_pos[i-1] in gender_honorific_dict:\n",
    "            hons = encrypted.pop()\n",
    "            encrypted.append(\"<|hons|>\")\n",
    "            encrypted.append(gender_honorific_dict[hons][\"merged\"])\n",
    "          if pos[i] == '<S-PER/NNP>':\n",
    "              name = tokens_pos[i]\n",
    "          elif pos[i] == '<B-PER/NNP>':\n",
    "              name = \"\"\n",
    "              while True:\n",
    "                  #print(i, oracle[i])\n",
    "                  name += tokens_pos[i]\n",
    "                  if pos[i] == '<E-PER/NNP>':\n",
    "                      break\n",
    "                  name += \" \"\n",
    "                  i+=1\n",
    "          \n",
    "          if oracle[i] == 4:\n",
    "              key, num_keys = store(name, name, Name2Key, Key2Name, num_keys)\n",
    "              encrypted.append(key)\n",
    "          else:\n",
    "              coref = doc[i]._.coref_clusters[0][0].text\n",
    "              name_found = coref2name[coref]\n",
    "              if name == name_found:\n",
    "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
    "                  encrypted.append(key)\n",
    "              else:\n",
    "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
    "                  encrypted.append(\"<|alias|>\")\n",
    "                  encrypted.append(key)\n",
    "      else:\n",
    "        encrypted.append(tokens_pos[i])\n",
    "      i+=1\n",
    "      \n",
    "  encrypted_text = ' '.join(encrypted)\n",
    "\n",
    "  return tokenized_text, Key2Name, encrypted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMItOjUbUQNf"
   },
   "source": [
    "# Gender Decryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "quTM_EeiVCMu"
   },
   "outputs": [],
   "source": [
    "def gender_decrypt(encrypted_text, Key2Name):\n",
    "  encrypted = encrypted_text.split()\n",
    "  decrypted = []\n",
    "  i = 0\n",
    "  while i != len(encrypted):\n",
    "    token = encrypted[i]\n",
    "    if token in Key2Name:\n",
    "      decrypted.append(Key2Name[token][\"name\"])\n",
    "    elif token == '<|alias|>':\n",
    "      i+=1\n",
    "      key = encrypted[i]\n",
    "      if Key2Name[key][\"alias\"]:\n",
    "        decrypted.append(Key2Name[key][\"alias\"])\n",
    "      else:\n",
    "        decrypted.append(Key2Name[key][\"name\"])\n",
    "    elif token == '<|coref|>':\n",
    "      startOfSent = (i==0 or encrypted[i-1] == \".\")\n",
    "      pronoun =  encrypted[i+1]\n",
    "      key = encrypted[i+2]\n",
    "      gender = Key2Name[key][\"gender\"].lower()\n",
    "      decrypted_pronoun = gender_pronouns_dict[pronoun][gender]\n",
    "      decrypted_pronoun = decrypted_pronoun[0].upper()+decrypted_pronoun[1:] if startOfSent else decrypted_pronoun\n",
    "      decrypted.append(decrypted_pronoun)\n",
    "      i+=2\n",
    "    elif token == \"<|hons|>\":\n",
    "      hons = encrypted[i+1]\n",
    "      key = encrypted[i+2] # NEED CHECK FOR HONS IN ALIAS\n",
    "      gender = Key2Name[key][\"gender\"].lower()\n",
    "      decrypted.append(gender_honorific_dict[hons][gender])\n",
    "      i+=1\n",
    "    elif token == \"he/she\":\n",
    "        if i==0 or encrypted[i-1] == \".\":\n",
    "            decrypted.append(\"He/She\")\n",
    "        else:\n",
    "            decrypted.append(\"he/she\")\n",
    "    else:\n",
    "      decrypted.append(token)\n",
    "    i+=1\n",
    "\n",
    "  decrypted_text = ' '.join(decrypted)\n",
    "  #decrypted_text = decrypted_text.replace(\" .\", \".\")\n",
    "  return decrypted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qv5Y4nngq9AJ"
   },
   "outputs": [],
   "source": [
    "key2name_changed = {'PER_1': {'name': 'Abira',\n",
    "    'key': 'PER_1',\n",
    "    'gender': 'Female',\n",
    "    'alias': None,\n",
    "    'is_alias': False,\n",
    "    'alias_to': None},\n",
    "  'PER_2': {'name': 'Shibir',\n",
    "    'key': 'PER_2',\n",
    "    'gender': 'Male',\n",
    "    'alias': None,\n",
    "    'is_alias': False,\n",
    "    'alias_to': None}\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_Ad5ljDRvvB"
   },
   "source": [
    "### Testing Encryption-Decryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDUandyxxJ8m"
   },
   "outputs": [],
   "source": [
    "s = \"Mr. John is not a doctor. Ms. Katy is also not a nurse. John can fly, but she cannot swim.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJnQwJd5S_GJ"
   },
   "outputs": [],
   "source": [
    "s = \"Morshed Khan told newsmen that 'BNP is a massive party with huge popularity and public acceptance.' This party is now running its operations over Skype. He (Tarique) is operating from London over Skype and that too with only selected leaders. It has turned into the ‘Bangladesh Nationalist Skype Party’. This is painful. I believe the next generation must assume leadership within the party — that would be my recommendation.”\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YsmaikFZFHtl",
    "outputId": "7d647507-2da3-47de-ca79-d97d8e59ab6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qLWPn4lR1Ss",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|hons|> Mr./Ms. PER_1 is not a doctor . <|hons|> Mr./Ms. PER_2 is also not a nurse . PER_1 can fly , but <|coref|> he/she PER_2 can not swim .\n",
      "{'PER_1': {'name': 'John', 'key': 'PER_1', 'gender': 'male', 'alias': None, 'is_alias': False, 'alias_to': None}, 'PER_2': {'name': 'Katy', 'key': 'PER_2', 'gender': 'female', 'alias': None, 'is_alias': False, 'alias_to': None}}\n",
      "1.6402082443237305\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "text, key2name, encrypted = gender_encrypt(s)\n",
    "end = time.time()\n",
    "\n",
    "print(encrypted)\n",
    "print(key2name)\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XB-PJPr7lIuJ"
   },
   "outputs": [],
   "source": [
    "key2name = {'PER_1': {'name': 'Masum', 'key': 'PER_1', 'gender': 'female', 'alias': None, 'is_alias': False, 'alias_to': None}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "eeSiLybyVCMx",
    "outputId": "1ea4a950-3955-453a-9554-fa0b59daaaf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. John is not a doctor . Ms. Katy is also not a nurse . John can fly , but she can not swim .'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrypted = gender_decrypt(encrypted, key2name)\n",
    "decrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z2DGAAsDT6HN",
    "outputId": "948fe8a6-356f-4deb-c72d-7758be9e6431"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrypted == text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "PKBfFmbYvtad",
    "outputId": "33c9a311-0b5e-49f9-86ee-212928bbeff8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "2 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Mr Masum Hasan is not a doctor . Masum is an engineer .',\n",
       " {'PER_1': {'name': 'Masum Hasan',\n",
       "   'key': 'PER_1',\n",
       "   'gender': 'male',\n",
       "   'alias': None,\n",
       "   'is_alias': False,\n",
       "   'alias_to': None}},\n",
       " '<|hons|> Mr/Ms PER_1 is not a doctor . <|alias|> PER_1 is an engineer .')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = gender_encrypt(\"Mr Masum Hasan is not a doctor. Masum is an engineer.\")\n",
    "en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-uNtEcNaJQt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Gender Encrypter Decrypter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
