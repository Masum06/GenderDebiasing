{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Masum06/GenderDebiasing/blob/development2/Gender_Encrypter_Decrypter_cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLRLPZ9BDqgo"
   },
   "source": [
    "https://www.researchgate.net/publication/337918817_What_You_See_Is_What_You_Learn_Mitigating_Gender_Biases_from_Natural_Language_Processing_Context_through_Gender_Encrypted_Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g17bTEJ7VCJ5"
   },
   "source": [
    "# Gender Encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFctT8bvVCJ9"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RSlIksK3-BSm",
    "outputId": "b4a2de92-bb0a-4141-cf85-d149e4f1057f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e3uubDldnEOO",
    "outputId": "7454f357-def9-4b29-9e0e-650da8b0468e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: conda: command not found\n"
     ]
    }
   ],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "puJwG-ymnEOS",
    "outputId": "6560443f-9d6a-49fc-8273-1ea407b2db43",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: activate: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!source activate gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7F74akq3VCJ-"
   },
   "source": [
    "https://github.com/zalandoresearch/flair\n",
    "\n",
    "https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Zvn8rO3mVCKA",
    "outputId": "53c6db4f-bb69-4a16-8793-4b24c3aa71a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair==0.4.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 1.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (4.38.0)\n",
      "Collecting bpemb>=0.2.9\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.8.7)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.0)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n",
      "Collecting segtok>=1.5.7\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (2019.12.20)\n",
      "Collecting pytorch-pretrained-bert>=0.6.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 60.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.4.0)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.0)\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.2.1)\n",
      "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.4)\n",
      "Collecting mpld3==0.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
      "\u001b[K     |████████████████████████████████| 798kB 49.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.1.2)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.24.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair==0.4.2) (1.18.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair==0.4.2) (2.21.0)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 52.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair==0.4.2) (0.22.2.post1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.2) (1.12.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.12.27)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.4.6)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.3.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (8.2.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (0.7.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (46.0.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (0.16.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (2.4)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (3.10.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (3.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair==0.4.2) (0.14.1)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.15.27)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.9.5)\n",
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (1.18.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.2) (4.4.2)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.15.2)\n",
      "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (1.7.2)\n",
      "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (0.4.1)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (1.0.3)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (0.2.8)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (1.16.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (0.4.8)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (1.51.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (3.10.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (2018.9)\n",
      "Building wheels for collected packages: segtok, sqlitedict, mpld3\n",
      "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=c73b1720391f7de8827304d5bdf7e78ba7078608b6abb224d31a853a9d992c2e\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=f42a6ee532c266243202b8a89663fd920c4e79519d48f6c39ae5d8ffcb390306\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
      "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=cdd67e4b839ca406a790b4207792fe49c5eb4ef5d0633b89544c8e4e5d917c76\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
      "Successfully built segtok sqlitedict mpld3\n",
      "Installing collected packages: sentencepiece, bpemb, deprecated, segtok, pytorch-pretrained-bert, sqlitedict, mpld3, flair\n",
      "Successfully installed bpemb-0.3.0 deprecated-1.2.7 flair-0.4.2 mpld3-0.3 pytorch-pretrained-bert-0.6.2 segtok-1.5.7 sentencepiece-0.1.85 sqlitedict-1.6.0\n",
      "Uninstalling spacy-2.2.4:\n",
      "  Successfully uninstalled spacy-2.2.4\n",
      "Collecting spacy==2.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/39/4bde5da5f18ab0bdd525760c4fe38808b4bb03907a2aea094000d831afe1/spacy-2.1.0-cp36-cp36m-manylinux1_x86_64.whl (27.7MB)\n",
      "\u001b[K     |████████████████████████████████| 27.7MB 111kB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.0.3)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.0.2)\n",
      "Collecting preshed<2.1.0,>=2.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 13.2MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.0.12 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (0.6.0)\n",
      "Collecting blis<0.3.0,>=0.2.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 34.5MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.6.0)\n",
      "Collecting plac<1.0.0,>=0.9.6\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
      "Collecting thinc<7.1.0,>=7.0.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 46.7MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.0) (4.38.0)\n",
      "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: preshed, blis, plac, thinc, spacy\n",
      "  Found existing installation: preshed 3.0.2\n",
      "    Uninstalling preshed-3.0.2:\n",
      "      Successfully uninstalled preshed-3.0.2\n",
      "  Found existing installation: blis 0.4.1\n",
      "    Uninstalling blis-0.4.1:\n",
      "      Successfully uninstalled blis-0.4.1\n",
      "  Found existing installation: plac 1.1.3\n",
      "    Uninstalling plac-1.1.3:\n",
      "      Successfully uninstalled plac-1.1.3\n",
      "  Found existing installation: thinc 7.4.0\n",
      "    Uninstalling thinc-7.4.0:\n",
      "      Successfully uninstalled thinc-7.4.0\n",
      "Successfully installed blis-0.2.4 plac-0.9.6 preshed-2.0.1 spacy-2.1.0 thinc-7.0.8\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "blis",
         "plac",
         "plac_core",
         "plac_ext",
         "preshed",
         "spacy",
         "thinc"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_lg==2.1.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
      "\u001b[K     |████████████████████████████████| 826.9MB 100.4MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
      "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255078 sha256=6b322e6f96f084dd798303601e7e5da341af5da900efb2ae0f04a76373d9bf25\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-a5ro5f3i/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
      "Successfully built en-core-web-lg\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-2.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n",
      "Collecting neuralcoref\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/40/8db3db763077fe80b71859f57731261aeb03cc624635f97a3bcfe55ab37b/neuralcoref-4.0.tar.gz (368kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 1.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.18.2)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.12.27)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.21.0)\n",
      "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.1.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.9.5)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (1.15.27)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
      "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.0.12 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.6.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->neuralcoref) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->neuralcoref) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.38.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.27->boto3->neuralcoref) (1.12.0)\n",
      "Skipping wheel build for neuralcoref, due to binaries being disabled for it.\n",
      "Installing collected packages: neuralcoref\n",
      "    Running setup.py install for neuralcoref ... \u001b[?25l\u001b[?25hdone\n",
      "Successfully installed neuralcoref-4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flair==0.4.2\n",
    "!pip uninstall spacy --yes\n",
    "!pip install -U spacy==2.1.0\n",
    "##!python -m spacy download en # SMALL VERSION OF SPACY, FAST DOWNLOAD\n",
    "##!python -m spacy download en_core_web_md # MEDIUM VERSION OF SPACY\n",
    "!python -m spacy download en_core_web_lg # LARGE VERSION OF SPACY, SLOW DOWNLOAD\n",
    "!pip install neuralcoref --no-binary neuralcoref\n",
    "#!pip uninstall torch torchvision --yes\n",
    "#!pip install torch==1.3.0 torchvision==0.4.0\n",
    "#!pip install keras==2.2.4\n",
    "#!conda install -c conda-forge tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "rSa3KyZnt4Ja",
    "outputId": "71879801-b9fd-4982-f0c0-42b106c90f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.3.1+cu100\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.3.1%2Bcu100-cp36-cp36m-linux_x86_64.whl (705.3MB)\n",
      "\u001b[K     |████████████████████████████████| 705.3MB 26kB/s \n",
      "\u001b[?25hCollecting torchvision==0.4.2+cu100\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torchvision-0.4.2%2Bcu100-cp36-cp36m-linux_x86_64.whl (10.1MB)\n",
      "\u001b[K     |████████████████████████████████| 10.2MB 340kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.3.1+cu100) (1.18.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2+cu100) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2+cu100) (7.0.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.3.1+cu100 torchvision-0.4.2+cu100\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision -y\n",
    "!pip install torch==1.3.1+cu100 torchvision==0.4.2+cu100 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 944
    },
    "colab_type": "code",
    "id": "Otn_BP2dUtKy",
    "outputId": "16f7371b-07fe-4dc9-de00-cedc9b5d2853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tesnforflow as it is not installed.\u001b[0m\n",
      "Collecting tensorflow-gpu==1.14\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
      "\u001b[K     |████████████████████████████████| 377.0MB 46kB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.18.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 27.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.0)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 49.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.34.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.9.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.3.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.27.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (39.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.2.1)\n",
      "\u001b[31mERROR: tensorflow 2.2.0rc1 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.2.0rc1 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
      "  Found existing installation: tensorboard 1.11.0\n",
      "    Uninstalling tensorboard-1.11.0:\n",
      "      Successfully uninstalled tensorboard-1.11.0\n",
      "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
      "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
      "  Found existing installation: tensorflow-gpu 1.11.0\n",
      "    Uninstalling tensorflow-gpu-1.11.0:\n",
      "      Successfully uninstalled tensorflow-gpu-1.11.0\n",
      "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n",
      "Uninstalling Keras-2.2.4:\n",
      "  Successfully uninstalled Keras-2.2.4\n",
      "Collecting keras==2.2.4\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tesnforflow --yes\n",
    "!pip install tensorflow-gpu==1.14\n",
    "!pip uninstall keras --yes\n",
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBNGIakZnEOb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Not on Colab\n",
    "#!conda uninstall tensorflow --yes\n",
    "#!conda install tensorflow-gpu anaconda --yes\n",
    "#!conda install -c pytorch pytorch --yes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "ylKonOmZnEOe",
    "outputId": "2a6e7b7a-3c00-43ec-8470-728c9ce44b3a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12463094563540319059\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "QaVft4zOn74O",
    "outputId": "416bee0a-be20-4d6e-cbac-0096ec4ef648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "Uninstalling tensorflow-2.2.0rc1:\n",
      "  Would remove:\n",
      "    /usr/local/bin/estimator_ckpt_converter\n",
      "    /usr/local/bin/saved_model_cli\n",
      "    /usr/local/bin/tensorboard\n",
      "    /usr/local/bin/tf_upgrade_v2\n",
      "    /usr/local/bin/tflite_convert\n",
      "    /usr/local/bin/toco\n",
      "    /usr/local/bin/toco_from_protos\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.2.0rc1.dist-info/*\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
      "Proceed (y/n)? y\n",
      "y\n",
      "  Successfully uninstalled tensorflow-2.2.0rc1\n",
      "\u001b[33mWARNING: Skipping tensorflow-base as it is not installed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow-gpu tensorflow tensorflow-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "_aeeeD0WpJ_7",
    "outputId": "18b58fb1-fb15-4628-8b98-7924b109510d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling Keras-2.2.5:\n",
      "  Successfully uninstalled Keras-2.2.5\n",
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 1.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "keras"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip uninstall keras -y\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dydTLlC0oA1Y",
    "outputId": "3f984d8b-a4aa-4fe4-be0f-deb7298caa5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8MB 40kB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 46.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.2)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (46.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=a8c39d9d22bcce2579a4fbadb503c85730e9f0cccfe04432bf78f6ab39eb3bb4\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "Installing collected packages: tensorflow-estimator, gast, tensorflow\n",
      "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
      "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
      "  Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "Successfully installed gast-0.2.2 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "gast",
         "tensorflow"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0Z7Cn3ZCb2Nh",
    "outputId": "0fd38c82-f99c-4f05-bcf8-ee3886a0673e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/e7/172a9eeee2bf44fe6f02922d075ece11a0dbd026e672b9fe4716745ba142/tensorflow_gpu-2.1.0-cp36-cp36m-win_amd64.whl (356.5MB)\n",
      "Collecting six>=1.12.0 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
      "Collecting tensorflow-gpu-estimator<2.2.0,>=2.1.0rc0 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/06/9e/57edfd2684d46992850522bf3dad4807fa15b80ade090f64ffa544abbeea/tensorflow_gpu_estimator-2.1.0-py2.py3-none-any.whl (464kB)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
      "Collecting keras-preprocessing>=1.1.0 (from tensorflow-gpu)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting numpy<2.0,>=1.16.0 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/2d/24/82c216bbf8f9a781d8ff84899f95e31aaa6f219f999ae8b254b32595ac76/numpy-1.18.2-cp36-cp36m-win_amd64.whl (12.8MB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/12/5f/e781305bd0428f02aca645e23c09a75c508a063bf0247da9deda94d58b37/grpcio-1.27.2-cp36-cp36m-win_amd64.whl (2.0MB)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\" (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/2f/fcb6150813b89d628749784370132e431f687ebab5a1063eb298cc941f76/scipy-1.4.1-cp36-cp36m-win_amd64.whl (30.8MB)\n",
      "Collecting gast==0.2.2 (from tensorflow-gpu)\n",
      "  Using cached https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting absl-py>=0.7.0 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "Collecting wheel>=0.26; python_version >= \"3\" (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
      "Collecting wrapt>=1.11.1 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz\n",
      "Collecting protobuf>=3.8.0 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/52/a71156b82dbb8a40833b7a571e22c9e65ca4204a56739f97d3eaa25d111e/protobuf-3.11.3-cp36-cp36m-win_amd64.whl (1.1MB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-gpu)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/49/2233e63052d5686c72131b579837ddfb98ba9dd0b92bb91efcb441ada8ce/opt_einsum-3.2.0-py3-none-any.whl (63kB)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
      "Collecting astor>=0.6.0 (from tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.8 (from tensorflow-gpu)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/a5/d6f8a6e71f15364d35678a4ec8a0186f980b3bd2545f40ad51dd26a87fb1/Werkzeug-1.0.0-py2.py3-none-any.whl (298kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)\n",
      "Collecting setuptools>=41.0.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/df/635cdb901ee4a8a42ec68e480c49f85f4c59e8816effbf57d9e6ee8b3588/setuptools-46.1.3-py3-none-any.whl (582kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl (58kB)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/b0/cc391ebf8ebf7855cdcfe0a9a4cdc8dcd90287c90e1ac22651d104ac6481/google_auth-1.12.0-py2.py3-none-any.whl (83kB)\n",
      "Collecting h5py (from keras-applications>=1.0.8->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/fa/bee65d2dbdbd3611702aafd128139c53c90a1285f169ba5467aab252e27a/h5py-2.10.0-cp36-cp36m-win_amd64.whl (2.4MB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl (58kB)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl (125kB)\n",
      "Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl (156kB)\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "Building wheels for collected packages: gast, absl-py, wrapt, termcolor\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7546 sha256=b54b374c9a7bce8c4874e7ed323b18e530bef643188f4a134818cff5af309ddd\n",
      "  Stored in directory: C:\\Users\\Hp\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.9.0-cp36-none-any.whl size=121936 sha256=fa235e7c9fd4a7d59e48ee6ee53f2ec53aec5723d330026afaee240b86a79b30\n",
      "  Stored in directory: C:\\Users\\Hp\\AppData\\Local\\pip\\Cache\\wheels\\8e\\28\\49\\fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-win_amd64.whl size=33230 sha256=403a601bd18a3aeb7e37f05294af3732e3bcee34c5d1fb9a43417288d52edcd2\n",
      "  Stored in directory: C:\\Users\\Hp\\AppData\\Local\\pip\\Cache\\wheels\\b1\\c2\\ed\\d62208260edbd3fa7156545c00ef966f45f2063d0a84f8208a\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-cp36-none-any.whl size=4837 sha256=0c032bdc1c226bbdfcaa60255d327c387d10f26522c04d4ace17194d804d15fa\n",
      "  Stored in directory: C:\\Users\\Hp\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "Successfully built gast absl-py wrapt termcolor\n",
      "Installing collected packages: six, tensorflow-gpu-estimator, absl-py, werkzeug, setuptools, markdown, numpy, protobuf, idna, urllib3, chardet, certifi, requests, oauthlib, requests-oauthlib, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, wheel, grpcio, tensorboard, keras-preprocessing, scipy, gast, wrapt, termcolor, opt-einsum, google-pasta, astor, h5py, keras-applications, tensorflow-gpu\n",
      "  Found existing installation: six 1.12.0\n",
      "    Uninstalling six-1.12.0:\n",
      "      Successfully uninstalled six-1.12.0\n",
      "  Found existing installation: absl-py 0.7.1\n",
      "    Uninstalling absl-py-0.7.1:\n",
      "      Successfully uninstalled absl-py-0.7.1\n",
      "  Found existing installation: Werkzeug 0.15.4\n",
      "    Uninstalling Werkzeug-0.15.4:\n",
      "      Successfully uninstalled Werkzeug-0.15.4\n",
      "  Found existing installation: setuptools 41.0.1\n",
      "    Uninstalling setuptools-41.0.1:\n",
      "      Successfully uninstalled setuptools-41.0.1\n",
      "  Found existing installation: Markdown 3.1.1\n",
      "    Uninstalling Markdown-3.1.1:\n",
      "      Successfully uninstalled Markdown-3.1.1\n",
      "  Found existing installation: numpy 1.16.3\n",
      "    Uninstalling numpy-1.16.3:\n",
      "      Successfully uninstalled numpy-1.16.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: tensorflow 1.14.0 has requirement tensorboard<1.15.0,>=1.14.0, but you'll have tensorboard 2.1.1 which is incompatible.\n",
      "ERROR: flair 0.4.2 has requirement urllib3<1.25,>=1.20, but you'll have urllib3 1.25.8 which is incompatible.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\users\\\\hp\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 19.2.2, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "colab_type": "code",
    "id": "cNQ9YRlMnEOk",
    "outputId": "8b292dd8-ae61-4e88-b9ba-4e7ed9abd988"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0330 03:13:42.170299 23156 deprecation_wrapper.py:119] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0330 03:13:42.174289 23156 deprecation_wrapper.py:119] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0330 03:13:42.182266 23156 deprecation_wrapper.py:119] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0330 03:13:42.367770 23156 deprecation_wrapper.py:119] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3692276c0c24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import backend\n",
    "assert len(backend.tensorflow_backend._get_available_gpus()) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N31wqboEnEOm",
    "outputId": "c257f2d1-1341-4fe5-c9e2-bdcea3f22351",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pZqwsmTJnEOr",
    "outputId": "67aa64ff-8e89-4a81-b789-f8726872ddd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce MX150'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "03dQLWLvnEO1",
    "outputId": "0a668f13-8fb3-4ca8-c2f7-361426b7b34a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 29 18:40:13 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P0    31W / 250W |    353MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qlzZsMXVCKH"
   },
   "source": [
    "### Creating Language Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2h4nHNwnVCKJ"
   },
   "outputs": [],
   "source": [
    "male_pronouns   = [\"he\",  \"him\", \"his$\", \"his\", \"himself\"]\n",
    "female_pronouns = [\"she\", \"her\", \"her$\", \"hers\", \"herself\"]\n",
    "neutral_pronouns= [\"zie\", \"zim\", \"zir\", \"zis\", \"zieself\"]\n",
    "merged_pronouns = [\"he/she\", \"him/her\", \"his/her\", \"his/hers\", \"himself/herself\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sim_9aXgVCKO"
   },
   "outputs": [],
   "source": [
    "gender_pronouns_dict = {}\n",
    "gender_honorific_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IC4J8YREVCKV"
   },
   "outputs": [],
   "source": [
    "for (g1,g2,g3,g4) in zip(male_pronouns, female_pronouns, neutral_pronouns, merged_pronouns):\n",
    "    element = {\"male\": g1.replace(\"$\",\"\"), \"female\":g2.replace(\"$\",\"\"), \"neutral\":g3, \"merged\":g4}\n",
    "    gender_pronouns_dict[g1] = gender_pronouns_dict[g2] = gender_pronouns_dict[g3] = gender_pronouns_dict[g4] =element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmE6CL7PVCKd"
   },
   "outputs": [],
   "source": [
    "male_hons   =  [\"Mr.\", \"Mr\", \"Md.\", \"Md\", \"Sir\", \"Lord\", \"Mister\"]\n",
    "female_hons =  [\"Ms.\", \"Ms\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Miss\"]\n",
    "neutral_hons = [\"Mx.\", \"Mx\", \"Mx.\", \"Mx\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]\n",
    "married_hons = [\"Mrs.\", \"Mrs\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Mis'ess\"]\n",
    "merged_hons =  [\"Mr./Ms.\", \"Mr/Ms\", \"Md./Mst.\", \"Md/Mst\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbb4Jf6mVCKk"
   },
   "outputs": [],
   "source": [
    "for (h1,h2,h3,h4,h5) in zip(male_hons, female_hons, neutral_hons, married_hons, merged_hons):\n",
    "    element = {\"male\": h1, \"female\":h2, \"neutral\":h3, \"married_fem\":h4, \"merged\":h5}\n",
    "    gender_honorific_dict[h1] = gender_honorific_dict[h2] = gender_honorific_dict[h3] = \\\n",
    "    gender_honorific_dict[h4] = gender_honorific_dict[h5] = element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TzgZxsSUVCKq"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yTkWcUAYH7n"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZN82xZJgVCKr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "#from segtok.segmenter import split_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MoC0zGDKggFj"
   },
   "outputs": [],
   "source": [
    "import flair\n",
    "assert flair.__version__=='0.4.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKRKCr8uVCKv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Be8BR8KQVCKz"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import neuralcoref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZuAm9_9VCK5"
   },
   "source": [
    "### Loading Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "UI8M4VyXVDV6",
    "outputId": "e83661bc-e8fb-4277-8acb-a3972293b677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!git clone --single-branch --branch development2 https://github.com/Masum06/GenderDebiasing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nA8Mt85PUHJy",
    "outputId": "ece44004-244e-4cc8-d55f-ff41fcc3836c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/GenderDebiasing\n"
     ]
    }
   ],
   "source": [
    "cd GenderDebiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjlMu-sNVCK6"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "char2idx = 'resources/char2idx.json'\n",
    "idx2char = 'resources/idx2char.json'\n",
    "with open(char2idx, 'r') as fp:\n",
    "    char2idx = json.load(fp)\n",
    "    \n",
    "with open(idx2char, 'r') as fp:\n",
    "    idx2char = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "TzVfTDkDoqS4",
    "outputId": "68627f0c-874d-4271-9029-c0f3793a5dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-30 03:15:58,877 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G9u1EvUfpr34",
    "outputId": "709d0e83-ae6f-42bd-ce66-a46248a9ab08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "h0BOOa4fVCK-",
    "outputId": "0909c5c3-1266-44dc-9fd3-611e986907cd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-30 03:16:11,927 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2020-03-30 03:16:12,172 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2020-03-30 03:16:12,688 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2020-03-30 03:16:12,697 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_name = 'resources/char_rnn_hsc_model_0.h5'\n",
    "model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ggCw99GvVCLC",
    "outputId": "b67847e4-8514-4190-eadc-89e7de20c632"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1b7720ff128>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nlp = spacy.load('en_core_web_lg') # en_core_web_sm #en_core_web_md\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8-VH-28OqMGc",
    "outputId": "baf7a12d-9229-42b8-94c2-86185c301941"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "id": "aW9R7VuFqRua",
    "outputId": "e7aeaecd-3963-4fc9-8af5-321104ab6543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\n",
      "Collecting torch==1.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/50a05de5337f7a924bb8bd70c6936230642233e424d6a9747ef1cfbde353/torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (773.1MB)\n",
      "\u001b[K     |████████████████████████████████| 773.1MB 16kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.3.0) (1.18.2)\n",
      "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 1.3.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.3.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "torch"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip uninstall torch -y\n",
    "!pip install torch==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "eP7eFWBaVCLH",
    "outputId": "e01fc5c0-85e7-4650-c4cc-fb6530ca3bb6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-30 03:16:37,105 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n",
      "2020-03-30 03:17:03,712 loading file C:\\Users\\Hp\\.flair\\models\\en-pos-ontonotes-v0.2.pt\n"
     ]
    }
   ],
   "source": [
    "tagger_ner = SequenceTagger.load('ner')\n",
    "tagger_pos = SequenceTagger.load('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyHJZ4t-VCLL"
   },
   "source": [
    "### Necessary Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2FRQ-qzEzDF"
   },
   "source": [
    "Name2Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UExr_6fiVCLM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Converts a name into vector\n",
    "def name2vectorTest(name):\n",
    "    name = name.lower()\n",
    "    new_name = \"\"\n",
    "    for char in name:\n",
    "      if char in char2idx:\n",
    "        new_name += char\n",
    "    chars = list(new_name)\n",
    "    vector = [ char2idx[c] for c in chars ]\n",
    "    return np.array(vector)\n",
    "\n",
    "# Converts names to fixed size tensor\n",
    "def names2tensorTest(names, maxlen=25):\n",
    "    namelist = [name2vectorTest(name) for name in names]\n",
    "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
    "\n",
    "def name2gender(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  if result:\n",
    "    return \"male\"\n",
    "  else:\n",
    "    return \"female\"\n",
    "  \n",
    "def isMale(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXxZYr_mflVz"
   },
   "source": [
    "Storing Names in Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJzj_UF_VCMX"
   },
   "outputs": [],
   "source": [
    "def store(name, name_found, Name2Key, Key2Name, num_keys): \n",
    "    \n",
    "    if name_found not in Name2Key:\n",
    "        #global num_keys\n",
    "        num_keys+=1\n",
    "        key = \"PER_\"+str(num_keys)\n",
    "        #gender = name2gender(name_found)\n",
    "        alias = None\n",
    "        element = {\"name\": name, \"key\": key, \"gender\":None, \"alias\":alias, \"is_alias\": False, \"alias_to\": None}\n",
    "        Name2Key[name_found] = element\n",
    "        Key2Name[key] = {\"name\": name, \"gender\": None, \"alias\": alias}\n",
    "    \n",
    "    if name not in Name2Key:\n",
    "        element_alias = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
    "        Name2Key[name] = element_alias\n",
    "        Name2Key[name_found][\"alias\"] = name\n",
    "        \n",
    "    return Name2Key[name_found][\"key\"], num_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSYCQfJcOTLU"
   },
   "source": [
    "# Unit Gender Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJLCTIOQOYav"
   },
   "outputs": [],
   "source": [
    "def gender_encrypt(s):\n",
    "  s = ' '.join(s.split())\n",
    "  doc = nlp(s)\n",
    "  tokenized_text = ' '.join([token.text for token in doc])\n",
    "  oracle = []\n",
    "  coref2name = {}\n",
    "\n",
    "  # POS TAG\n",
    "  sent = Sentence(tokenized_text)\n",
    "  tagger_ner.predict(sent)\n",
    "  tagger_pos.predict(sent)\n",
    "  tagged_list = sent.to_tagged_string().split()\n",
    "  tokens_pos = []\n",
    "  pos = []\n",
    "  count = 0\n",
    "  for i in range(0,len(tagged_list),2):\n",
    "      tokens_pos.append(tagged_list[i])\n",
    "      count = count+1\n",
    "      pos.append(tagged_list[i+1])\n",
    "      \n",
    "      if tagged_list[i].lower() in male_pronouns+female_pronouns:\n",
    "          oracle.append(2)\n",
    "      elif tagged_list[i+1] in ['<B-PER/NNP>', '<I-PER/NNP>', '<E-PER/NNP>', '<S-PER/NNP>']:\n",
    "          oracle.append(4)\n",
    "      else:\n",
    "          oracle.append(0)\n",
    "\n",
    "  # COREFERENCE RESOLUTION \n",
    "  if len(doc)!=len(tokens_pos):\n",
    "    tokens_doc = [token.text for token in doc]\n",
    "    print(\"doc:\", tokens_doc)\n",
    "    print(\"pos:\", tokens_pos)\n",
    "    return None, None\n",
    "  \n",
    "  coref_stack = []\n",
    "  name_stack = []\n",
    "  for i in range(len(doc)):\n",
    "      token = doc[i]\n",
    "      if token._.in_coref:\n",
    "          coref_stack.append(tokens_pos[i])\n",
    "          if oracle[i] == 4:\n",
    "              name_stack.append(tokens_pos[i])\n",
    "          oracle[i] += 1\n",
    "      else:\n",
    "          if len(name_stack) > 0:\n",
    "              name = ' '.join(name_stack)\n",
    "              coref = ' '.join(coref_stack)\n",
    "              #name2coref[name] = coref\n",
    "              coref2name[coref] = name\n",
    "              name_stack.clear()\n",
    "          coref_stack.clear()\n",
    "\n",
    "  # IF THE SENTENCE DOES NOT END WITH A PERIOD OR SPECIAL CHARACTER\n",
    "  if len(name_stack) > 0:\n",
    "      name = ' '.join(name_stack)\n",
    "      name2coref[name] = ' '.join(coref_stack)\n",
    "      name_stack.clear()\n",
    "  coref_stack.clear()\n",
    "\n",
    "  Name2Key = {}\n",
    "  Key2Name = {}\n",
    "  encrypted = []\n",
    "  num_keys = 0\n",
    "  i = 0\n",
    "  while i<len(tokens_pos): \n",
    "      #print(\"Oracle \", i, tokens_pos[i])\n",
    "      if oracle[i] == 2:\n",
    "          pronoun = tokens_pos[i].lower()\n",
    "          if pos[i] == '<PRP$>':\n",
    "              pronoun+=\"$\"\n",
    "          encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "      elif oracle[i] == 3:\n",
    "          coref = doc[i]._.coref_clusters[0][0].text\n",
    "          pronoun = tokens_pos[i].lower()\n",
    "          if pos[i] == '<PRP$>':\n",
    "              pronoun+=\"$\"\n",
    "          if coref in coref2name:\n",
    "            name_found = coref2name[coref]\n",
    "            key = Name2Key[name_found][\"key\"]\n",
    "            if pronoun in male_pronouns:\n",
    "              Name2Key[name_found][\"gender\"] = \"male\"\n",
    "            else if pronoun in female_pronouns:\n",
    "              Name2Key[name_found][\"gender\"] = \"female\"\n",
    "            else:\n",
    "              Name2Key[name_found][\"gender\"] = \"<|unk|>\"\n",
    "            encrypted.append(\"<|coref|>\")\n",
    "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "            encrypted.append(key)\n",
    "          else:\n",
    "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "          \n",
    "      elif oracle[i] in [4,5]:\n",
    "          if i > 0 and tokens_pos[i-1] in gender_honorific_dict:\n",
    "            hons = encrypted.pop()\n",
    "            if hons in male_hons:\n",
    "              gender = \"male\"\n",
    "            else if hons in female_hons+married_hons:\n",
    "              gender = \"female\"\n",
    "            else:\n",
    "              gender = \"<|unk|>\"\n",
    "            encrypted.append(\"<|hons|>\")\n",
    "            encrypted.append(gender_honorific_dict[hons][\"merged\"])\n",
    "          if pos[i] == '<S-PER/NNP>':\n",
    "              name = tokens_pos[i]\n",
    "          elif pos[i] == '<B-PER/NNP>':\n",
    "              name = \"\"\n",
    "              while True:\n",
    "                  #print(i, oracle[i])\n",
    "                  name += tokens_pos[i]\n",
    "                  if pos[i] == '<E-PER/NNP>':\n",
    "                      break\n",
    "                  name += \" \"\n",
    "                  i+=1\n",
    "          \n",
    "          if oracle[i] == 4:\n",
    "              key, num_keys = store(name, name, Name2Key, Key2Name, num_keys)\n",
    "              encrypted.append(key)\n",
    "          else:\n",
    "              coref = doc[i]._.coref_clusters[0][0].text\n",
    "              name_found = coref2name[coref]\n",
    "              if name == name_found:\n",
    "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
    "                  encrypted.append(key)\n",
    "              else:\n",
    "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
    "                  encrypted.append(\"<|alias|>\")\n",
    "                  encrypted.append(key)\n",
    "          Name2Key[key][\"gender\"] = gender\n",
    "      else:\n",
    "        encrypted.append(tokens_pos[i])\n",
    "      i+=1\n",
    "      \n",
    "  encrypted_text = ' '.join(encrypted)\n",
    "\n",
    "  return tokenized_text, Key2Name, encrypted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMItOjUbUQNf"
   },
   "source": [
    "# Gender Decryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "quTM_EeiVCMu"
   },
   "outputs": [],
   "source": [
    "def gender_decrypt(encrypted_text, Key2Name):\n",
    "  encrypted = encrypted_text.split()\n",
    "  decrypted = []\n",
    "  i = 0\n",
    "  while i != len(encrypted):\n",
    "    token = encrypted[i]\n",
    "    if token in Key2Name:\n",
    "      decrypted.append(Key2Name[token][\"name\"])\n",
    "    elif token == '<|alias|>':\n",
    "      i+=1\n",
    "      key = encrypted[i]\n",
    "      if Key2Name[key][\"alias\"]:\n",
    "        decrypted.append(Key2Name[key][\"alias\"])\n",
    "      else:\n",
    "        decrypted.append(Key2Name[key][\"name\"])\n",
    "    elif token == '<|coref|>':\n",
    "      startOfSent = (i==0 or encrypted[i-1] == \".\")\n",
    "      pronoun =  encrypted[i+1]\n",
    "      key = encrypted[i+2]\n",
    "      gender = Key2Name[key][\"gender\"].lower()\n",
    "      decrypted_pronoun = gender_pronouns_dict[pronoun][gender]\n",
    "      decrypted_pronoun = decrypted_pronoun[0].upper()+decrypted_pronoun[1:] if startOfSent else decrypted_pronoun\n",
    "      decrypted.append(decrypted_pronoun)\n",
    "      i+=2\n",
    "    elif token == \"<|hons|>\":\n",
    "      hons = encrypted[i+1]\n",
    "      key = encrypted[i+2] # NEED CHECK FOR HONS IN ALIAS\n",
    "      gender = Key2Name[key][\"gender\"].lower()\n",
    "      decrypted.append(gender_honorific_dict[hons][gender])\n",
    "      i+=1\n",
    "    elif token == \"he/she\":\n",
    "        if i==0 or encrypted[i-1] == \".\":\n",
    "            decrypted.append(\"He/She\")\n",
    "        else:\n",
    "            decrypted.append(\"he/she\")\n",
    "    else:\n",
    "      decrypted.append(token)\n",
    "    i+=1\n",
    "\n",
    "  decrypted_text = ' '.join(decrypted)\n",
    "  #decrypted_text = decrypted_text.replace(\" .\", \".\")\n",
    "  return decrypted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qv5Y4nngq9AJ"
   },
   "outputs": [],
   "source": [
    "key2name_changed = {'PER_1': {'name': 'Abira',\n",
    "    'key': 'PER_1',\n",
    "    'gender': 'Female',\n",
    "    'alias': None,\n",
    "    'is_alias': False,\n",
    "    'alias_to': None},\n",
    "  'PER_2': {'name': 'Shibir',\n",
    "    'key': 'PER_2',\n",
    "    'gender': 'Male',\n",
    "    'alias': None,\n",
    "    'is_alias': False,\n",
    "    'alias_to': None}\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_Ad5ljDRvvB"
   },
   "source": [
    "### Testing Encryption-Decryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDUandyxxJ8m"
   },
   "outputs": [],
   "source": [
    "s = \"Mr. John is not a doctor. Ms. Katy is also not a nurse. John can fly, but she cannot swim.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJnQwJd5S_GJ"
   },
   "outputs": [],
   "source": [
    "s = \"Morshed Khan told newsmen that 'BNP is a massive party with huge popularity and public acceptance.' This party is now running its operations over Skype. He (Tarique) is operating from London over Skype and that too with only selected leaders. It has turned into the ‘Bangladesh Nationalist Skype Party’. This is painful. I believe the next generation must assume leadership within the party — that would be my recommendation.”\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WL1lFCFnEQF"
   },
   "outputs": [],
   "source": [
    "s = \"Dineshwar then left behind his wife’s stabbed body and hanged himself from a tree in a field nearby.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YsmaikFZFHtl",
    "outputId": "7d647507-2da3-47de-ca79-d97d8e59ab6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qLWPn4lR1Ss",
    "outputId": "b90350a4-f0d6-4bec-9fa7-a22bec971b8e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_1 then left behind <|coref|> his/her PER_1 wife ’s stabbed body and hanged <|coref|> himself/herself PER_1 from a tree in a field nearby .\n",
      "{'PER_1': {'name': 'Dineshwar', 'gender': 'male', 'alias': None}}\n",
      "5.390132427215576\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "text, key2name, encrypted = gender_encrypt(s)\n",
    "end = time.time()\n",
    "\n",
    "print(encrypted)\n",
    "print(key2name)\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XB-PJPr7lIuJ"
   },
   "outputs": [],
   "source": [
    "key2name = {'PER_1': {'name': 'Dineshwar', 'gender': 'merged', 'alias': None}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "eeSiLybyVCMx",
    "outputId": "1ea4a950-3955-453a-9554-fa0b59daaaf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dineshwar then left behind his/her wife ’s stabbed body and hanged himself/herself from a tree in a field nearby .'"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrypted = gender_decrypt(encrypted, key2name)\n",
    "decrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z2DGAAsDT6HN",
    "outputId": "948fe8a6-356f-4deb-c72d-7758be9e6431"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrypted == text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "PKBfFmbYvtad",
    "outputId": "33c9a311-0b5e-49f9-86ee-212928bbeff8",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gender_encrypt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3cf708c253ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0men\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgender_encrypt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mr Masum Hasan is not a doctor. Masum is an engineer.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0men\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gender_encrypt' is not defined"
     ]
    }
   ],
   "source": [
    "en = gender_encrypt(\"Mr Masum Hasan is not a doctor. Masum is an engineer.\")\n",
    "en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-uNtEcNaJQt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Gender_Encrypter_Decrypter.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
