{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zalandoresearch/flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-14 23:06:35,626 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from segtok.segmenter import split_single\n",
    "\n",
    "# load the NER tagger\n",
    "tagger = SequenceTagger.load('ner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namesAndSentences(text):\n",
    "    sentences_obj = [Sentence(sent, use_tokenizer=True) for sent in split_single(text)]\n",
    "    tagger: SequenceTagger = SequenceTagger.load('ner')\n",
    "    tagger.predict(sentences_obj)\n",
    "    tegged_sentences = tagger.predict(sentences_obj)\n",
    "    #name_gender = {}\n",
    "    sentences = []\n",
    "    male_names = []\n",
    "    female_names = []\n",
    "    for tagged_sent in tegged_sentences:\n",
    "        sent_dict = tagged_sent.to_dict(tag_type='ner')\n",
    "        sentences += [sent_dict['text']]\n",
    "        if sent_dict['entities']:\n",
    "            for entity in sent_dict['entities']:\n",
    "                if entity['type'] == 'PER':\n",
    "                    name = entity['text']\n",
    "                    gender = isMale(name)\n",
    "                    #name_gender[name] = gender\n",
    "                    if gender:\n",
    "                        male_names.append(name)\n",
    "                    else:\n",
    "                        female_names.append(name)\n",
    "                    print(name, gender)\n",
    "    return male_names, female_names, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanName(name, names):\n",
    "    for x in names:\n",
    "        if x in name:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name To Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-14 23:06:44,122 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2019-10-14 23:06:44,144 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2019-10-14 23:06:44,160 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2019-10-14 23:06:44,279 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2019-10-14 23:06:44,287 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2019-10-14 23:06:44,518 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2019-10-14 23:06:44,612 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2019-10-14 23:06:44,621 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# LOAD SAVED MODEL\n",
    "from keras.models import load_model\n",
    "\n",
    "#del model  # deletes the existing model\n",
    "model = load_model('char_rnn_hsc_model_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('char2idx.json', 'r') as fp:\n",
    "    char2idx = json.load(fp)\n",
    "    \n",
    "with open('idx2char.json', 'r') as fp:\n",
    "    idx2char = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Converts a name into vector\n",
    "def name2vectorTest(name):\n",
    "    name = name.lower()\n",
    "    new_name = \"\"\n",
    "    for char in name:\n",
    "      if char in char2idx:\n",
    "        new_name += char\n",
    "    chars = list(new_name)\n",
    "    vector = [ char2idx[c] for c in chars ]\n",
    "    return np.array(vector)\n",
    "\n",
    "# Converts names to fixed size tensor\n",
    "def names2tensorTest(names, maxlen=25):\n",
    "    namelist = [name2vectorTest(name) for name in names]\n",
    "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
    "\n",
    "def name2gender(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  if result:\n",
    "    print(\"Male\")\n",
    "  else:\n",
    "    print(\"Female\")\n",
    "  \n",
    "def isMale(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isMale(\"khaleesi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-14 23:06:46,045 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n",
      "Masum 1\n",
      "Onti 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Masum'], ['Onti'], ['Masum is considering to date Onti.'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namesAndSentences(\"Masum is considering to date Onti.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constituency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load your usual SpaCy model (one of SpaCy English models)\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x23742a22390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add neural coref to SpaCy's pipe\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[My sister: [My sister, She], a dog: [a dog, him]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You're done. You can now use NeuralCoref as you usually manipulate a SpaCy document annotations.\n",
    "doc = nlp(u'My sister has a dog. She loves him.')\n",
    "\n",
    "doc._.has_coref\n",
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
