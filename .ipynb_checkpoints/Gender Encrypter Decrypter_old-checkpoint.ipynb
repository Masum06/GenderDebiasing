{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zalandoresearch/flair\n",
    "\n",
    "https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flair\n",
    "#!pip uninstall spacy\n",
    "#!pip install -U spacy==2.1.0\n",
    "##!python -m spacy download en\n",
    "#!python -m spacy download en_core_web_lg\n",
    "##!python -m spacy download en_core_web_md\n",
    "#!pip install neuralcoref --no-binary neuralcoref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_pronouns   = [\"he\",  \"him\", \"his$\", \"his\", \"himself\"]\n",
    "female_pronouns = [\"she\", \"her\", \"her$\", \"hers\", \"herself\"]\n",
    "neutral_pronouns= [\"zie\", \"zim\", \"zir\", \"zis\", \"zieself\"]\n",
    "merged_pronouns = [\"he/she\", \"him/her\", \"his/her\", \"his/hers\", \"himself/herself\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_pronouns_dict = {}\n",
    "gender_honorific_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (g1,g2,g3,g4) in zip(male_pronouns, female_pronouns, neutral_pronouns, merged_pronouns):\n",
    "    element = {\"male\": g1, \"female\":g2, \"neutral\":g3, \"merged\":g4}\n",
    "    gender_pronouns_dict[g1] = gender_pronouns_dict[g2] = gender_pronouns_dict[g3] = gender_pronouns_dict[g4] =element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_hons   =  [\"Mr.\", \"Mr\", \"Md.\", \"Md\", \"Sir\", \"Lord\", \"Mister\"]\n",
    "female_hons =  [\"Ms.\", \"Ms\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Miss\"]\n",
    "neutral_hons = [\"Mx.\", \"Mx\", \"Mx.\", \"Mx\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]\n",
    "married_hons = [\"Mrs.\", \"Mrs\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Mis'ess\"]\n",
    "merged_hons =  [\"Mr./Ms.\", \"Mr/Ms\", \"Md./Mst.\", \"Md/Mst\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (h1,h2,h3,h4,h5) in zip(male_hons, female_hons, neutral_hons, married_hons, merged_hons):\n",
    "    element = {\"male\": h1, \"female\":h2, \"neutral\":h3, \"married_fem\":h4, \"merged\":h5}\n",
    "    gender_honorific_dict[h1] = gender_honorific_dict[h2] = gender_honorific_dict[h3] = \\\n",
    "    gender_honorific_dict[h4] = gender_honorific_dict[h5] = element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from segtok.segmenter import split_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import neuralcoref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('char2idx.json', 'r') as fp:\n",
    "    char2idx = json.load(fp)\n",
    "    \n",
    "with open('idx2char.json', 'r') as fp:\n",
    "    idx2char = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-02 23:14:32,201 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2019-11-02 23:14:32,258 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2019-11-02 23:14:32,278 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2019-11-02 23:14:32,407 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2019-11-02 23:14:32,415 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2019-11-02 23:14:32,636 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2019-11-02 23:14:32,810 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2019-11-02 23:14:32,819 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model('char_rnn_hsc_model_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1ec7111dbe0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg') # en_core_web_sm #en_core_web_md\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-02 23:14:51,085 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n",
      "2019-11-02 23:15:12,914 loading file C:\\Users\\Hp\\.flair\\models\\en-pos-ontonotes-v0.2.pt\n"
     ]
    }
   ],
   "source": [
    "tagger_ner = SequenceTagger.load('ner')\n",
    "tagger_pos = SequenceTagger.load('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name2Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Converts a name into vector\n",
    "def name2vectorTest(name):\n",
    "    name = name.lower()\n",
    "    new_name = \"\"\n",
    "    for char in name:\n",
    "      if char in char2idx:\n",
    "        new_name += char\n",
    "    chars = list(new_name)\n",
    "    vector = [ char2idx[c] for c in chars ]\n",
    "    return np.array(vector)\n",
    "\n",
    "# Converts names to fixed size tensor\n",
    "def names2tensorTest(names, maxlen=25):\n",
    "    namelist = [name2vectorTest(name) for name in names]\n",
    "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
    "\n",
    "def name2gender(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  if result:\n",
    "    return \"Male\"\n",
    "  else:\n",
    "    return \"Female\"\n",
    "  \n",
    "def isMale(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(name, name_found):\n",
    "    if name_found in Name2Key:\n",
    "        if name not in Name2Key:\n",
    "            element = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
    "            Name2Key[name] = element\n",
    "    else:\n",
    "        global num_keys\n",
    "        num_keys+=1\n",
    "        key = \"PER_\"+str(num_keys)\n",
    "        gender = name2gender(name)\n",
    "        alias = None\n",
    "        \n",
    "        if name!=name_found:\n",
    "            element_alias = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
    "            Name2Key[name] = element_alias\n",
    "            alias = name\n",
    "        \n",
    "        element = {\"name\": name, \"key\": key, \"gender\":gender, \"alias\":alias, \"is_alias\": False, \"alias_to\": None}\n",
    "        Name2Key[name_found] = element\n",
    "        Key2Name[key] = element\n",
    "        \n",
    "    return Name2Key[name_found][\"key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Input Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '''Biden said he would beat the President \"like a drum\" and that Trump \"knows it\" because he has spent \"a lot of money to make sure I'm not\" the nominee.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ' '.join(s.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS-NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_pos = []\n",
    "pos = []\n",
    "oracle = []\n",
    "coref2name = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = Sentence(s, use_tokenizer=True)\n",
    "tagger_ner.predict(sent)\n",
    "tagger_pos.predict(sent)\n",
    "tagged_list = sent.to_tagged_string().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(tagged_list),2):\n",
    "    tokens_pos.append(tagged_list[i])\n",
    "    pos.append(tagged_list[i+1])\n",
    "    \n",
    "    if tagged_list[i].lower() in male_pronouns+female_pronouns:\n",
    "        oracle.append(2)\n",
    "    elif tagged_list[i+1] in ['<B-PER/NNP>', '<I-PER/NNP>', '<E-PER/NNP>', '<S-PER/NNP>']:\n",
    "        oracle.append(4)\n",
    "    else:\n",
    "        oracle.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coreference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(doc)==len(tokens_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokens = [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacy_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tokens_pos) - set(spacy_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(spacy_tokens) - set(tokens_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Biden said he would beat the President \"like a drum\" and that Trump \"knows it\" because he has spent \"a lot of money to make sure I\\'m not\" the nominee.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumption: The sentence will end with period or any other special token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_stack = []\n",
    "name_stack = []\n",
    "for i in range(len(doc)):\n",
    "    token = doc[i]\n",
    "    if token._.in_coref:\n",
    "        coref_stack.append(tokens_pos[i])\n",
    "        if oracle[i] == 4:\n",
    "            name_stack.append(tokens_pos[i])\n",
    "        oracle[i] += 1\n",
    "    else:\n",
    "        if len(name_stack) > 0:\n",
    "            name = ' '.join(name_stack)\n",
    "            coref = ' '.join(coref_stack)\n",
    "            #name2coref[name] = coref\n",
    "            coref2name[coref] = name\n",
    "            name_stack.clear()\n",
    "        coref_stack.clear()\n",
    "\n",
    "# IF THE SENTENCE DOES NOT END WITH A PERIOD OR SPECIAL CHARACTER\n",
    "if len(name_stack) > 0:\n",
    "    name = ' '.join(name_stack)\n",
    "    name2coref[name] = ' '.join(coref_stack)\n",
    "    name_stack.clear()\n",
    "coref_stack.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Name2Key = {}\n",
    "Key2Name = {}\n",
    "encrypted = []\n",
    "num_keys = 0\n",
    "\n",
    "i = 0\n",
    "while i<len(tokens_pos): \n",
    "    #print(\"Oracle \", i, tokens_pos[i])\n",
    "    if oracle[i] == 0:\n",
    "        encrypted.append(tokens_pos[i])\n",
    "    elif oracle[i] == 1:\n",
    "        if tokens_pos[i] in gender_honorific_dict:\n",
    "            encrypted.append(\"<|hons|>\")\n",
    "            encrypted.append(gender_honorific_dict[tokens_pos[i]][\"merged\"])\n",
    "        else:\n",
    "            encrypted.append(tokens_pos[i])\n",
    "    elif oracle[i] == 2:\n",
    "        pronoun = tokens_pos[i].lower()\n",
    "        if pos[i] == '<PRP$>':\n",
    "            pronoun+=\"$\"\n",
    "        encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "    elif oracle[i] == 3:\n",
    "        coref = doc[i]._.coref_clusters[0][0].text\n",
    "        name_found = coref2name[coref]\n",
    "        key = Name2Key[name_found][\"key\"]\n",
    "        encrypted.append(\"<|coref|>\")\n",
    "        pronoun = tokens_pos[i].lower()\n",
    "        if pos[i] == '<PRP$>':\n",
    "            pronoun+=\"$\"\n",
    "        encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "        encrypted.append(key)\n",
    "        \n",
    "    elif oracle[i] in [4,5]:\n",
    "        if pos[i] == '<S-PER/NNP>':\n",
    "            name = tokens_pos[i]\n",
    "        elif pos[i] == '<B-PER/NNP>':\n",
    "            name = \"\"\n",
    "            while True:\n",
    "                print(i, oracle[i])\n",
    "                name += tokens_pos[i]\n",
    "                if pos[i] == '<E-PER/NNP>':\n",
    "                    break\n",
    "                name += \" \"\n",
    "                i+=1\n",
    "        \n",
    "        if oracle[i] == 4:\n",
    "            key = store(name, name)\n",
    "            encrypted.append(key)\n",
    "        else:\n",
    "            coref = doc[i]._.coref_clusters[0][0].text\n",
    "            name_found = coref2name[coref]\n",
    "            if name == name_found:\n",
    "                key = store(name, name_found)\n",
    "                encrypted.append(key)\n",
    "            else:\n",
    "                key = store(name, name_found)\n",
    "                encrypted.append(\"<|alias|>\")\n",
    "                encrypted.append(key)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['said',\n",
       " '<|alias|>',\n",
       " 'PER_1',\n",
       " 'would',\n",
       " 'beat',\n",
       " 'the',\n",
       " 'President',\n",
       " '\"',\n",
       " 'like',\n",
       " 'a',\n",
       " 'drum',\n",
       " '\"',\n",
       " 'and',\n",
       " 'that',\n",
       " 'PER_2',\n",
       " '\"',\n",
       " 'knows',\n",
       " 'it',\n",
       " '\"',\n",
       " 'because',\n",
       " '<|alias|>',\n",
       " 'PER_1',\n",
       " 'has',\n",
       " 'spent',\n",
       " '\"',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'money',\n",
       " 'to',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'not',\n",
       " '\"',\n",
       " 'the',\n",
       " 'nominee',\n",
       " '.']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'he would beat the President \" like a drum \" and that Trump \" knows it \" because he has spent \" a lot of money to make sure I \\'m not \" the nominee . ': {'name': 'he would beat the President \" like a drum \" and that Trump \" knows it \" because he has spent \" a lot of money to make sure I \\'m not \" the nominee . ',\n",
       "  'is_alias': True,\n",
       "  'alias_to': 'Biden'},\n",
       " 'Biden': {'name': 'he would beat the President \" like a drum \" and that Trump \" knows it \" because he has spent \" a lot of money to make sure I \\'m not \" the nominee . ',\n",
       "  'key': 'PER_1',\n",
       "  'gender': 'Female',\n",
       "  'alias': 'he would beat the President \" like a drum \" and that Trump \" knows it \" because he has spent \" a lot of money to make sure I \\'m not \" the nominee . ',\n",
       "  'is_alias': False,\n",
       "  'alias_to': None},\n",
       " 'Trump': {'name': 'Trump',\n",
       "  'key': 'PER_2',\n",
       "  'gender': 'Female',\n",
       "  'alias': None,\n",
       "  'is_alias': False,\n",
       "  'alias_to': None}}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name2Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PER_1': {'name': 'he would beat the President \" like a drum \" and that Trump \" knows it \" because he has spent \" a lot of money to make sure I \\'m not \" the nominee . ',\n",
       "  'key': 'PER_1',\n",
       "  'gender': 'Female',\n",
       "  'alias': 'he would beat the President \" like a drum \" and that Trump \" knows it \" because he has spent \" a lot of money to make sure I \\'m not \" the nominee . ',\n",
       "  'is_alias': False,\n",
       "  'alias_to': None},\n",
       " 'PER_2': {'name': 'Trump',\n",
       "  'key': 'PER_2',\n",
       "  'gender': 'Female',\n",
       "  'alias': None,\n",
       "  'is_alias': False,\n",
       "  'alias_to': None}}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Key2Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reference can be last name, which is not associated with gender\n",
    "- We have to look for a smaller type of data w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flair\n",
    "flair.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_decrypt(encrypted, Key2Name):\n",
    "  decrypted = []\n",
    "  i = 0\n",
    "  while i != len(encrypted):\n",
    "    token = encrypted[i]\n",
    "    if token in Key2Name:\n",
    "      decrypted.append(Key2Name[token][\"name\"])\n",
    "    elif token == '<|alias|>':\n",
    "      i+=1\n",
    "      key = encrypted[i]\n",
    "      if Key2Name[key][\"alias\"]:\n",
    "        decrypted.append(Key2Name[key][\"alias\"])\n",
    "      else:\n",
    "        decrypted.append(Key2Name[key][\"name\"])\n",
    "    elif token == '<|coref|>':\n",
    "      pronoun =  encrypted[i+1]\n",
    "      key = encrypted[i+2]\n",
    "      gender = Key2Name[key][\"gender\"].lower()\n",
    "      decrypted.append(gender_pronouns_dict[pronoun][gender])\n",
    "      i+=2\n",
    "    elif token == \"<|hons|>\":\n",
    "      hons = encrypted[i+1]\n",
    "      key = encrypted[i+2]\n",
    "      if key in Key2Name:\n",
    "        gender = Key2Name[key][\"gender\"].lower()\n",
    "        decrypted.append(gender_honorific_dict[hons][gender])\n",
    "      else:\n",
    "        i+=2\n",
    "    else:\n",
    "      decrypted.append(token)\n",
    "    i+=1\n",
    "\n",
    "  return ' '.join(decrypted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
