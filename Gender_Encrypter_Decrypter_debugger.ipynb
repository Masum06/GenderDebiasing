{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zalandoresearch/flair\n",
    "\n",
    "https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flair\n",
    "#!pip uninstall spacy\n",
    "#!pip install -U spacy==2.1.0\n",
    "##!python -m spacy download en\n",
    "#!python -m spacy download en_core_web_lg\n",
    "##!python -m spacy download en_core_web_md\n",
    "#!pip install neuralcoref --no-binary neuralcoref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_pronouns   = [\"he\",  \"him\", \"his$\", \"his\", \"himself\"]\n",
    "female_pronouns = [\"she\", \"her\", \"her$\", \"hers\", \"herself\"]\n",
    "neutral_pronouns= [\"zie\", \"zim\", \"zir\", \"zis\", \"zieself\"]\n",
    "merged_pronouns = [\"he/she\", \"him/her\", \"his/her\", \"his/hers\", \"himself/herself\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_pronouns_dict = {}\n",
    "gender_honorific_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (g1,g2,g3,g4) in zip(male_pronouns, female_pronouns, neutral_pronouns, merged_pronouns):\n",
    "    element = {\"male\": g1, \"female\":g2, \"neutral\":g3, \"merged\":g4}\n",
    "    gender_pronouns_dict[g1] = gender_pronouns_dict[g2] = gender_pronouns_dict[g3] = gender_pronouns_dict[g4] =element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_hons   =  [\"Mr.\", \"Mr\", \"Md.\", \"Md\", \"Sir\", \"Lord\", \"Mister\"]\n",
    "female_hons =  [\"Ms.\", \"Ms\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Miss\"]\n",
    "neutral_hons = [\"Mx.\", \"Mx\", \"Mx.\", \"Mx\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]\n",
    "married_hons = [\"Mrs.\", \"Mrs\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Mis'ess\"]\n",
    "merged_hons =  [\"Mr./Ms.\", \"Mr/Ms\", \"Md./Mst.\", \"Md/Mst\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (h1,h2,h3,h4,h5) in zip(male_hons, female_hons, neutral_hons, married_hons, merged_hons):\n",
    "    element = {\"male\": h1, \"female\":h2, \"neutral\":h3, \"married_fem\":h4, \"merged\":h5}\n",
    "    gender_honorific_dict[h1] = gender_honorific_dict[h2] = gender_honorific_dict[h3] = \\\n",
    "    gender_honorific_dict[h4] = gender_honorific_dict[h5] = element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from segtok.segmenter import split_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import neuralcoref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('char2idx.json', 'r') as fp:\n",
    "    char2idx = json.load(fp)\n",
    "    \n",
    "with open('idx2char.json', 'r') as fp:\n",
    "    idx2char = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-08 10:14:03,133 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2019-11-08 10:14:03,172 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2019-11-08 10:14:03,196 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2019-11-08 10:14:03,330 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2019-11-08 10:14:03,337 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2019-11-08 10:14:03,552 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2019-11-08 10:14:03,669 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2019-11-08 10:14:03,678 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model('char_rnn_hsc_model_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x14835964358>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg') # en_core_web_sm #en_core_web_md\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-08 10:14:17,137 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n",
      "2019-11-08 10:14:36,227 loading file C:\\Users\\Hp\\.flair\\models\\en-pos-ontonotes-v0.2.pt\n"
     ]
    }
   ],
   "source": [
    "tagger_ner = SequenceTagger.load('ner')\n",
    "tagger_pos = SequenceTagger.load('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name2Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Converts a name into vector\n",
    "def name2vectorTest(name):\n",
    "    name = name.lower()\n",
    "    new_name = \"\"\n",
    "    for char in name:\n",
    "      if char in char2idx:\n",
    "        new_name += char\n",
    "    chars = list(new_name)\n",
    "    vector = [ char2idx[c] for c in chars ]\n",
    "    return np.array(vector)\n",
    "\n",
    "# Converts names to fixed size tensor\n",
    "def names2tensorTest(names, maxlen=25):\n",
    "    namelist = [name2vectorTest(name) for name in names]\n",
    "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
    "\n",
    "def name2gender(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  if result:\n",
    "    return \"male\"\n",
    "  else:\n",
    "    return \"female\"\n",
    "  \n",
    "def isMale(name):\n",
    "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(name, name_found, Name2Key, Key2Name, num_keys): \n",
    "    \n",
    "    if name_found not in Name2Key:\n",
    "        #global num_keys\n",
    "        num_keys+=1\n",
    "        key = \"PER_\"+str(num_keys)\n",
    "        gender = name2gender(name_found)\n",
    "        alias = None\n",
    "        element = {\"name\": name, \"key\": key, \"gender\":gender, \"alias\":alias, \"is_alias\": False, \"alias_to\": None}\n",
    "        Name2Key[name_found] = element\n",
    "        Key2Name[key] = element\n",
    "    \n",
    "    if name not in Name2Key:\n",
    "        element_alias = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
    "        Name2Key[name] = element_alias\n",
    "        Name2Key[name_found][\"alias\"] = name\n",
    "        \n",
    "    return Name2Key[name_found][\"key\"], num_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Input Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '''Biden said he would beat the President \"like a drum\" and that Trump \"knows it\" because he has spent \"a lot of money to make sure I'm not\" the nominee.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Morshed Khan told newsmen that 'BNP is a massive party with huge popularity and public acceptance.'\"# This party is now running its operations over Skype. He (Tarique) is operating from London over Skype and that too with only selected leaders. It has turned into the ‘Bangladesh Nationalist Skype Party’. This is painful. I believe the next generation must assume leadership within the party — that would be my recommendation.”\"77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Mr Masum Hasan is not a doctor. Masum is an engineer.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS-NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ' '.join(s.split())\n",
    "doc = nlp(s)\n",
    "tokenized_text = ' '.join([token.text for token in doc])\n",
    "oracle = []\n",
    "coref2name = {}\n",
    "\n",
    "# POS TAG\n",
    "sent = Sentence(tokenized_text)\n",
    "tagger_ner.predict(sent)\n",
    "tagger_pos.predict(sent)\n",
    "tagged_list = sent.to_tagged_string().split()\n",
    "tokens_pos = []\n",
    "pos = []\n",
    "count = 0\n",
    "for i in range(0,len(tagged_list),2):\n",
    "  tokens_pos.append(tagged_list[i])\n",
    "  count = count+1\n",
    "  pos.append(tagged_list[i+1])\n",
    "\n",
    "  if tagged_list[i].lower() in male_pronouns+female_pronouns:\n",
    "      oracle.append(2)\n",
    "  elif tagged_list[i+1] in ['<B-PER/NNP>', '<I-PER/NNP>', '<E-PER/NNP>', '<S-PER/NNP>']:\n",
    "      oracle.append(4)\n",
    "  else:\n",
    "      oracle.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr \t <NNP> \t 1\n",
      "Masum \t <B-PER/NNP> \t 5\n",
      "Hasan \t <E-PER/NNP> \t 5\n",
      "is \t <VBZ> \t 0\n",
      "not \t <RB> \t 0\n",
      "a \t <DT> \t 0\n",
      "doctor \t <NN> \t 0\n",
      ". \t <.> \t 0\n",
      "Masum \t <S-PER/NNP> \t 5\n",
      "is \t <VBZ> \t 0\n",
      "an \t <DT> \t 0\n",
      "engineer \t <NN> \t 0\n",
      ". \t <.> \t 0\n"
     ]
    }
   ],
   "source": [
    "for x,y,z in zip(tokens_pos, pos, oracle):\n",
    "    print(x, \"\\t\", y, \"\\t\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coreference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr Masum Hasan is not a doctor. Masum is an engineer."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Mr Masum Hasan: [Mr Masum Hasan, Masum]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Masum"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[8]._.in_coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COREFERENCE RESOLUTION \n",
    "coref_stack = []\n",
    "name_stack = []\n",
    "for i in range(len(doc)):\n",
    "  token = doc[i]\n",
    "  if token._.in_coref:\n",
    "      coref_stack.append(tokens_pos[i])\n",
    "      if oracle[i] == 4:\n",
    "          name_stack.append(tokens_pos[i])\n",
    "      oracle[i] += 1\n",
    "  else:\n",
    "      if len(name_stack) > 0:\n",
    "          name = ' '.join(name_stack)\n",
    "          coref = ' '.join(coref_stack)\n",
    "          #name2coref[name] = coref\n",
    "          coref2name[coref] = name\n",
    "          name_stack.clear()\n",
    "      coref_stack.clear()\n",
    "\n",
    "# IF THE SENTENCE DOES NOT END WITH A PERIOD OR SPECIAL CHARACTER\n",
    "if len(name_stack) > 0:\n",
    "  name = ' '.join(name_stack)\n",
    "  name2coref[name] = ' '.join(coref_stack)\n",
    "  name_stack.clear()\n",
    "coref_stack.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumption: The sentence will end with period or any other special token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "2 5\n",
      "Mr Masum Hasan is not a doctor . Masum is an engineer . {'PER_1': {'name': 'Masum Hasan', 'key': 'PER_1', 'gender': 'male', 'alias': 'Masum', 'is_alias': False, 'alias_to': None}} <|hons|> Mr/Ms PER_1 is not a doctor . <|alias|> PER_1 is an engineer .\n"
     ]
    }
   ],
   "source": [
    "Name2Key = {}\n",
    "Key2Name = {}\n",
    "encrypted = []\n",
    "num_keys = 0\n",
    "i = 0\n",
    "while i<len(tokens_pos): \n",
    "  #print(\"Oracle \", i, tokens_pos[i])\n",
    "  if oracle[i] == 2:\n",
    "      pronoun = tokens_pos[i].lower()\n",
    "      if pos[i] == '<PRP$>':\n",
    "          pronoun+=\"$\"\n",
    "      encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "  elif oracle[i] == 3:\n",
    "      coref = doc[i]._.coref_clusters[0][0].text\n",
    "      pronoun = tokens_pos[i].lower()\n",
    "      if pos[i] == '<PRP$>':\n",
    "          pronoun+=\"$\"\n",
    "      if coref in coref2name:\n",
    "        name_found = coref2name[coref]\n",
    "        key = Name2Key[name_found][\"key\"]\n",
    "        encrypted.append(\"<|coref|>\")\n",
    "        encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "        encrypted.append(key)\n",
    "      else:\n",
    "        encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
    "\n",
    "  elif oracle[i] in [4,5]:\n",
    "      if i > 0 and tokens_pos[i-1] in gender_honorific_dict:\n",
    "        hons = encrypted.pop()\n",
    "        encrypted.append(\"<|hons|>\")\n",
    "        encrypted.append(gender_honorific_dict[hons][\"merged\"])\n",
    "      if pos[i] == '<S-PER/NNP>':\n",
    "          name = tokens_pos[i]\n",
    "      elif pos[i] == '<B-PER/NNP>':\n",
    "          name = \"\"\n",
    "          while True:\n",
    "              #print(i, oracle[i])\n",
    "              name += tokens_pos[i]\n",
    "              if pos[i] == '<E-PER/NNP>':\n",
    "                  break\n",
    "              name += \" \"\n",
    "              i+=1\n",
    "\n",
    "      if oracle[i] == 4:\n",
    "          key, num_keys = store(name, name, Name2Key, Key2Name, num_keys)\n",
    "          encrypted.append(key)\n",
    "      else:\n",
    "          coref = doc[i]._.coref_clusters[0][0].text\n",
    "          name_found = coref2name[coref]\n",
    "          if name != name_found:\n",
    "              encrypted.append(\"<|alias|>\")\n",
    "            \n",
    "          key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
    "          encrypted.append(key)\n",
    "  else:\n",
    "    encrypted.append(tokens_pos[i])\n",
    "  i+=1\n",
    "\n",
    "encrypted_text = ' '.join(encrypted)\n",
    "\n",
    "print(tokenized_text, Key2Name, encrypted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PER_1',\n",
       " 'told',\n",
       " 'newsmen',\n",
       " 'that',\n",
       " \"'\",\n",
       " 'BNP',\n",
       " 'is',\n",
       " 'a',\n",
       " 'massive',\n",
       " 'party',\n",
       " 'with',\n",
       " 'huge',\n",
       " 'popularity',\n",
       " 'and',\n",
       " 'public',\n",
       " 'acceptance',\n",
       " '.',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Masum Hasan': {'name': 'Masum Hasan',\n",
       "  'key': 'PER_1',\n",
       "  'gender': 'Male',\n",
       "  'alias': 'Masum',\n",
       "  'is_alias': False,\n",
       "  'alias_to': None},\n",
       " 'Masum': {'name': 'Masum', 'is_alias': True, 'alias_to': 'Masum Hasan'}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name2Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PER_1': {'name': 'Masum Hasan',\n",
       "  'key': 'PER_1',\n",
       "  'gender': 'Male',\n",
       "  'alias': 'Masum',\n",
       "  'is_alias': False,\n",
       "  'alias_to': None}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Key2Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Masum Hasan', 'gender': 'male', 'alias': 'Masum'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'name': 'Masum Hasan', 'gender': 'male', 'alias': 'Masum'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
