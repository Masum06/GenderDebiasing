{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Gender Encrypter Decrypter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masum06/GenderDebiasing/blob/development/Gender_Encrypter_Decrypter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g17bTEJ7VCJ5",
        "colab_type": "text"
      },
      "source": [
        "# Gender Encryption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFctT8bvVCJ9",
        "colab_type": "text"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSlIksK3-BSm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a637b53d-ee37-4ca6-8d43-64f5b77d08c5"
      },
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.9'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F74akq3VCJ-",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/zalandoresearch/flair\n",
        "\n",
        "https://github.com/huggingface/neuralcoref"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvn8rO3mVCKA",
        "colab_type": "code",
        "outputId": "201e58e4-725a-435a-8c99-5ef3a3006b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install flair==0.4.2\n",
        "#!pip uninstall spacy\n",
        "#!pip install -U spacy==2.1.0\n",
        "##!python -m spacy download en # SMALL VERSION OF SPACY, FAST DOWNLOAD\n",
        "##!python -m spacy download en_core_web_md # MEDIUM VERSION OF SPACY\n",
        "!python -m spacy download en_core_web_lg # LARGE VERSION OF SPACY, SLOW DOWNLOAD\n",
        "!pip install neuralcoref --no-binary neuralcoref"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair==0.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 10.1MB/s \n",
            "\u001b[?25hCollecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (4.28.1)\n",
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 48.2MB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/88/0e/9d5a1a8cd7130c49334cce7b8167ceda63d6a329c8ea65b626116bc9e9e6/Deprecated-1.2.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.8.5)\n",
            "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.4)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.3.0+cu100)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.24.3)\n",
            "Collecting pytorch-pretrained-bert>=0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.1.1)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.0)\n",
            "Collecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.1.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.0)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.2) (1.11.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (19.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (41.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (7.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->flair==0.4.2) (1.17.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.10.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.3.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.8.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (3.9.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair==0.4.2) (0.21.3)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.7 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.13.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.9.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (2019.9.11)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (2.49.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.2) (4.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair==0.4.2) (0.14.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.15.2)\n",
            "Building wheels for collected packages: mpld3, sqlitedict, segtok\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=fa3d0b2ee053a69f591c6c085a65c38ea0bc802c5fae4a456d97a93dba59d311\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=84f5322466ef66863eba6de99b41527810b49fb79108ef998537cc0386d58cb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=0f17632a935deeefc90dd3eeeff0682e43d74d65d97fea6af5b0b9df3a1ac042\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "Successfully built mpld3 sqlitedict segtok\n",
            "Installing collected packages: mpld3, regex, deprecated, sqlitedict, pytorch-pretrained-bert, sentencepiece, bpemb, segtok, flair\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.6 flair-0.4.2 mpld3-0.3 pytorch-pretrained-bert-0.6.2 regex-2019.11.1 segtok-1.5.7 sentencepiece-0.1.83 sqlitedict-1.6.0\n",
            "Collecting en_core_web_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
            "\u001b[K     |████████████████████████████████| 826.9MB 1.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255076 sha256=c415c89471fa26c98fc5ef5f46aaebde6b783d640ce70ff2c136c20f0d5fb077\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hwo36rl0/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "Collecting neuralcoref\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/40/8db3db763077fe80b71859f57731261aeb03cc624635f97a3bcfe55ab37b/neuralcoref-4.0.tar.gz (368kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.17.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.10.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.21.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.1.9)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.7 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (1.13.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.9.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.3.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->neuralcoref) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->neuralcoref) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy>=2.1.0->neuralcoref) (4.28.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.7->boto3->neuralcoref) (1.12.0)\n",
            "Skipping wheel build for neuralcoref, due to binaries being disabled for it.\n",
            "Installing collected packages: neuralcoref\n",
            "    Running setup.py install for neuralcoref ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed neuralcoref-4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qlzZsMXVCKH",
        "colab_type": "text"
      },
      "source": [
        "### Creating Language Resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h4nHNwnVCKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "male_pronouns   = [\"he\",  \"him\", \"his$\", \"his\", \"himself\"]\n",
        "female_pronouns = [\"she\", \"her\", \"her$\", \"hers\", \"herself\"]\n",
        "neutral_pronouns= [\"zie\", \"zim\", \"zir\", \"zis\", \"zieself\"]\n",
        "merged_pronouns = [\"he/she\", \"him/her\", \"his/her\", \"his/hers\", \"himself/herself\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sim_9aXgVCKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gender_pronouns_dict = {}\n",
        "gender_honorific_dict = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC4J8YREVCKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for (g1,g2,g3,g4) in zip(male_pronouns, female_pronouns, neutral_pronouns, merged_pronouns):\n",
        "    element = {\"male\": g1.replace(\"$\",\"\"), \"female\":g2.replace(\"$\",\"\"), \"neutral\":g3, \"merged\":g4}\n",
        "    gender_pronouns_dict[g1] = gender_pronouns_dict[g2] = gender_pronouns_dict[g3] = gender_pronouns_dict[g4] =element"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmE6CL7PVCKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "male_hons   =  [\"Mr.\", \"Mr\", \"Md.\", \"Md\", \"Sir\", \"Lord\", \"Mister\"]\n",
        "female_hons =  [\"Ms.\", \"Ms\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Miss\"]\n",
        "neutral_hons = [\"Mx.\", \"Mx\", \"Mx.\", \"Mx\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]\n",
        "married_hons = [\"Mrs.\", \"Mrs\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Mis'ess\"]\n",
        "merged_hons =  [\"Mr./Ms.\", \"Mr/Ms\", \"Md./Mst.\", \"Md/Mst\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbb4Jf6mVCKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for (h1,h2,h3,h4,h5) in zip(male_hons, female_hons, neutral_hons, married_hons, merged_hons):\n",
        "    element = {\"male\": h1, \"female\":h2, \"neutral\":h3, \"married_fem\":h4, \"merged\":h5}\n",
        "    gender_honorific_dict[h1] = gender_honorific_dict[h2] = gender_honorific_dict[h3] = \\\n",
        "    gender_honorific_dict[h4] = gender_honorific_dict[h5] = element"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzgZxsSUVCKq",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yTkWcUAYH7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZN82xZJgVCKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from segtok.segmenter import split_single"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoC0zGDKggFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import flair\n",
        "assert flair.__version__=='0.4.2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKRKCr8uVCKv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "32c6b80b-6ee3-4ecc-ef19-4e514dbcbd0b"
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be8BR8KQVCKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4fd8730e-1513-4472-f7e3-2de7b87b3af9"
      },
      "source": [
        "import spacy\n",
        "import neuralcoref"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: spacy.tokens.span.Span size changed, may indicate binary incompatibility. Expected 72 from C header, got 80 from PyObject\n",
            "  return f(*args, **kwds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZuAm9_9VCK5",
        "colab_type": "text"
      },
      "source": [
        "### Loading Essentials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI8M4VyXVDV6",
        "colab_type": "code",
        "outputId": "7055c7c2-3ab2-4ce4-b23a-1e2a3808db54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone --single-branch --branch development https://github.com/Masum06/GenderDebiasing.git resources"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'resources' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjlMu-sNVCK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "char2idx = 'resources/char2idx.json'\n",
        "idx2char = 'resources/idx2char.json'\n",
        "with open(char2idx, 'r') as fp:\n",
        "    char2idx = json.load(fp)\n",
        "    \n",
        "with open(idx2char, 'r') as fp:\n",
        "    idx2char = json.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "h0BOOa4fVCK-",
        "colab_type": "code",
        "outputId": "f912b456-00fa-49e2-8264-39558915bcbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "model_name = 'resources/char_rnn_hsc_model_0.h5'\n",
        "model = load_model(model_name)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-11-07 22:58:47,642 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "2019-11-07 22:58:47,648 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "2019-11-07 22:58:47,668 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "2019-11-07 22:58:47,761 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "2019-11-07 22:58:47,772 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2019-11-07 22:58:48,055 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "2019-11-07 22:58:48,060 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-11-07 22:58:48,062 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-11-07 22:58:48,071 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "2019-11-07 22:58:48,073 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "2019-11-07 22:58:48,100 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "2019-11-07 22:58:48,150 From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "2019-11-07 22:58:48,160 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "2019-11-07 22:58:48,166 From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2019-11-07 22:58:49,172 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "2019-11-07 22:58:49,277 From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggCw99GvVCLC",
        "colab_type": "code",
        "outputId": "4d6ae43e-d3d1-4700-c6ea-6b4bc6666c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#nlp = spacy.load('en_core_web_lg') # en_core_web_sm #en_core_web_md\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()\n",
        "neuralcoref.add_to_pipe(nlp)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7f7532d36f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "eP7eFWBaVCLH",
        "colab_type": "code",
        "outputId": "032777c6-c994-48d4-d7bd-f07586d78ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "tagger_ner = SequenceTagger.load('ner')\n",
        "tagger_pos = SequenceTagger.load('pos')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-11-07 22:59:00,804 loading file /root/.flair/models/en-ner-conll03-v0.4.pt\n",
            "2019-11-07 22:59:02,682 loading file /root/.flair/models/en-pos-ontonotes-v0.2.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyHJZ4t-VCLL",
        "colab_type": "text"
      },
      "source": [
        "### Necessary Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2FRQ-qzEzDF",
        "colab_type": "text"
      },
      "source": [
        "Name2Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UExr_6fiVCLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "# Converts a name into vector\n",
        "def name2vectorTest(name):\n",
        "    name = name.lower()\n",
        "    new_name = \"\"\n",
        "    for char in name:\n",
        "      if char in char2idx:\n",
        "        new_name += char\n",
        "    chars = list(new_name)\n",
        "    vector = [ char2idx[c] for c in chars ]\n",
        "    return np.array(vector)\n",
        "\n",
        "# Converts names to fixed size tensor\n",
        "def names2tensorTest(names, maxlen=25):\n",
        "    namelist = [name2vectorTest(name) for name in names]\n",
        "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
        "\n",
        "def name2gender(name):\n",
        "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
        "  if result:\n",
        "    return \"male\"\n",
        "  else:\n",
        "    return \"female\"\n",
        "  \n",
        "def isMale(name):\n",
        "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXxZYr_mflVz",
        "colab_type": "text"
      },
      "source": [
        "Storing Names in Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJzj_UF_VCMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def store(name, name_found, Name2Key, Key2Name, num_keys):\n",
        "    if name_found in Name2Key:\n",
        "        if name not in Name2Key:\n",
        "            element = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
        "    else:\n",
        "        #global num_keys\n",
        "        num_keys+=1\n",
        "        key = \"PER_\"+str(num_keys)\n",
        "        gender = name2gender(name)\n",
        "        alias = None\n",
        "        \n",
        "        if name!=name_found:\n",
        "            element_alias = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
        "            Name2Key[name] = element_alias\n",
        "            alias = name\n",
        "        \n",
        "        element = {\"name\": name, \"key\": key, \"gender\":gender, \"alias\":alias, \"is_alias\": False, \"alias_to\": None}\n",
        "        Name2Key[name_found] = element\n",
        "        Key2Name[key] = element\n",
        "        \n",
        "    return Name2Key[name_found][\"key\"], num_keys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQLK_E67-gUu",
        "colab_type": "text"
      },
      "source": [
        "# Debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAlr_fntYwBI",
        "colab_type": "text"
      },
      "source": [
        "### Input sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFcpuVA1VCLV",
        "colab_type": "code",
        "outputId": "d7f47bdc-ba46-4e1b-e2de-621d4ac8c118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "s = \"Two days before Buet student Abrar was tortured to death, some of his suspects held two meetings at their dorm canteen and guest room and decided to beat him up and evict him if his involvement with Shibir was found.\"\n",
        "#s = ' '.join(s.split())\n",
        "s"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Two days before Buet student Abrar was tortured to death, some of his suspects held two meetings at their dorm canteen and guest room and decided to beat him up and evict him if his involvement with Shibir was found.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOgb6AAJVCLh",
        "colab_type": "text"
      },
      "source": [
        "### POS-NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zZQ6b6BgVCL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5tEfpXqVCLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oracle = []\n",
        "coref2name = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5V722k7VCLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent = Sentence(' '.join([token.text for token in doc])) #s, use_tokenizer=True\n",
        "tagger_ner.predict(sent)\n",
        "tagger_pos.predict(sent)\n",
        "tagged_list = sent.to_tagged_string().split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3L0saglcF1C",
        "colab_type": "code",
        "outputId": "6f6fd6be-8d5c-4d71-8acb-4029aeea486b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(sent))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKbHAUD9VCLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_pos = []\n",
        "pos = []\n",
        "count = 0\n",
        "for i in range(0,len(tagged_list),2):\n",
        "    tokens_pos.append(tagged_list[i])\n",
        "    count = count+1\n",
        "    pos.append(tagged_list[i+1])\n",
        "    \n",
        "    if tagged_list[i].lower() in male_pronouns+female_pronouns:\n",
        "        oracle.append(2)\n",
        "    elif tagged_list[i+1] in ['<B-PER/NNP>', '<I-PER/NNP>', '<E-PER/NNP>', '<S-PER/NNP>']:\n",
        "        oracle.append(4)\n",
        "    else:\n",
        "        oracle.append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EaJyI1uVCL6",
        "colab_type": "text"
      },
      "source": [
        "### Coreference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Q566Q8VCL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(doc)==len(tokens_pos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUxAkrpV40pM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb63f7d1-9d49-449a-cbf7-cc443530d92c"
      },
      "source": [
        "doc[1]._.coref_clusters"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8YLTxmN4Je5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41ceb337-0c48-4541-80cc-1c06d01c5245"
      },
      "source": [
        "doc._.coref_clusters[0].mentions[-1]._.coref_cluster.main"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mrs. Katy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws7iXE05VCMS",
        "colab_type": "text"
      },
      "source": [
        "**Assumption: The sentence will end with period or any other special token**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEeCq_kJVCMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coref_stack = []\n",
        "name_stack = []\n",
        "for i in range(len(doc)):\n",
        "    token = doc[i]\n",
        "    if token._.in_coref:\n",
        "        coref_stack.append(tokens_pos[i])\n",
        "        if oracle[i] == 4:\n",
        "            name_stack.append(tokens_pos[i])\n",
        "        oracle[i] += 1\n",
        "    else:\n",
        "        if len(name_stack) > 0:\n",
        "            name = ' '.join(name_stack)\n",
        "            coref = ' '.join(coref_stack)\n",
        "            #name2coref[name] = coref\n",
        "            coref2name[coref] = name\n",
        "            name_stack.clear()\n",
        "        coref_stack.clear()\n",
        "\n",
        "# IF THE SENTENCE DOES NOT END WITH A PERIOD OR SPECIAL CHARACTER\n",
        "if len(name_stack) > 0:\n",
        "    name = ' '.join(name_stack)\n",
        "    name2coref[name] = ' '.join(coref_stack)\n",
        "    name_stack.clear()\n",
        "coref_stack.clear()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nlwgTlAzVCMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Name2Key = {}\n",
        "Key2Name = {}\n",
        "encrypted = []\n",
        "num_keys = 0\n",
        "\n",
        "i = 0\n",
        "while i<len(tokens_pos): \n",
        "    #print(\"Oracle \", i, tokens_pos[i])\n",
        "    if oracle[i] == 0:\n",
        "        encrypted.append(tokens_pos[i])\n",
        "    elif oracle[i+1] in [4,5]:\n",
        "        if tokens_pos[i] in gender_honorific_dict:\n",
        "            encrypted.append(\"<|hons|>\")\n",
        "            encrypted.append(gender_honorific_dict[tokens_pos[i]][\"merged\"])\n",
        "        else:\n",
        "            encrypted.append(tokens_pos[i])\n",
        "    elif oracle[i] == 2:\n",
        "        pronoun = tokens_pos[i].lower()\n",
        "        if pos[i] == '<PRP$>':\n",
        "            pronoun+=\"$\"\n",
        "        encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "    elif oracle[i] == 3:\n",
        "        coref = doc[i]._.coref_clusters[0][0].text\n",
        "        pronoun = tokens_pos[i].lower()\n",
        "        if pos[i] == '<PRP$>':\n",
        "            pronoun+=\"$\"\n",
        "        if coref in coref2name:\n",
        "          name_found = coref2name[coref]\n",
        "          key = Name2Key[name_found][\"key\"]\n",
        "          encrypted.append(\"<|coref|>\")\n",
        "          encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "          encrypted.append(key)\n",
        "        else:\n",
        "          encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "      \n",
        "    elif oracle[i] in [4,5]:\n",
        "        if pos[i] == '<S-PER/NNP>':\n",
        "            name = tokens_pos[i]\n",
        "        elif pos[i] == '<B-PER/NNP>':\n",
        "            name = \"\"\n",
        "            while True:\n",
        "                print(i, oracle[i])\n",
        "                name += tokens_pos[i]\n",
        "                if pos[i] == '<E-PER/NNP>':\n",
        "                    break\n",
        "                name += \" \"\n",
        "                i+=1\n",
        "        \n",
        "        if oracle[i] == 4:\n",
        "            key, num_keys = store(name, name, Name2Key, Key2Name, num_keys)\n",
        "            encrypted.append(key)\n",
        "        else:\n",
        "            coref = doc[i]._.coref_clusters[0][0].text\n",
        "            name_found = coref2name[coref]\n",
        "            if name == name_found:\n",
        "                key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                encrypted.append(key)\n",
        "            else:\n",
        "                key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                encrypted.append(\"<|alias|>\")\n",
        "                encrypted.append(key)\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6b37HLfmWn8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "5bb27d21-b3c4-4775-b768-eadc466a1a42"
      },
      "source": [
        "for x,y in zip(tokens_pos, oracle):\n",
        "  print(x,y)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mr. 0\n",
            "Masum 4\n",
            "is 0\n",
            "not 0\n",
            "a 0\n",
            "doctor 0\n",
            ". 0\n",
            "Mrs. 1\n",
            "Katy 5\n",
            "is 0\n",
            "also 0\n",
            "not 0\n",
            "an 1\n",
            "engineer 1\n",
            ". 0\n",
            "He 3\n",
            "can 0\n",
            "fly 0\n",
            ", 0\n",
            "but 0\n",
            "she 3\n",
            "can 0\n",
            "not 0\n",
            "swim 0\n",
            ". 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ8UEas4i-Jr",
        "colab_type": "code",
        "outputId": "e667c8c7-ac66-4c02-928b-2394b1b9f417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc._.coref_clusters"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Mrs. Katy: [Mrs. Katy, she], an engineer: [an engineer, He]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BeEX2B0RVCMj",
        "colab_type": "code",
        "outputId": "a73a0c7a-c79a-4c2b-bc3d-5ad73723c90d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "coref2name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Two days before Buet student Abrar was tortured to death': 'Abrar'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXZZGIFfeU5y",
        "colab_type": "code",
        "outputId": "354672ba-fa6d-4513-cc60-2298d04a5e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "s"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Two days before Buet student Abrar was tortured to death, some of the suspects held two meetings at their dorm canteen and guest room and decided to beat him up and evict him if his involvement with Shibir was found.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoAJvmGAkOD7",
        "colab_type": "code",
        "outputId": "d5ee1c7d-89c7-415b-a713-94593f96c11b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "encrypted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Two',\n",
              " 'days',\n",
              " 'before',\n",
              " 'Buet',\n",
              " 'student',\n",
              " 'PER_1',\n",
              " 'was',\n",
              " 'tortured',\n",
              " 'to',\n",
              " 'death',\n",
              " ',',\n",
              " 'some',\n",
              " 'of',\n",
              " '<|coref|>',\n",
              " 'his/her',\n",
              " 'PER_1',\n",
              " 'suspects',\n",
              " 'held',\n",
              " 'two',\n",
              " 'meetings',\n",
              " 'at',\n",
              " 'their',\n",
              " 'dorm',\n",
              " 'canteen',\n",
              " 'and',\n",
              " 'guest',\n",
              " 'room',\n",
              " 'and',\n",
              " 'decided',\n",
              " 'to',\n",
              " 'beat',\n",
              " '<|coref|>',\n",
              " 'him/her',\n",
              " 'PER_1',\n",
              " 'up',\n",
              " 'and',\n",
              " 'evict',\n",
              " '<|coref|>',\n",
              " 'him/her',\n",
              " 'PER_1',\n",
              " 'if',\n",
              " '<|coref|>',\n",
              " 'his/her',\n",
              " 'PER_1',\n",
              " 'involvement',\n",
              " 'with',\n",
              " 'PER_2',\n",
              " 'was',\n",
              " 'found',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGHFnC6MVCMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Name2Key"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_8_80yWVCMq",
        "colab_type": "code",
        "outputId": "49193835-2075-4024-80fd-ff64f5c78817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "Key2Name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'PER_1': {'name': 'Abrar',\n",
              "  'key': 'PER_1',\n",
              "  'gender': 'Male',\n",
              "  'alias': None,\n",
              "  'is_alias': False,\n",
              "  'alias_to': None},\n",
              " 'PER_2': {'name': 'Shibir',\n",
              "  'key': 'PER_2',\n",
              "  'gender': 'Male',\n",
              "  'alias': None,\n",
              "  'is_alias': False,\n",
              "  'alias_to': None}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBUjsc8IqfAf",
        "colab_type": "code",
        "outputId": "cdca02d7-45ba-4ff6-eb99-53e59710eb21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "encrypted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Two',\n",
              " 'days',\n",
              " 'before',\n",
              " 'Buet',\n",
              " 'student',\n",
              " 'PER_1',\n",
              " 'was',\n",
              " 'tortured',\n",
              " 'to',\n",
              " 'death',\n",
              " ',',\n",
              " 'some',\n",
              " 'of',\n",
              " '<|coref|>',\n",
              " 'his/her',\n",
              " 'PER_1',\n",
              " 'suspects',\n",
              " 'held',\n",
              " 'two',\n",
              " 'meetings',\n",
              " 'at',\n",
              " 'their',\n",
              " 'dorm',\n",
              " 'canteen',\n",
              " 'and',\n",
              " 'guest',\n",
              " 'room',\n",
              " 'and',\n",
              " 'decided',\n",
              " 'to',\n",
              " 'beat',\n",
              " '<|coref|>',\n",
              " 'him/her',\n",
              " 'PER_1',\n",
              " 'up',\n",
              " 'and',\n",
              " 'evict',\n",
              " '<|coref|>',\n",
              " 'him/her',\n",
              " 'PER_1',\n",
              " 'if',\n",
              " '<|coref|>',\n",
              " 'his/her',\n",
              " 'PER_1',\n",
              " 'involvement',\n",
              " 'with',\n",
              " 'PER_2',\n",
              " 'was',\n",
              " 'found',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSYCQfJcOTLU",
        "colab_type": "text"
      },
      "source": [
        "# Unit Gender Encryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJLCTIOQOYav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gender_encrypt(s):\n",
        "  s = ' '.join(s.split())\n",
        "  doc = nlp(s)\n",
        "  tokenized_text = ' '.join([token.text for token in doc])\n",
        "  oracle = []\n",
        "  coref2name = {}\n",
        "\n",
        "  # POS TAG\n",
        "  sent = Sentence(tokenized_text)\n",
        "  tagger_ner.predict(sent)\n",
        "  tagger_pos.predict(sent)\n",
        "  tagged_list = sent.to_tagged_string().split()\n",
        "  tokens_pos = []\n",
        "  pos = []\n",
        "  count = 0\n",
        "  for i in range(0,len(tagged_list),2):\n",
        "      tokens_pos.append(tagged_list[i])\n",
        "      count = count+1\n",
        "      pos.append(tagged_list[i+1])\n",
        "      \n",
        "      if tagged_list[i].lower() in male_pronouns+female_pronouns:\n",
        "          oracle.append(2)\n",
        "      elif tagged_list[i+1] in ['<B-PER/NNP>', '<I-PER/NNP>', '<E-PER/NNP>', '<S-PER/NNP>']:\n",
        "          oracle.append(4)\n",
        "      else:\n",
        "          oracle.append(0)\n",
        "\n",
        "  # COREFERENCE RESOLUTION \n",
        "  if len(doc)!=len(tokens_pos):\n",
        "    tokens_doc = [token.text for token in doc]\n",
        "    print(\"doc:\", tokens_doc)\n",
        "    print(\"pos:\", tokens_pos)\n",
        "    return None, None\n",
        "  \n",
        "  coref_stack = []\n",
        "  name_stack = []\n",
        "  for i in range(len(doc)):\n",
        "      token = doc[i]\n",
        "      if token._.in_coref:\n",
        "          coref_stack.append(tokens_pos[i])\n",
        "          if oracle[i] == 4:\n",
        "              name_stack.append(tokens_pos[i])\n",
        "          oracle[i] += 1\n",
        "      else:\n",
        "          if len(name_stack) > 0:\n",
        "              name = ' '.join(name_stack)\n",
        "              coref = ' '.join(coref_stack)\n",
        "              #name2coref[name] = coref\n",
        "              coref2name[coref] = name\n",
        "              name_stack.clear()\n",
        "          coref_stack.clear()\n",
        "\n",
        "  # IF THE SENTENCE DOES NOT END WITH A PERIOD OR SPECIAL CHARACTER\n",
        "  if len(name_stack) > 0:\n",
        "      name = ' '.join(name_stack)\n",
        "      name2coref[name] = ' '.join(coref_stack)\n",
        "      name_stack.clear()\n",
        "  coref_stack.clear()\n",
        "\n",
        "  Name2Key = {}\n",
        "  Key2Name = {}\n",
        "  encrypted = []\n",
        "  num_keys = 0\n",
        "  i = 0\n",
        "  while i<len(tokens_pos): \n",
        "      #print(\"Oracle \", i, tokens_pos[i])\n",
        "      if oracle[i] == 2:\n",
        "          pronoun = tokens_pos[i].lower()\n",
        "          if pos[i] == '<PRP$>':\n",
        "              pronoun+=\"$\"\n",
        "          encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "      elif oracle[i] == 3:\n",
        "          coref = doc[i]._.coref_clusters[0][0].text\n",
        "          pronoun = tokens_pos[i].lower()\n",
        "          if pos[i] == '<PRP$>':\n",
        "              pronoun+=\"$\"\n",
        "          if coref in coref2name:\n",
        "            name_found = coref2name[coref]\n",
        "            key = Name2Key[name_found][\"key\"]\n",
        "            encrypted.append(\"<|coref|>\")\n",
        "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "            encrypted.append(key)\n",
        "          else:\n",
        "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "          \n",
        "      elif oracle[i] in [4,5]:\n",
        "          if i > 0 and tokens_pos[i-1] in gender_honorific_dict:\n",
        "            hons = encrypted.pop()\n",
        "            encrypted.append(\"<|hons|>\")\n",
        "            encrypted.append(gender_honorific_dict[hons][\"merged\"])\n",
        "          if pos[i] == '<S-PER/NNP>':\n",
        "              name = tokens_pos[i]\n",
        "          elif pos[i] == '<B-PER/NNP>':\n",
        "              name = \"\"\n",
        "              while True:\n",
        "                  print(i, oracle[i])\n",
        "                  name += tokens_pos[i]\n",
        "                  if pos[i] == '<E-PER/NNP>':\n",
        "                      break\n",
        "                  name += \" \"\n",
        "                  i+=1\n",
        "          \n",
        "          if oracle[i] == 4:\n",
        "              key, num_keys = store(name, name, Name2Key, Key2Name, num_keys)\n",
        "              encrypted.append(key)\n",
        "          else:\n",
        "              coref = doc[i]._.coref_clusters[0][0].text\n",
        "              name_found = coref2name[coref]\n",
        "              if name == name_found:\n",
        "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                  encrypted.append(key)\n",
        "              else:\n",
        "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                  encrypted.append(\"<|alias|>\")\n",
        "                  encrypted.append(key)\n",
        "      else:\n",
        "        encrypted.append(tokens_pos[i])\n",
        "      i+=1\n",
        "      \n",
        "  encrypted_text = ' '.join(encrypted)\n",
        "\n",
        "  return tokenized_text, Key2Name, encrypted_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMItOjUbUQNf",
        "colab_type": "text"
      },
      "source": [
        "# Gender Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quTM_EeiVCMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gender_decrypt(encrypted_text, Key2Name):\n",
        "  encrypted = encrypted_text.split()\n",
        "  decrypted = []\n",
        "  i = 0\n",
        "  while i != len(encrypted):\n",
        "    token = encrypted[i]\n",
        "    if token in Key2Name:\n",
        "      decrypted.append(Key2Name[token][\"name\"])\n",
        "    elif token == '<|alias|>':\n",
        "      i+=1\n",
        "      key = encrypted[i]\n",
        "      if Key2Name[key][\"alias\"]:\n",
        "        decrypted.append(Key2Name[key][\"alias\"])\n",
        "      else:\n",
        "        decrypted.append(Key2Name[key][\"name\"])\n",
        "    elif token == '<|coref|>':\n",
        "      pronoun =  encrypted[i+1]\n",
        "      key = encrypted[i+2]\n",
        "      gender = Key2Name[key][\"gender\"].lower()\n",
        "      decrypted.append(gender_pronouns_dict[pronoun][gender])\n",
        "      i+=2\n",
        "    elif token == \"<|hons|>\":\n",
        "      hons = encrypted[i+1]\n",
        "      key = encrypted[i+2] # NEED CHECK FOR HONS IN ALIAS\n",
        "      gender = Key2Name[key][\"gender\"].lower()\n",
        "      decrypted.append(gender_honorific_dict[hons][gender])\n",
        "      i+=1\n",
        "    else:\n",
        "      decrypted.append(token)\n",
        "    i+=1\n",
        "\n",
        "  decrypted_text = ' '.join(decrypted)\n",
        "  #decrypted_text = decrypted_text.replace(\" .\", \".\")\n",
        "  return decrypted_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv5Y4nngq9AJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "key2name_changed = {'PER_1': {'name': 'Abira',\n",
        "    'key': 'PER_1',\n",
        "    'gender': 'Female',\n",
        "    'alias': None,\n",
        "    'is_alias': False,\n",
        "    'alias_to': None},\n",
        "  'PER_2': {'name': 'Shibir',\n",
        "    'key': 'PER_2',\n",
        "    'gender': 'Male',\n",
        "    'alias': None,\n",
        "    'is_alias': False,\n",
        "    'alias_to': None}\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_Ad5ljDRvvB",
        "colab_type": "text"
      },
      "source": [
        "### Testing Encryption-Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDUandyxxJ8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = \"Mr. John is not a doctor. Ms. Katy is also not a nurse. He can fly, but she cannot swim.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJnQwJd5S_GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = \"Morshed Khan told newsmen that 'BNP is a massive party with huge popularity and public acceptance.'\"# This party is now running its operations over Skype. He (Tarique) is operating from London over Skype and that too with only selected leaders. It has turned into the ‘Bangladesh Nationalist Skype Party’. This is painful. I believe the next generation must assume leadership within the party — that would be my recommendation.”\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsmaikFZFHtl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d647507-2da3-47de-ca79-d97d8e59ab6b"
      },
      "source": [
        "len(s.split())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qLWPn4lR1Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "start = time.time()\n",
        "text, key2name, encrypted = gender_encrypt(s)\n",
        "end = time.time()\n",
        "\n",
        "print(encrypted)\n",
        "print(key2name)\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB-PJPr7lIuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "key2name = {'PER_1': {'name': 'Masum', 'key': 'PER_1', 'gender': 'female', 'alias': None, 'is_alias': False, 'alias_to': None}}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeSiLybyVCMx",
        "colab_type": "code",
        "outputId": "1ea4a950-3955-453a-9554-fa0b59daaaf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "decrypted = gender_decrypt(encrypted, key2name)\n",
        "decrypted"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Prime Minister Sheikh Hasina on Wednesday reiterated her government ’s stance on not setting up industries by destroying arable land . “ We have set up 100 economic zones so that the arable land is not destroyed . Those , who want to set up industries , will be given plots in the zones . It is because we have to save arable land , ” she said , adding that farmers are given the highest importance while undertaking any development programme .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2DGAAsDT6HN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "948fe8a6-356f-4deb-c72d-7758be9e6431"
      },
      "source": [
        "decrypted == text"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKBfFmbYvtad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "33c9a311-0b5e-49f9-86ee-212928bbeff8"
      },
      "source": [
        "en = gender_encrypt(\"Mr. Masum is not a doctor.\")\n",
        "en"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<|hons|> Mr./Ms. PER_1 is not a doctor .',\n",
              " {'PER_1': {'alias': None,\n",
              "   'alias_to': None,\n",
              "   'gender': 'male',\n",
              "   'is_alias': False,\n",
              "   'key': 'PER_1',\n",
              "   'name': 'Masum'}})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-uNtEcNaJQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}