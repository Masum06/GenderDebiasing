{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Gender_Encrypter_Decrypter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masum06/GenderDebiasing/blob/development2/Gender_Encrypter_Decrypter_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DLRLPZ9BDqgo"
      },
      "source": [
        "https://www.researchgate.net/publication/337918817_What_You_See_Is_What_You_Learn_Mitigating_Gender_Biases_from_Natural_Language_Processing_Context_through_Gender_Encrypted_Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g17bTEJ7VCJ5"
      },
      "source": [
        "# Gender Encryption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NELJ69fFphPZ",
        "colab_type": "text"
      },
      "source": [
        "## New Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrAIgpDSqgzA",
        "colab_type": "text"
      },
      "source": [
        "### Install Anaconda\n",
        "https://www.digitalocean.com/community/tutorials/how-to-install-anaconda-on-ubuntu-18-04-quickstart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkNTPfzppqYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir anaconda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O1qfB4HqIPE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6842c94f-60bd-43c1-db02-4ecb1cad2ad9"
      },
      "source": [
        "cd anaconda"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/anaconda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoQ2oc4XqJwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e3048d54-2e96-4a86-ddde-66ee2d63484d"
      },
      "source": [
        "!curl -O https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-x86_64.sh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  654M  100  654M    0     0  48.6M      0  0:00:13  0:00:13 --:--:-- 49.2M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqBplaDyqQXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21abee38-9c02-4689-8eea-cad757f070f3"
      },
      "source": [
        "!sha256sum Anaconda3-2019.03-Linux-x86_64.sh"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45c851b7497cc14d5ca060064394569f724b67d9b5f98a926ed49b834a6bb73a  Anaconda3-2019.03-Linux-x86_64.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCt8WlliqZcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b7edb70-d6f0-4b97-8309-bf63aeae4904"
      },
      "source": [
        "!bash Anaconda3-2019.03-Linux-x86_64.sh --yes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Welcome to Anaconda3 2019.03\n",
            "\n",
            "In order to continue the installation process, please review the license\n",
            "agreement.\n",
            "Please, press ENTER to continue\n",
            ">>> \n",
            "===================================\n",
            "Anaconda End User License Agreement\n",
            "===================================\n",
            "\n",
            "Copyright 2015, Anaconda, Inc.\n",
            "\n",
            "All rights reserved under the 3-clause BSD License:\n",
            "\n",
            "Redistribution and use in source and binary forms, with or without modification,\n",
            " are permitted provided that the following conditions are met:\n",
            "\n",
            "  * Redistributions of source code must retain the above copyright notice, this \n",
            "list of conditions and the following disclaimer.\n",
            "  * Redistributions in binary form must reproduce the above copyright notice, th\n",
            "is list of conditions and the following disclaimer in the documentation and/or o\n",
            "ther materials provided with the distribution.\n",
            "  * Neither the name of Anaconda, Inc. (\"Anaconda, Inc.\") nor the names of its c\n",
            "ontributors may be used to endorse or promote products derived from this softwar\n",
            "e without specific prior written permission.\n",
            "\n",
            "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND \n",
            "ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WA\n",
            "RRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n",
            " IN NO EVENT SHALL ANACONDA, INC. BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL\n",
            ", SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, P\n",
            "ROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BU\n",
            "SINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN C\n",
            "ONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING I\n",
            "N ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n",
            " SUCH DAMAGE.\n",
            "\u001b[K\n",
            "Notice of Third Party Software Licenses\n",
            "=======================================\n",
            "\u001b[K\n",
            "Anaconda Distribution contains open source software packages from third parties.\n",
            " These are available on an \"as is\" basis and subject to their individual license\n",
            " agreements. These licenses are available in Anaconda Distribution or at http://\n",
            "docs.anaconda.com/anaconda/pkg-docs. Any binary packages of these third party to\n",
            "ols you obtain via Anaconda Distribution are subject to their individual license\n",
            "s as well as the Anaconda license. Anaconda, Inc. reserves the right to change w\n",
            "hich third party tools are provided in Anaconda Distribution.\n",
            "\u001b[K\n",
            "In particular, Anaconda Distribution contains re-distributable, run-time, shared\n",
            "-library files from the Intel(TM) Math Kernel Library (\"MKL binaries\"). You are \n",
            "specifically authorized to use the MKL binaries with your installation of Anacon\n",
            "da Distribution. You are also authorized to redistribute the MKL binaries with A\n",
            "naconda Distribution or in the conda package that contains them. Use and redistr\n",
            "ibution of the MKL binaries are subject to the licensing terms located at https:\n",
            "//software.intel.com/en-us/license/intel-simplified-software-license. If needed,\n",
            " instructions for removing the MKL binaries after installation of Anaconda Distr\n",
            "ibution are available at http://www.anaconda.com.\n",
            "\u001b[K\n",
            "Anaconda Distribution also contains cuDNN software binaries from NVIDIA Corporat\n",
            "ion (\"cuDNN binaries\"). You are specifically authorized to use the cuDNN binarie\n",
            "s with your installation of Anaconda Distribution. You are also authorized to re\n",
            "distribute the cuDNN binaries with an Anaconda Distribution package that contain\n",
            "s them. If needed, instructions for removing the cuDNN binaries after installati\n",
            "on of Anaconda Distribution are available at http://www.anaconda.com.\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "Anaconda Distribution also contains Visual Studio Code software binaries from Mi\n",
            "crosoft Corporation (\"VS Code\"). You are specifically authorized to use VS Code \n",
            "with your installation of Anaconda Distribution. Use of VS Code is subject to th\n",
            "e licensing terms located at https://code.visualstudio.com/License.\n",
            "\u001b[K\n",
            "Cryptography Notice\n",
            "===================\n",
            "\u001b[K\n",
            "This distribution includes cryptographic software. The country in which you curr\n",
            "ently reside may have restrictions on the import, possession, use, and/or re-exp\n",
            "ort to another country, of encryption software. BEFORE using any encryption soft\n",
            "ware, please check your country's laws, regulations and policies concerning the \n",
            "import, possession, or use, and re-export of encryption software, to see if this\n",
            " is permitted. See the Wassenaar Arrangement http://www.wassenaar.org/ for more \n",
            "information.\n",
            "\u001b[K\n",
            "Anaconda, Inc. has self-classified this software as Export Commodity Control Num\n",
            "ber (ECCN) 5D992b, which includes mass market information security software usin\n",
            "g or performing cryptographic functions with asymmetric algorithms. No license i\n",
            "s required for export of this software to non-embargoed countries. In addition, \n",
            "the Intel(TM) Math Kernel Library contained in Anaconda, Inc.'s software is clas\n",
            "sified by Intel(TM) as ECCN 5D992b with no license required for export to non-em\n",
            "bargoed countries and Microsoft's Visual Studio Code software is classified by M\n",
            "icrosoft as ECCN 5D992.c with no license required for export to non-embargoed co\n",
            "untries.\n",
            "\u001b[K\n",
            "The following packages are included in this distribution that relate to cryptogr\n",
            "aphy:\u001b[K\n",
            "\u001b[K\n",
            "openssl\u001b[K\n",
            "    The OpenSSL Project is a collaborative effort to develop a robust, commercia\n",
            "l-grade, full-featured, and Open Source toolkit implementing the Transport Layer\n",
            " Security (TLS) and Secure Sockets Layer (SSL) protocols as well as a full-stren\n",
            "gth general purpose cryptography library.\n",
            "\u001b[K\n",
            "pycrypto\n",
            "    A collection of both secure hash functions (such as SHA256 and RIPEMD160), a\n",
            "nd various encryption algorithms (AES, DES, RSA, ElGamal, etc.).\n",
            "\u001b[K\n",
            "pyopenssl\n",
            "    A thin Python wrapper around (a subset of) the OpenSSL library.\n",
            "\u001b[K\n",
            "kerberos (krb5, non-Windows platforms)\n",
            "    A network authentication protocol designed to provide strong authentication \n",
            "for client/server applications by using secret-key cryptography.\n",
            "\u001b[K\n",
            "cryptography\n",
            "    A Python library which exposes cryptographic recipes and primitives.\n",
            "\u001b[K\n",
            "\n",
            "Do you accept the license terms? [yes|no]\n",
            "[no] >>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> \n",
            "Please answer 'yes' or 'no':'\n",
            ">>> yes\n",
            "\n",
            "Anaconda3 will now be installed into this location:\n",
            "/root/anaconda3\n",
            "\n",
            "  - Press ENTER to confirm the location\n",
            "  - Press CTRL-C to abort the installation\n",
            "  - Or specify a different location below\n",
            "\n",
            "[/root/anaconda3] >>> \n",
            "PREFIX=/root/anaconda3\n",
            "installing: python-3.7.3-h0371630_0 ...\n",
            "Python 3.7.3\n",
            "installing: conda-env-2.6.0-1 ...\n",
            "installing: blas-1.0-mkl ...\n",
            "installing: ca-certificates-2019.1.23-0 ...\n",
            "installing: intel-openmp-2019.3-199 ...\n",
            "installing: libgcc-ng-8.2.0-hdf63c60_1 ...\n",
            "installing: libgfortran-ng-7.3.0-hdf63c60_0 ...\n",
            "installing: libstdcxx-ng-8.2.0-hdf63c60_1 ...\n",
            "installing: bzip2-1.0.6-h14c3975_5 ...\n",
            "installing: expat-2.2.6-he6710b0_0 ...\n",
            "installing: fribidi-1.0.5-h7b6447c_0 ...\n",
            "installing: gmp-6.1.2-h6c8ec71_1 ...\n",
            "installing: graphite2-1.3.13-h23475e2_0 ...\n",
            "installing: icu-58.2-h9c2bf20_1 ...\n",
            "installing: jbig-2.1-hdba287a_0 ...\n",
            "installing: jpeg-9b-h024ee3a_2 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: liblief-0.9.0-h7725739_2 ...\n",
            "installing: libsodium-1.0.16-h1bed415_0 ...\n",
            "installing: libtool-2.4.6-h7b6447c_5 ...\n",
            "installing: libuuid-1.0.3-h1bed415_2 ...\n",
            "installing: libxcb-1.13-h1bed415_1 ...\n",
            "installing: lz4-c-1.8.1.2-h14c3975_0 ...\n",
            "installing: lzo-2.10-h49e0be7_2 ...\n",
            "installing: mkl-2019.3-199 ...\n",
            "installing: ncurses-6.1-he6710b0_1 ...\n",
            "installing: openssl-1.1.1b-h7b6447c_1 ...\n",
            "installing: patchelf-0.9-he6710b0_3 ...\n",
            "installing: pcre-8.43-he6710b0_0 ...\n",
            "installing: pixman-0.38.0-h7b6447c_0 ...\n",
            "installing: snappy-1.1.7-hbae5bb6_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-h7b6447c_3 ...\n",
            "installing: blosc-1.15.0-hd408876_0 ...\n",
            "installing: glib-2.56.2-hd408876_0 ...\n",
            "installing: hdf5-1.10.4-hb1b8bf9_0 ...\n",
            "installing: libedit-3.1.20181209-hc058e9b_0 ...\n",
            "installing: libpng-1.6.36-hbc83047_0 ...\n",
            "installing: libssh2-1.8.0-h1ba5d50_4 ...\n",
            "installing: libxml2-2.9.9-he19cac6_0 ...\n",
            "installing: mpfr-4.0.1-hdf1c602_3 ...\n",
            "installing: pandoc-2.2.3.2-0 ...\n",
            "installing: readline-7.0-h7b6447c_5 ...\n",
            "installing: tk-8.6.8-hbc83047_0 ...\n",
            "installing: zeromq-4.3.1-he6710b0_3 ...\n",
            "installing: zstd-1.3.7-h0b5b093_0 ...\n",
            "installing: dbus-1.13.6-h746ee38_0 ...\n",
            "installing: freetype-2.9.1-h8a8886c_1 ...\n",
            "installing: gstreamer-1.14.0-hb453b48_1 ...\n",
            "installing: krb5-1.16.1-h173b8e3_7 ...\n",
            "installing: libarchive-3.3.3-h5d8350f_5 ...\n",
            "installing: libtiff-4.0.10-h2733197_2 ...\n",
            "installing: libxslt-1.1.33-h7d1a2b0_0 ...\n",
            "installing: mpc-1.1.0-h10f8cd9_1 ...\n",
            "installing: sqlite-3.27.2-h7b6447c_0 ...\n",
            "installing: unixodbc-2.3.7-h14c3975_0 ...\n",
            "installing: fontconfig-2.13.0-h9420a91_0 ...\n",
            "installing: gst-plugins-base-1.14.0-hbbd80ab_1 ...\n",
            "installing: libcurl-7.64.0-h20c2e04_2 ...\n",
            "installing: alabaster-0.7.12-py37_0 ...\n",
            "installing: asn1crypto-0.24.0-py37_0 ...\n",
            "installing: atomicwrites-1.3.0-py37_1 ...\n",
            "installing: attrs-19.1.0-py37_1 ...\n",
            "installing: backcall-0.1.0-py37_0 ...\n",
            "installing: backports-1.0-py37_1 ...\n",
            "installing: bitarray-0.8.3-py37h14c3975_0 ...\n",
            "installing: boto-2.49.0-py37_0 ...\n",
            "installing: cairo-1.14.12-h8948797_3 ...\n",
            "installing: certifi-2019.3.9-py37_0 ...\n",
            "installing: chardet-3.0.4-py37_1 ...\n",
            "installing: click-7.0-py37_0 ...\n",
            "installing: cloudpickle-0.8.0-py37_0 ...\n",
            "installing: colorama-0.4.1-py37_0 ...\n",
            "installing: contextlib2-0.5.5-py37_0 ...\n",
            "installing: curl-7.64.0-hbc83047_2 ...\n",
            "installing: dask-core-1.1.4-py37_1 ...\n",
            "installing: decorator-4.4.0-py37_1 ...\n",
            "installing: defusedxml-0.5.0-py37_1 ...\n",
            "installing: docutils-0.14-py37_0 ...\n",
            "installing: entrypoints-0.3-py37_0 ...\n",
            "installing: et_xmlfile-1.0.1-py37_0 ...\n",
            "installing: fastcache-1.0.2-py37h14c3975_2 ...\n",
            "installing: filelock-3.0.10-py37_0 ...\n",
            "installing: future-0.17.1-py37_0 ...\n",
            "installing: glob2-0.6-py37_1 ...\n",
            "installing: gmpy2-2.0.8-py37h10f8cd9_2 ...\n",
            "installing: greenlet-0.4.15-py37h7b6447c_0 ...\n",
            "installing: heapdict-1.0.0-py37_2 ...\n",
            "installing: idna-2.8-py37_0 ...\n",
            "installing: imagesize-1.1.0-py37_0 ...\n",
            "installing: ipython_genutils-0.2.0-py37_0 ...\n",
            "installing: itsdangerous-1.1.0-py37_0 ...\n",
            "installing: jdcal-1.4-py37_0 ...\n",
            "installing: jeepney-0.4-py37_0 ...\n",
            "installing: kiwisolver-1.0.1-py37hf484d3e_0 ...\n",
            "installing: lazy-object-proxy-1.3.1-py37h14c3975_2 ...\n",
            "installing: llvmlite-0.28.0-py37hd408876_0 ...\n",
            "installing: locket-0.2.0-py37_1 ...\n",
            "installing: lxml-4.3.2-py37hefd8a0e_0 ...\n",
            "installing: markupsafe-1.1.1-py37h7b6447c_0 ...\n",
            "installing: mccabe-0.6.1-py37_1 ...\n",
            "installing: mistune-0.8.4-py37h7b6447c_0 ...\n",
            "installing: mkl-service-1.1.2-py37he904b0f_5 ...\n",
            "installing: more-itertools-6.0.0-py37_0 ...\n",
            "installing: mpmath-1.1.0-py37_0 ...\n",
            "installing: msgpack-python-0.6.1-py37hfd86e86_1 ...\n",
            "installing: numpy-base-1.16.2-py37hde5b4d6_0 ...\n",
            "installing: olefile-0.46-py37_0 ...\n",
            "installing: pandocfilters-1.4.2-py37_1 ...\n",
            "installing: parso-0.3.4-py37_0 ...\n",
            "installing: pep8-1.7.1-py37_0 ...\n",
            "installing: pickleshare-0.7.5-py37_0 ...\n",
            "installing: pkginfo-1.5.0.1-py37_0 ...\n",
            "installing: pluggy-0.9.0-py37_0 ...\n",
            "installing: ply-3.11-py37_0 ...\n",
            "installing: prometheus_client-0.6.0-py37_0 ...\n",
            "installing: psutil-5.6.1-py37h7b6447c_0 ...\n",
            "installing: ptyprocess-0.6.0-py37_0 ...\n",
            "installing: py-1.8.0-py37_0 ...\n",
            "installing: py-lief-0.9.0-py37h7725739_2 ...\n",
            "installing: pycodestyle-2.5.0-py37_0 ...\n",
            "installing: pycosat-0.6.3-py37h14c3975_0 ...\n",
            "installing: pycparser-2.19-py37_0 ...\n",
            "installing: pycrypto-2.6.1-py37h14c3975_9 ...\n",
            "installing: pycurl-7.43.0.2-py37h1ba5d50_0 ...\n",
            "installing: pyflakes-2.1.1-py37_0 ...\n",
            "installing: pyodbc-4.0.26-py37he6710b0_0 ...\n",
            "installing: pyparsing-2.3.1-py37_0 ...\n",
            "installing: pysocks-1.6.8-py37_0 ...\n",
            "installing: python-libarchive-c-2.8-py37_6 ...\n",
            "installing: pytz-2018.9-py37_0 ...\n",
            "installing: pyyaml-5.1-py37h7b6447c_0 ...\n",
            "installing: pyzmq-18.0.0-py37he6710b0_0 ...\n",
            "installing: qt-5.9.7-h5867ecd_1 ...\n",
            "installing: qtpy-1.7.0-py37_1 ...\n",
            "installing: rope-0.12.0-py37_0 ...\n",
            "installing: ruamel_yaml-0.15.46-py37h14c3975_0 ...\n",
            "installing: send2trash-1.5.0-py37_0 ...\n",
            "installing: simplegeneric-0.8.1-py37_2 ...\n",
            "installing: sip-4.19.8-py37hf484d3e_0 ...\n",
            "installing: six-1.12.0-py37_0 ...\n",
            "installing: snowballstemmer-1.2.1-py37_0 ...\n",
            "installing: sortedcontainers-2.1.0-py37_0 ...\n",
            "installing: soupsieve-1.8-py37_0 ...\n",
            "installing: sphinxcontrib-1.0-py37_1 ...\n",
            "installing: sqlalchemy-1.3.1-py37h7b6447c_0 ...\n",
            "installing: tblib-1.3.2-py37_0 ...\n",
            "installing: testpath-0.4.2-py37_0 ...\n",
            "installing: toolz-0.9.0-py37_0 ...\n",
            "installing: tornado-6.0.2-py37h7b6447c_0 ...\n",
            "installing: tqdm-4.31.1-py37_1 ...\n",
            "installing: unicodecsv-0.14.1-py37_0 ...\n",
            "installing: wcwidth-0.1.7-py37_0 ...\n",
            "installing: webencodings-0.5.1-py37_1 ...\n",
            "installing: werkzeug-0.14.1-py37_0 ...\n",
            "installing: wrapt-1.11.1-py37h7b6447c_0 ...\n",
            "installing: wurlitzer-1.0.2-py37_0 ...\n",
            "installing: xlrd-1.2.0-py37_0 ...\n",
            "installing: xlsxwriter-1.1.5-py37_0 ...\n",
            "installing: xlwt-1.3.0-py37_0 ...\n",
            "installing: zipp-0.3.3-py37_1 ...\n",
            "installing: babel-2.6.0-py37_0 ...\n",
            "installing: backports.os-0.1.1-py37_0 ...\n",
            "installing: backports.shutil_get_terminal_size-1.0.0-py37_2 ...\n",
            "installing: beautifulsoup4-4.7.1-py37_1 ...\n",
            "installing: cffi-1.12.2-py37h2e261b9_1 ...\n",
            "installing: cycler-0.10.0-py37_0 ...\n",
            "installing: cytoolz-0.9.0.1-py37h14c3975_1 ...\n",
            "installing: harfbuzz-1.8.8-hffaf4a1_0 ...\n",
            "installing: html5lib-1.0.1-py37_0 ...\n",
            "installing: importlib_metadata-0.8-py37_0 ...\n",
            "installing: jedi-0.13.3-py37_0 ...\n",
            "installing: mkl_random-1.0.2-py37hd81dba3_0 ...\n",
            "installing: multipledispatch-0.6.0-py37_0 ...\n",
            "installing: nltk-3.4-py37_1 ...\n",
            "installing: openpyxl-2.6.1-py37_1 ...\n",
            "installing: packaging-19.0-py37_0 ...\n",
            "installing: partd-0.3.10-py37_1 ...\n",
            "installing: pathlib2-2.3.3-py37_0 ...\n",
            "installing: pexpect-4.6.0-py37_0 ...\n",
            "installing: pillow-5.4.1-py37h34e0f95_0 ...\n",
            "installing: pyqt-5.9.2-py37h05f1152_2 ...\n",
            "installing: pyrsistent-0.14.11-py37h7b6447c_0 ...\n",
            "installing: python-dateutil-2.8.0-py37_0 ...\n",
            "installing: qtawesome-0.5.7-py37_1 ...\n",
            "installing: setuptools-40.8.0-py37_0 ...\n",
            "installing: singledispatch-3.4.0.3-py37_0 ...\n",
            "installing: sortedcollections-1.1.2-py37_0 ...\n",
            "installing: sphinxcontrib-websupport-1.1.0-py37_1 ...\n",
            "installing: sympy-1.3-py37_0 ...\n",
            "installing: terminado-0.8.1-py37_1 ...\n",
            "installing: traitlets-4.3.2-py37_0 ...\n",
            "installing: zict-0.1.4-py37_0 ...\n",
            "installing: astroid-2.2.5-py37_0 ...\n",
            "installing: bleach-3.1.0-py37_0 ...\n",
            "installing: clyent-1.2.2-py37_1 ...\n",
            "installing: cryptography-2.6.1-py37h1ba5d50_0 ...\n",
            "installing: cython-0.29.6-py37he6710b0_0 ...\n",
            "installing: distributed-1.26.0-py37_1 ...\n",
            "installing: get_terminal_size-1.0.0-haa9412d_0 ...\n",
            "installing: gevent-1.4.0-py37h7b6447c_0 ...\n",
            "installing: isort-4.3.16-py37_0 ...\n",
            "installing: jinja2-2.10-py37_0 ...\n",
            "installing: jsonschema-3.0.1-py37_0 ...\n",
            "installing: jupyter_core-4.4.0-py37_0 ...\n",
            "installing: navigator-updater-0.2.1-py37_0 ...\n",
            "installing: networkx-2.2-py37_1 ...\n",
            "installing: nose-1.3.7-py37_2 ...\n",
            "installing: pango-1.42.4-h049681c_0 ...\n",
            "installing: path.py-11.5.0-py37_0 ...\n",
            "installing: pygments-2.3.1-py37_0 ...\n",
            "installing: pytest-4.3.1-py37_0 ...\n",
            "installing: wheel-0.33.1-py37_0 ...\n",
            "installing: conda-verify-3.1.1-py37_0 ...\n",
            "installing: flask-1.0.2-py37_1 ...\n",
            "installing: jupyter_client-5.2.4-py37_0 ...\n",
            "installing: nbformat-4.4.0-py37_0 ...\n",
            "installing: pip-19.0.3-py37_0 ...\n",
            "installing: prompt_toolkit-2.0.9-py37_0 ...\n",
            "installing: pylint-2.3.1-py37_0 ...\n",
            "installing: pyopenssl-19.0.0-py37_0 ...\n",
            "installing: pytest-openfiles-0.3.2-py37_0 ...\n",
            "installing: pytest-remotedata-0.3.1-py37_0 ...\n",
            "installing: secretstorage-3.1.1-py37_0 ...\n",
            "installing: ipython-7.4.0-py37h39e3cac_0 ...\n",
            "installing: keyring-18.0.0-py37_0 ...\n",
            "installing: nbconvert-5.4.1-py37_3 ...\n",
            "installing: urllib3-1.24.1-py37_0 ...\n",
            "installing: ipykernel-5.1.0-py37h39e3cac_0 ...\n",
            "installing: requests-2.21.0-py37_0 ...\n",
            "installing: anaconda-client-1.7.2-py37_0 ...\n",
            "installing: conda-4.6.11-py37_0 ...\n",
            "installing: jupyter_console-6.0.0-py37_0 ...\n",
            "installing: notebook-5.7.8-py37_0 ...\n",
            "installing: qtconsole-4.4.3-py37_0 ...\n",
            "installing: sphinx-1.8.5-py37_0 ...\n",
            "installing: spyder-kernels-0.4.2-py37_0 ...\n",
            "installing: anaconda-navigator-1.9.7-py37_0 ...\n",
            "installing: anaconda-project-0.8.2-py37_0 ...\n",
            "installing: conda-build-3.17.8-py37_0 ...\n",
            "installing: jupyterlab_server-0.2.0-py37_0 ...\n",
            "installing: numpydoc-0.8.0-py37_0 ...\n",
            "installing: widgetsnbextension-3.4.2-py37_0 ...\n",
            "installing: ipywidgets-7.4.2-py37_0 ...\n",
            "installing: jupyterlab-0.35.4-py37hf63ae98_0 ...\n",
            "installing: spyder-3.3.3-py37_0 ...\n",
            "installing: _ipyw_jlab_nb_ext_conf-0.1.0-py37_0 ...\n",
            "installing: jupyter-1.0.0-py37_7 ...\n",
            "installing: bokeh-1.0.4-py37_0 ...\n",
            "installing: bottleneck-1.2.1-py37h035aef0_1 ...\n",
            "installing: h5py-2.9.0-py37h7918eee_0 ...\n",
            "installing: imageio-2.5.0-py37_0 ...\n",
            "installing: matplotlib-3.0.3-py37h5429711_0 ...\n",
            "installing: mkl_fft-1.0.10-py37ha843d7b_0 ...\n",
            "installing: numpy-1.16.2-py37h7e9f1db_0 ...\n",
            "installing: numba-0.43.1-py37h962f231_0 ...\n",
            "installing: numexpr-2.6.9-py37h9e4a6bb_0 ...\n",
            "installing: pandas-0.24.2-py37he6710b0_0 ...\n",
            "installing: pytest-arraydiff-0.3-py37h39e3cac_0 ...\n",
            "installing: pytest-doctestplus-0.3.0-py37_0 ...\n",
            "installing: pywavelets-1.0.2-py37hdd07704_0 ...\n",
            "installing: scipy-1.2.1-py37h7c811a0_0 ...\n",
            "installing: bkcharts-0.2-py37_0 ...\n",
            "installing: dask-1.1.4-py37_1 ...\n",
            "installing: patsy-0.5.1-py37_0 ...\n",
            "installing: pytables-3.5.1-py37h71ec239_0 ...\n",
            "installing: pytest-astropy-0.5.0-py37_0 ...\n",
            "installing: scikit-image-0.14.2-py37he6710b0_0 ...\n",
            "installing: scikit-learn-0.20.3-py37hd81dba3_0 ...\n",
            "installing: astropy-3.1.2-py37h7b6447c_0 ...\n",
            "installing: statsmodels-0.9.0-py37h035aef0_0 ...\n",
            "installing: seaborn-0.9.0-py37_0 ...\n",
            "installing: anaconda-2019.03-py37_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Anaconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Anaconda3: /root/anaconda3\n",
            "Do you wish the installer to initialize Anaconda3\n",
            "by running conda init? [yes|no]\n",
            "[no] >>> "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Vl5UF9qbrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeTelJfXqlVq",
        "colab_type": "text"
      },
      "source": [
        "### Create an Environment\n",
        "https://medium.com/@nrk25693/how-to-add-your-conda-environment-to-your-jupyter-notebook-in-just-4-steps-abeab8b8d084"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57ZTwkJApkfV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d00a2940-643b-4531-bf2f-05545543d595"
      },
      "source": [
        "!conda create --name gender"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lFctT8bvVCJ9"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RSlIksK3-BSm",
        "outputId": "b4a2de92-bb0a-4141-cf85-d149e4f1057f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e3uubDldnEOO",
        "outputId": "7454f357-def9-4b29-9e0e-650da8b0468e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!conda info --envs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "puJwG-ymnEOS",
        "outputId": "6560443f-9d6a-49fc-8273-1ea407b2db43",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!source activate gender"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: activate: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7F74akq3VCJ-"
      },
      "source": [
        "https://github.com/zalandoresearch/flair\n",
        "\n",
        "https://github.com/huggingface/neuralcoref"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zvn8rO3mVCKA",
        "outputId": "53c6db4f-bb69-4a16-8793-4b24c3aa71a5",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install flair==0.4.2\n",
        "!pip uninstall spacy --yes\n",
        "!pip install -U spacy==2.1.0\n",
        "##!python -m spacy download en # SMALL VERSION OF SPACY, FAST DOWNLOAD\n",
        "##!python -m spacy download en_core_web_md # MEDIUM VERSION OF SPACY\n",
        "!python -m spacy download en_core_web_lg # LARGE VERSION OF SPACY, SLOW DOWNLOAD\n",
        "!pip install neuralcoref --no-binary neuralcoref\n",
        "#!pip uninstall torch torchvision --yes\n",
        "#!pip install torch==1.3.0 torchvision==0.4.0\n",
        "#!pip install keras==2.2.4\n",
        "#!conda install -c conda-forge tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair==0.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (4.38.0)\n",
            "Collecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.8.7)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.0)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (2019.12.20)\n",
            "Collecting pytorch-pretrained-bert>=0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 60.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.4.0)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.0)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.2.1)\n",
            "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.4)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.24.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair==0.4.2) (1.18.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair==0.4.2) (2.21.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair==0.4.2) (0.22.2.post1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.2) (1.12.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.12.27)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.12.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.4.6)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (8.2.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (46.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (2.4)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (3.10.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair==0.4.2) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.15.27)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.9.5)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (1.18.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.2) (4.4.2)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.15.2)\n",
            "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (1.7.2)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (1.0.3)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (0.2.8)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (1.16.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (0.4.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (1.51.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (3.10.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (2018.9)\n",
            "Building wheels for collected packages: segtok, sqlitedict, mpld3\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=c73b1720391f7de8827304d5bdf7e78ba7078608b6abb224d31a853a9d992c2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=f42a6ee532c266243202b8a89663fd920c4e79519d48f6c39ae5d8ffcb390306\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=cdd67e4b839ca406a790b4207792fe49c5eb4ef5d0633b89544c8e4e5d917c76\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "Successfully built segtok sqlitedict mpld3\n",
            "Installing collected packages: sentencepiece, bpemb, deprecated, segtok, pytorch-pretrained-bert, sqlitedict, mpld3, flair\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.7 flair-0.4.2 mpld3-0.3 pytorch-pretrained-bert-0.6.2 segtok-1.5.7 sentencepiece-0.1.85 sqlitedict-1.6.0\n",
            "Uninstalling spacy-2.2.4:\n",
            "  Successfully uninstalled spacy-2.2.4\n",
            "Collecting spacy==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/39/4bde5da5f18ab0bdd525760c4fe38808b4bb03907a2aea094000d831afe1/spacy-2.1.0-cp36-cp36m-manylinux1_x86_64.whl (27.7MB)\n",
            "\u001b[K     |████████████████████████████████| 27.7MB 111kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.0.2)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.0.12 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (0.6.0)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (2.6.0)\n",
            "Collecting plac<1.0.0,>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Collecting thinc<7.1.0,>=7.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.0) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.0) (4.38.0)\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: preshed, blis, plac, thinc, spacy\n",
            "  Found existing installation: preshed 3.0.2\n",
            "    Uninstalling preshed-3.0.2:\n",
            "      Successfully uninstalled preshed-3.0.2\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "Successfully installed blis-0.2.4 plac-0.9.6 preshed-2.0.1 spacy-2.1.0 thinc-7.0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "blis",
                  "plac",
                  "plac_core",
                  "plac_ext",
                  "preshed",
                  "spacy",
                  "thinc"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
            "\u001b[K     |████████████████████████████████| 826.9MB 100.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255078 sha256=6b322e6f96f084dd798303601e7e5da341af5da900efb2ae0f04a76373d9bf25\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a5ro5f3i/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "Collecting neuralcoref\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/40/8db3db763077fe80b71859f57731261aeb03cc624635f97a3bcfe55ab37b/neuralcoref-4.0.tar.gz (368kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.18.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.12.27)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.21.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.1.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (1.15.27)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.0.12 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->neuralcoref) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->neuralcoref) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.38.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.27->boto3->neuralcoref) (1.12.0)\n",
            "Skipping wheel build for neuralcoref, due to binaries being disabled for it.\n",
            "Installing collected packages: neuralcoref\n",
            "    Running setup.py install for neuralcoref ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed neuralcoref-4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rSa3KyZnt4Ja",
        "outputId": "71879801-b9fd-4982-f0c0-42b106c90f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "!pip uninstall torch torchvision -y\n",
        "!pip install torch==1.3.1+cu100 torchvision==0.4.2+cu100 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.3.1+cu100\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.3.1%2Bcu100-cp36-cp36m-linux_x86_64.whl (705.3MB)\n",
            "\u001b[K     |████████████████████████████████| 705.3MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.2+cu100\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torchvision-0.4.2%2Bcu100-cp36-cp36m-linux_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.2MB 340kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.3.1+cu100) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2+cu100) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2+cu100) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "Successfully installed torch-1.3.1+cu100 torchvision-0.4.2+cu100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Otn_BP2dUtKy",
        "outputId": "16f7371b-07fe-4dc9-de00-cedc9b5d2853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        }
      },
      "source": [
        "!pip uninstall tesnforflow --yes\n",
        "!pip install tensorflow-gpu==1.14\n",
        "!pip uninstall keras --yes\n",
        "!pip install keras==2.2.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping tesnforflow as it is not installed.\u001b[0m\n",
            "Collecting tensorflow-gpu==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.18.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.27.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (39.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.2.1)\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc1 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc1 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 1.11.0\n",
            "    Uninstalling tensorboard-1.11.0:\n",
            "      Successfully uninstalled tensorboard-1.11.0\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow-gpu 1.11.0\n",
            "    Uninstalling tensorflow-gpu-1.11.0:\n",
            "      Successfully uninstalled tensorflow-gpu-1.11.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n",
            "Uninstalling Keras-2.2.4:\n",
            "  Successfully uninstalled Keras-2.2.4\n",
            "Collecting keras==2.2.4\n",
            "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dBNGIakZnEOb",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "## Not on Colab\n",
        "#!conda uninstall tensorflow --yes\n",
        "#!conda install tensorflow-gpu anaconda --yes\n",
        "#!conda install -c pytorch pytorch --yes "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ylKonOmZnEOe",
        "outputId": "2a6e7b7a-3c00-43ec-8470-728c9ce44b3a",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 12463094563540319059\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QaVft4zOn74O",
        "outputId": "416bee0a-be20-4d6e-cbac-0096ec4ef648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "!pip uninstall tensorflow-gpu tensorflow tensorflow-base"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
            "Uninstalling tensorflow-2.2.0rc1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.2.0rc1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "y\n",
            "  Successfully uninstalled tensorflow-2.2.0rc1\n",
            "\u001b[33mWARNING: Skipping tensorflow-base as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_aeeeD0WpJ_7",
        "outputId": "18b58fb1-fb15-4628-8b98-7924b109510d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!pip uninstall keras -y\n",
        "!pip install keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Keras-2.2.5:\n",
            "  Successfully uninstalled Keras-2.2.5\n",
            "Collecting keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dydTLlC0oA1Y",
        "outputId": "3f984d8b-a4aa-4fe4-be0f-deb7298caa5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (46.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=a8c39d9d22bcce2579a4fbadb503c85730e9f0cccfe04432bf78f6ab39eb3bb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Z7Cn3ZCb2Nh",
        "outputId": "0fd38c82-f99c-4f05-bcf8-ee3886a0673e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade --force-reinstall tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/e7/172a9eeee2bf44fe6f02922d075ece11a0dbd026e672b9fe4716745ba142/tensorflow_gpu-2.1.0-cp36-cp36m-win_amd64.whl (356.5MB)\n",
            "Collecting six>=1.12.0 (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
            "Collecting tensorflow-gpu-estimator<2.2.0,>=2.1.0rc0 (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/06/9e/57edfd2684d46992850522bf3dad4807fa15b80ade090f64ffa544abbeea/tensorflow_gpu_estimator-2.1.0-py2.py3-none-any.whl (464kB)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "Collecting keras-preprocessing>=1.1.0 (from tensorflow-gpu)\n",
            "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
            "Collecting numpy<2.0,>=1.16.0 (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/2d/24/82c216bbf8f9a781d8ff84899f95e31aaa6f219f999ae8b254b32595ac76/numpy-1.18.2-cp36-cp36m-win_amd64.whl (12.8MB)\n",
            "Collecting grpcio>=1.8.6 (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/12/5f/e781305bd0428f02aca645e23c09a75c508a063bf0247da9deda94d58b37/grpcio-1.27.2-cp36-cp36m-win_amd64.whl (2.0MB)\n",
            "Collecting scipy==1.4.1; python_version >= \"3\" (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/2f/fcb6150813b89d628749784370132e431f687ebab5a1063eb298cc941f76/scipy-1.4.1-cp36-cp36m-win_amd64.whl (30.8MB)\n",
            "Collecting gast==0.2.2 (from tensorflow-gpu)\n",
            "  Using cached https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting absl-py>=0.7.0 (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
            "Collecting wheel>=0.26; python_version >= \"3\" (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
            "Collecting wrapt>=1.11.1 (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz\n",
            "Collecting protobuf>=3.8.0 (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/52/a71156b82dbb8a40833b7a571e22c9e65ca4204a56739f97d3eaa25d111e/protobuf-3.11.3-cp36-cp36m-win_amd64.whl (1.1MB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow-gpu)\n",
            "  Using cached https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/49/2233e63052d5686c72131b579837ddfb98ba9dd0b92bb91efcb441ada8ce/opt_einsum-3.2.0-py3-none-any.whl (63kB)\n",
            "Collecting google-pasta>=0.1.6 (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
            "Collecting astor>=0.6.0 (from tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
            "Collecting keras-applications>=1.0.8 (from tensorflow-gpu)\n",
            "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
            "Collecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/a5/d6f8a6e71f15364d35678a4ec8a0186f980b3bd2545f40ad51dd26a87fb1/Werkzeug-1.0.0-py2.py3-none-any.whl (298kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)\n",
            "Collecting setuptools>=41.0.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/df/635cdb901ee4a8a42ec68e480c49f85f4c59e8816effbf57d9e6ee8b3588/setuptools-46.1.3-py3-none-any.whl (582kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl (58kB)\n",
            "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/05/b0/cc391ebf8ebf7855cdcfe0a9a4cdc8dcd90287c90e1ac22651d104ac6481/google_auth-1.12.0-py2.py3-none-any.whl (83kB)\n",
            "Collecting h5py (from keras-applications>=1.0.8->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/fa/bee65d2dbdbd3611702aafd128139c53c90a1285f169ba5467aab252e27a/h5py-2.10.0-cp36-cp36m-win_amd64.whl (2.4MB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
            "Collecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl (58kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl (125kB)\n",
            "Collecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl (156kB)\n",
            "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
            "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n",
            "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
            "Building wheels for collected packages: gast, absl-py, wrapt, termcolor\n",
            "  Building wheel for gast (setup.py): started\n",
            "  Building wheel for gast (setup.py): finished with status 'done'\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7546 sha256=b54b374c9a7bce8c4874e7ed323b18e530bef643188f4a134818cff5af309ddd\n",
            "  Stored in directory: C:\\Users\\Hp\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for absl-py (setup.py): started\n",
            "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
            "  Created wheel for absl-py: filename=absl_py-0.9.0-cp36-none-any.whl size=121936 sha256=fa235e7c9fd4a7d59e48ee6ee53f2ec53aec5723d330026afaee240b86a79b30\n",
            "  Stored in directory: C:\\Users\\Hp\\AppData\\Local\\pip\\Cache\\wheels\\8e\\28\\49\\fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
            "  Building wheel for wrapt (setup.py): started\n",
            "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-win_amd64.whl size=33230 sha256=403a601bd18a3aeb7e37f05294af3732e3bcee34c5d1fb9a43417288d52edcd2\n",
            "  Stored in directory: C:\\Users\\Hp\\AppData\\Local\\pip\\Cache\\wheels\\b1\\c2\\ed\\d62208260edbd3fa7156545c00ef966f45f2063d0a84f8208a\n",
            "  Building wheel for termcolor (setup.py): started\n",
            "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-cp36-none-any.whl size=4837 sha256=0c032bdc1c226bbdfcaa60255d327c387d10f26522c04d4ace17194d804d15fa\n",
            "  Stored in directory: C:\\Users\\Hp\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
            "Successfully built gast absl-py wrapt termcolor\n",
            "Installing collected packages: six, tensorflow-gpu-estimator, absl-py, werkzeug, setuptools, markdown, numpy, protobuf, idna, urllib3, chardet, certifi, requests, oauthlib, requests-oauthlib, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, wheel, grpcio, tensorboard, keras-preprocessing, scipy, gast, wrapt, termcolor, opt-einsum, google-pasta, astor, h5py, keras-applications, tensorflow-gpu\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: absl-py 0.7.1\n",
            "    Uninstalling absl-py-0.7.1:\n",
            "      Successfully uninstalled absl-py-0.7.1\n",
            "  Found existing installation: Werkzeug 0.15.4\n",
            "    Uninstalling Werkzeug-0.15.4:\n",
            "      Successfully uninstalled Werkzeug-0.15.4\n",
            "  Found existing installation: setuptools 41.0.1\n",
            "    Uninstalling setuptools-41.0.1:\n",
            "      Successfully uninstalled setuptools-41.0.1\n",
            "  Found existing installation: Markdown 3.1.1\n",
            "    Uninstalling Markdown-3.1.1:\n",
            "      Successfully uninstalled Markdown-3.1.1\n",
            "  Found existing installation: numpy 1.16.3\n",
            "    Uninstalling numpy-1.16.3:\n",
            "      Successfully uninstalled numpy-1.16.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR: tensorflow 1.14.0 has requirement tensorboard<1.15.0,>=1.14.0, but you'll have tensorboard 2.1.1 which is incompatible.\n",
            "ERROR: flair 0.4.2 has requirement urllib3<1.25,>=1.20, but you'll have urllib3 1.25.8 which is incompatible.\n",
            "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\users\\\\hp\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n",
            "WARNING: You are using pip version 19.2.2, however version 20.0.2 is available.\n",
            "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cNQ9YRlMnEOk",
        "outputId": "8b292dd8-ae61-4e88-b9ba-4e7ed9abd988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "from keras import backend\n",
        "assert len(backend.tensorflow_backend._get_available_gpus()) > 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0330 03:13:42.170299 23156 deprecation_wrapper.py:119] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0330 03:13:42.174289 23156 deprecation_wrapper.py:119] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0330 03:13:42.182266 23156 deprecation_wrapper.py:119] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0330 03:13:42.367770 23156 deprecation_wrapper.py:119] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-4-3692276c0c24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N31wqboEnEOm",
        "outputId": "c257f2d1-1341-4fe5-c9e2-bdcea3f22351",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pZqwsmTJnEOr",
        "outputId": "67aa64ff-8e89-4a81-b789-f8726872ddd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GeForce MX150'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "03dQLWLvnEO1",
        "outputId": "0a668f13-8fb3-4ca8-c2f7-361426b7b34a",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Mar 29 18:40:13 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    31W / 250W |    353MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4qlzZsMXVCKH"
      },
      "source": [
        "### Creating Language Resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2h4nHNwnVCKJ",
        "colab": {}
      },
      "source": [
        "male_pronouns   = [\"he\",  \"him\", \"his$\", \"his\", \"himself\"]\n",
        "female_pronouns = [\"she\", \"her\", \"her$\", \"hers\", \"herself\"]\n",
        "neutral_pronouns= [\"zie\", \"zim\", \"zir\", \"zis\", \"zieself\"]\n",
        "merged_pronouns = [\"he/she\", \"him/her\", \"his/her\", \"his/hers\", \"himself/herself\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sim_9aXgVCKO",
        "colab": {}
      },
      "source": [
        "gender_pronouns_dict = {}\n",
        "gender_honorific_dict = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IC4J8YREVCKV",
        "colab": {}
      },
      "source": [
        "for (g1,g2,g3,g4) in zip(male_pronouns, female_pronouns, neutral_pronouns, merged_pronouns):\n",
        "    element = {\"male\": g1.replace(\"$\",\"\"), \"female\":g2.replace(\"$\",\"\"), \"neutral\":g3, \"merged\":g4}\n",
        "    gender_pronouns_dict[g1] = gender_pronouns_dict[g2] = gender_pronouns_dict[g3] = gender_pronouns_dict[g4] =element"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QmE6CL7PVCKd",
        "colab": {}
      },
      "source": [
        "male_hons   =  [\"Mr.\", \"Mr\", \"Md.\", \"Md\", \"Sir\", \"Lord\", \"Mister\"]\n",
        "female_hons =  [\"Ms.\", \"Ms\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Miss\"]\n",
        "neutral_hons = [\"Mx.\", \"Mx\", \"Mx.\", \"Mx\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]\n",
        "married_hons = [\"Mrs.\", \"Mrs\", \"Mst.\", \"Mst\", \"Madam\", \"Lady\", \"Mis'ess\"]\n",
        "merged_hons =  [\"Mr./Ms.\", \"Mr/Ms\", \"Md./Mst.\", \"Md/Mst\", \"Sir/Madam\", \"Lord/Lady\", \"Mister/Miss\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbb4Jf6mVCKk",
        "colab": {}
      },
      "source": [
        "for (h1,h2,h3,h4,h5) in zip(male_hons, female_hons, neutral_hons, married_hons, merged_hons):\n",
        "    element = {\"male\": h1, \"female\":h2, \"neutral\":h3, \"married_fem\":h4, \"merged\":h5}\n",
        "    gender_honorific_dict[h1] = gender_honorific_dict[h2] = gender_honorific_dict[h3] = \\\n",
        "    gender_honorific_dict[h4] = gender_honorific_dict[h5] = element"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TzgZxsSUVCKq"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5yTkWcUAYH7n",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZN82xZJgVCKr",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "#from segtok.segmenter import split_single"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MoC0zGDKggFj",
        "colab": {}
      },
      "source": [
        "import flair\n",
        "assert flair.__version__=='0.4.2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kKRKCr8uVCKv",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Be8BR8KQVCKz",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import neuralcoref"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nZuAm9_9VCK5"
      },
      "source": [
        "### Loading Essentials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UI8M4VyXVDV6",
        "outputId": "e83661bc-e8fb-4277-8acb-a3972293b677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!git clone --single-branch --branch development2 https://github.com/Masum06/GenderDebiasing.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nA8Mt85PUHJy",
        "outputId": "ece44004-244e-4cc8-d55f-ff41fcc3836c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd GenderDebiasing"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GenderDebiasing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mjlMu-sNVCK6",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "char2idx = 'resources/char2idx.json'\n",
        "idx2char = 'resources/idx2char.json'\n",
        "with open(char2idx, 'r') as fp:\n",
        "    char2idx = json.load(fp)\n",
        "    \n",
        "with open(idx2char, 'r') as fp:\n",
        "    idx2char = json.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TzVfTDkDoqS4",
        "outputId": "68627f0c-874d-4271-9029-c0f3793a5dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-30 03:15:58,877 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G9u1EvUfpr34",
        "outputId": "709d0e83-ae6f-42bd-ce66-a46248a9ab08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h0BOOa4fVCK-",
        "outputId": "0909c5c3-1266-44dc-9fd3-611e986907cd",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "model_name = 'resources/char_rnn_hsc_model_0.h5'\n",
        "model = load_model(model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-30 03:16:11,927 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "2020-03-30 03:16:12,172 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2020-03-30 03:16:12,688 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "2020-03-30 03:16:12,697 From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ggCw99GvVCLC",
        "outputId": "b67847e4-8514-4190-eadc-89e7de20c632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#nlp = spacy.load('en_core_web_lg') # en_core_web_sm #en_core_web_md\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()\n",
        "neuralcoref.add_to_pipe(nlp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x1b7720ff128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8-VH-28OqMGc",
        "outputId": "baf7a12d-9229-42b8-94c2-86185c301941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aW9R7VuFqRua",
        "outputId": "e7aeaecd-3963-4fc9-8af5-321104ab6543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "!pip uninstall torch -y\n",
        "!pip install torch==1.3.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\n",
            "Collecting torch==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/50a05de5337f7a924bb8bd70c6936230642233e424d6a9747ef1cfbde353/torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (773.1MB)\n",
            "\u001b[K     |████████████████████████████████| 773.1MB 16kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.3.0) (1.18.2)\n",
            "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 1.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eP7eFWBaVCLH",
        "outputId": "e01fc5c0-85e7-4650-c4cc-fb6530ca3bb6",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "tagger_ner = SequenceTagger.load('ner')\n",
        "tagger_pos = SequenceTagger.load('pos')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-30 03:16:37,105 loading file C:\\Users\\Hp\\.flair\\models\\en-ner-conll03-v0.4.pt\n",
            "2020-03-30 03:17:03,712 loading file C:\\Users\\Hp\\.flair\\models\\en-pos-ontonotes-v0.2.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tyHJZ4t-VCLL"
      },
      "source": [
        "### Necessary Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T2FRQ-qzEzDF"
      },
      "source": [
        "Name2Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UExr_6fiVCLM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "# Converts a name into vector\n",
        "def name2vectorTest(name):\n",
        "    name = name.lower()\n",
        "    new_name = \"\"\n",
        "    for char in name:\n",
        "      if char in char2idx:\n",
        "        new_name += char\n",
        "    chars = list(new_name)\n",
        "    vector = [ char2idx[c] for c in chars ]\n",
        "    return np.array(vector)\n",
        "\n",
        "# Converts names to fixed size tensor\n",
        "def names2tensorTest(names, maxlen=25):\n",
        "    namelist = [name2vectorTest(name) for name in names]\n",
        "    return sequence.pad_sequences(np.array(namelist), maxlen=maxlen)  # root of all troubles\n",
        "\n",
        "def name2gender(name):\n",
        "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
        "  if result:\n",
        "    return \"male\"\n",
        "  else:\n",
        "    return \"female\"\n",
        "  \n",
        "def isMale(name):\n",
        "  result = model.predict_classes(np.array(names2tensorTest([name.lower()])))[0][0]\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nXxZYr_mflVz"
      },
      "source": [
        "Storing Names in Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VJzj_UF_VCMX",
        "colab": {}
      },
      "source": [
        "def store(name, name_found, Name2Key, Key2Name, num_keys): \n",
        "    \n",
        "    if name_found not in Name2Key:\n",
        "        #global num_keys\n",
        "        num_keys+=1\n",
        "        key = \"PER_\"+str(num_keys)\n",
        "        #gender = name2gender(name_found)\n",
        "        alias = None\n",
        "        element = {\"name\": name, \"key\": key, \"gender\":None, \"alias\":alias, \"is_alias\": False, \"alias_to\": None}\n",
        "        Name2Key[name_found] = element\n",
        "        Key2Name[key] = {\"name\": name, \"gender\": None, \"alias\": alias}\n",
        "    \n",
        "    if name not in Name2Key:\n",
        "        element_alias = {\"name\": name, \"is_alias\": True, \"alias_to\": name_found}\n",
        "        Name2Key[name] = element_alias\n",
        "        Name2Key[name_found][\"alias\"] = name\n",
        "        \n",
        "    return Name2Key[name_found][\"key\"], num_keys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HSYCQfJcOTLU"
      },
      "source": [
        "# Unit Gender Encryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LJLCTIOQOYav",
        "colab": {}
      },
      "source": [
        "def gender_encrypt(s):\n",
        "  s = ' '.join(s.split())\n",
        "  doc = nlp(s)\n",
        "  tokenized_text = ' '.join([token.text for token in doc])\n",
        "  oracle = []\n",
        "  coref2name = {}\n",
        "\n",
        "  # POS TAG\n",
        "  sent = Sentence(tokenized_text)\n",
        "  tagger_ner.predict(sent)\n",
        "  tagger_pos.predict(sent)\n",
        "  tagged_list = sent.to_tagged_string().split()\n",
        "  tokens_pos = []\n",
        "  pos = []\n",
        "  count = 0\n",
        "  for i in range(0,len(tagged_list),2):\n",
        "      tokens_pos.append(tagged_list[i])\n",
        "      count = count+1\n",
        "      pos.append(tagged_list[i+1])\n",
        "      \n",
        "      if tagged_list[i].lower() in male_pronouns+female_pronouns:\n",
        "          oracle.append(2)\n",
        "      elif tagged_list[i+1] in ['<B-PER/NNP>', '<I-PER/NNP>', '<E-PER/NNP>', '<S-PER/NNP>']:\n",
        "          oracle.append(4)\n",
        "      else:\n",
        "          oracle.append(0)\n",
        "\n",
        "  # COREFERENCE RESOLUTION \n",
        "  if len(doc)!=len(tokens_pos):\n",
        "    tokens_doc = [token.text for token in doc]\n",
        "    print(\"doc:\", tokens_doc)\n",
        "    print(\"pos:\", tokens_pos)\n",
        "    return None, None\n",
        "  \n",
        "  coref_stack = []\n",
        "  name_stack = []\n",
        "  for i in range(len(doc)):\n",
        "      token = doc[i]\n",
        "      if token._.in_coref:\n",
        "          coref_stack.append(tokens_pos[i])\n",
        "          if oracle[i] == 4:\n",
        "              name_stack.append(tokens_pos[i])\n",
        "          oracle[i] += 1\n",
        "      else:\n",
        "          if len(name_stack) > 0:\n",
        "              name = ' '.join(name_stack)\n",
        "              coref = ' '.join(coref_stack)\n",
        "              #name2coref[name] = coref\n",
        "              coref2name[coref] = name\n",
        "              name_stack.clear()\n",
        "          coref_stack.clear()\n",
        "\n",
        "  # IF THE SENTENCE DOES NOT END WITH A PERIOD OR SPECIAL CHARACTER\n",
        "  if len(name_stack) > 0:\n",
        "      name = ' '.join(name_stack)\n",
        "      name2coref[name] = ' '.join(coref_stack)\n",
        "      name_stack.clear()\n",
        "  coref_stack.clear()\n",
        "\n",
        "  Name2Key = {}\n",
        "  Key2Name = {}\n",
        "  encrypted = []\n",
        "  num_keys = 0\n",
        "  i = 0\n",
        "  while i<len(tokens_pos): \n",
        "      #print(\"Oracle \", i, tokens_pos[i])\n",
        "      if oracle[i] == 2:\n",
        "          pronoun = tokens_pos[i].lower()\n",
        "          if pos[i] == '<PRP$>':\n",
        "              pronoun+=\"$\"\n",
        "          encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "      elif oracle[i] == 3:\n",
        "          coref = doc[i]._.coref_clusters[0][0].text\n",
        "          pronoun = tokens_pos[i].lower()\n",
        "          if pos[i] == '<PRP$>':\n",
        "              pronoun+=\"$\"\n",
        "          if coref in coref2name:\n",
        "            name_found = coref2name[coref]\n",
        "            key = Name2Key[name_found][\"key\"]\n",
        "            if pronoun in male_pronouns:\n",
        "              Name2Key[name_found][\"gender\"] = \"male\"\n",
        "            else if pronoun in female_pronouns:\n",
        "              Name2Key[name_found][\"gender\"] = \"female\"\n",
        "            else:\n",
        "              Name2Key[name_found][\"gender\"] = \"<|unk|>\"\n",
        "            encrypted.append(\"<|coref|>\")\n",
        "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "            encrypted.append(key)\n",
        "          else:\n",
        "            encrypted.append(gender_pronouns_dict[pronoun][\"merged\"])\n",
        "          \n",
        "      elif oracle[i] in [4,5]:\n",
        "          if i > 0 and tokens_pos[i-1] in gender_honorific_dict:\n",
        "            hons = encrypted.pop()\n",
        "            if hons in male_hons:\n",
        "              gender = \"male\"\n",
        "            else if hons in female_hons+married_hons:\n",
        "              gender = \"female\"\n",
        "            else:\n",
        "              gender = \"<|unk|>\"\n",
        "            encrypted.append(\"<|hons|>\")\n",
        "            encrypted.append(gender_honorific_dict[hons][\"merged\"])\n",
        "          if pos[i] == '<S-PER/NNP>':\n",
        "              name = tokens_pos[i]\n",
        "          elif pos[i] == '<B-PER/NNP>':\n",
        "              name = \"\"\n",
        "              while True:\n",
        "                  #print(i, oracle[i])\n",
        "                  name += tokens_pos[i]\n",
        "                  if pos[i] == '<E-PER/NNP>':\n",
        "                      break\n",
        "                  name += \" \"\n",
        "                  i+=1\n",
        "          \n",
        "          if oracle[i] == 4:\n",
        "              key, num_keys = store(name, name, Name2Key, Key2Name, num_keys)\n",
        "              encrypted.append(key)\n",
        "          else:\n",
        "              coref = doc[i]._.coref_clusters[0][0].text\n",
        "              name_found = coref2name[coref]\n",
        "              if name == name_found:\n",
        "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                  encrypted.append(key)\n",
        "              else:\n",
        "                  key, num_keys = store(name, name_found, Name2Key, Key2Name, num_keys)\n",
        "                  encrypted.append(\"<|alias|>\")\n",
        "                  encrypted.append(key)\n",
        "          Name2Key[key][\"gender\"] = gender\n",
        "      else:\n",
        "        encrypted.append(tokens_pos[i])\n",
        "      i+=1\n",
        "      \n",
        "  encrypted_text = ' '.join(encrypted)\n",
        "\n",
        "  return tokenized_text, Key2Name, encrypted_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bMItOjUbUQNf"
      },
      "source": [
        "# Gender Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "quTM_EeiVCMu",
        "colab": {}
      },
      "source": [
        "def gender_decrypt(encrypted_text, Key2Name):\n",
        "  encrypted = encrypted_text.split()\n",
        "  decrypted = []\n",
        "  i = 0\n",
        "  while i != len(encrypted):\n",
        "    token = encrypted[i]\n",
        "    if token in Key2Name:\n",
        "      decrypted.append(Key2Name[token][\"name\"])\n",
        "    elif token == '<|alias|>':\n",
        "      i+=1\n",
        "      key = encrypted[i]\n",
        "      if Key2Name[key][\"alias\"]:\n",
        "        decrypted.append(Key2Name[key][\"alias\"])\n",
        "      else:\n",
        "        decrypted.append(Key2Name[key][\"name\"])\n",
        "    elif token == '<|coref|>':\n",
        "      startOfSent = (i==0 or encrypted[i-1] == \".\")\n",
        "      pronoun =  encrypted[i+1]\n",
        "      key = encrypted[i+2]\n",
        "      gender = Key2Name[key][\"gender\"].lower()\n",
        "      decrypted_pronoun = gender_pronouns_dict[pronoun][gender]\n",
        "      decrypted_pronoun = decrypted_pronoun[0].upper()+decrypted_pronoun[1:] if startOfSent else decrypted_pronoun\n",
        "      decrypted.append(decrypted_pronoun)\n",
        "      i+=2\n",
        "    elif token == \"<|hons|>\":\n",
        "      hons = encrypted[i+1]\n",
        "      key = encrypted[i+2] # NEED CHECK FOR HONS IN ALIAS\n",
        "      gender = Key2Name[key][\"gender\"].lower()\n",
        "      decrypted.append(gender_honorific_dict[hons][gender])\n",
        "      i+=1\n",
        "    elif token == \"he/she\":\n",
        "        if i==0 or encrypted[i-1] == \".\":\n",
        "            decrypted.append(\"He/She\")\n",
        "        else:\n",
        "            decrypted.append(\"he/she\")\n",
        "    else:\n",
        "      decrypted.append(token)\n",
        "    i+=1\n",
        "\n",
        "  decrypted_text = ' '.join(decrypted)\n",
        "  #decrypted_text = decrypted_text.replace(\" .\", \".\")\n",
        "  return decrypted_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qv5Y4nngq9AJ",
        "colab": {}
      },
      "source": [
        "key2name_changed = {'PER_1': {'name': 'Abira',\n",
        "    'key': 'PER_1',\n",
        "    'gender': 'Female',\n",
        "    'alias': None,\n",
        "    'is_alias': False,\n",
        "    'alias_to': None},\n",
        "  'PER_2': {'name': 'Shibir',\n",
        "    'key': 'PER_2',\n",
        "    'gender': 'Male',\n",
        "    'alias': None,\n",
        "    'is_alias': False,\n",
        "    'alias_to': None}\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M_Ad5ljDRvvB"
      },
      "source": [
        "### Testing Encryption-Decryption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jDUandyxxJ8m",
        "colab": {}
      },
      "source": [
        "s = \"Mr. John is not a doctor. Ms. Katy is also not a nurse. John can fly, but she cannot swim.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJnQwJd5S_GJ",
        "colab": {}
      },
      "source": [
        "s = \"Morshed Khan told newsmen that 'BNP is a massive party with huge popularity and public acceptance.' This party is now running its operations over Skype. He (Tarique) is operating from London over Skype and that too with only selected leaders. It has turned into the ‘Bangladesh Nationalist Skype Party’. This is painful. I believe the next generation must assume leadership within the party — that would be my recommendation.”\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2WL1lFCFnEQF",
        "colab": {}
      },
      "source": [
        "s = \"Dineshwar then left behind his wife’s stabbed body and hanged himself from a tree in a field nearby.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YsmaikFZFHtl",
        "outputId": "7d647507-2da3-47de-ca79-d97d8e59ab6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(s.split())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5qLWPn4lR1Ss",
        "outputId": "b90350a4-f0d6-4bec-9fa7-a22bec971b8e",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "import time \n",
        "start = time.time()\n",
        "text, key2name, encrypted = gender_encrypt(s)\n",
        "end = time.time()\n",
        "\n",
        "print(encrypted)\n",
        "print(key2name)\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PER_1 then left behind <|coref|> his/her PER_1 wife ’s stabbed body and hanged <|coref|> himself/herself PER_1 from a tree in a field nearby .\n",
            "{'PER_1': {'name': 'Dineshwar', 'gender': 'male', 'alias': None}}\n",
            "5.390132427215576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XB-PJPr7lIuJ",
        "colab": {}
      },
      "source": [
        "key2name = {'PER_1': {'name': 'Dineshwar', 'gender': 'merged', 'alias': None}}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eeSiLybyVCMx",
        "outputId": "1ea4a950-3955-453a-9554-fa0b59daaaf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "decrypted = gender_decrypt(encrypted, key2name)\n",
        "decrypted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dineshwar then left behind his/her wife ’s stabbed body and hanged himself/herself from a tree in a field nearby .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z2DGAAsDT6HN",
        "outputId": "948fe8a6-356f-4deb-c72d-7758be9e6431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decrypted == text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PKBfFmbYvtad",
        "outputId": "33c9a311-0b5e-49f9-86ee-212928bbeff8",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "en = gender_encrypt(\"Mr Masum Hasan is not a doctor. Masum is an engineer.\")\n",
        "en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gender_encrypt' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-3cf708c253ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0men\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgender_encrypt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mr Masum Hasan is not a doctor. Masum is an engineer.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0men\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'gender_encrypt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7-uNtEcNaJQt",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}